<!DOCTYPE html>
<html lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
        <meta http-equiv="Content-Style-Type" content="text/css" />
        <meta name="generator" content="pandoc" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
                    <meta name="author" content="G. Jahn" />
                        <title>Open Specification of a user-controlled Web Service for Personal Data</title>
        <style type="text/css">code{white-space: pre;}</style>
                            <style type="text/css">
            div.sourceCode { overflow-x: auto; }
            table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
              margin: 0; padding: 0; vertical-align: baseline; border: none; }
            table.sourceCode { width: 100%; line-height: 100%; }
            td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
            td.sourceCode { padding-left: 5px; }
            code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
            code > span.dt { color: #902000; } /* DataType */
            code > span.dv { color: #40a070; } /* DecVal */
            code > span.bn { color: #40a070; } /* BaseN */
            code > span.fl { color: #40a070; } /* Float */
            code > span.ch { color: #4070a0; } /* Char */
            code > span.st { color: #4070a0; } /* String */
            code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
            code > span.ot { color: #007020; } /* Other */
            code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
            code > span.fu { color: #06287e; } /* Function */
            code > span.er { color: #ff0000; font-weight: bold; } /* Error */
            code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
            code > span.cn { color: #880000; } /* Constant */
            code > span.sc { color: #4070a0; } /* SpecialChar */
            code > span.vs { color: #4070a0; } /* VerbatimString */
            code > span.ss { color: #bb6688; } /* SpecialString */
            code > span.im { } /* Import */
            code > span.va { color: #19177c; } /* Variable */
            code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
            code > span.op { color: #666666; } /* Operator */
            code > span.bu { } /* BuiltIn */
            code > span.ex { } /* Extension */
            code > span.pp { color: #bc7a00; } /* Preprocessor */
            code > span.at { color: #7d9029; } /* Attribute */
            code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
            code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
            code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
            code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
            </style>
                            <link rel="stylesheet" href="./assets/styles/tompollard.css" />
                                <script src="js/jquery.js"></script>
        <script src="js/diff.js"></script>
        <script src="js/main.js"></script>
    </head>
    <body>
                <!--
                    <div id="header">
                <h1 class="title">Open Specification of a user-controlled Web Service for Personal Data</h1>
                                <h1 class="subtitle">Master Thesis</h1>
                                                <h2 class="author">G. Jahn</h2>
                                            </div>
                -->
        <div id="title-page">
            <h1>This is the title of the thesis</h1>
            <h2>Firstname Surname</h2>
        </div>
                    <div id="TOC">
                <ul>
                <li><a href="#introduction"><span class="toc-section-number">2</span> Introduction</a><ul>
                <li><a href="#motivation"><span class="toc-section-number">2.2</span> Motivation</a></li>
                <li><a href="#purpose-outcome"><span class="toc-section-number">2.3</span> Purpose &amp; Outcome</a></li>
                <li><a href="#scenarios"><span class="toc-section-number">2.4</span> Scenarios</a></li>
                <li><a href="#terminologies"><span class="toc-section-number">2.5</span> Terminologies</a></li>
                </ul></li>
                <li><a href="#fundamentals"><span class="toc-section-number">3</span> Fundamentals</a><ul>
                <li><a href="#digital-identity-personal-data-and-ownership"><span class="toc-section-number">3.2</span> Digital Identity, Personal Data and Ownership</a></li>
                <li><a href="#personal-data-in-the-context-of-the-big-data-movement"><span class="toc-section-number">3.3</span> Personal Data in the context of the Big Data Movement</a></li>
                <li><a href="#personal-data-as-a-product"><span class="toc-section-number">3.4</span> Personal Data as a Product</a></li>
                <li><a href="#related-work"><span class="toc-section-number">3.5</span> Related Work</a></li>
                <li><a href="#standards-specifications-and-related-technologies"><span class="toc-section-number">3.6</span> Standards, Specifications and related Technologies</a></li>
                </ul></li>
                <li><a href="#core-principles"><span class="toc-section-number">4</span> Core Principles</a><ul>
                <li><a href="#data-ownership"><span class="toc-section-number">4.2</span> Data Ownership</a></li>
                <li><a href="#identity-verification"><span class="toc-section-number">4.3</span> Identity Verification</a></li>
                <li><a href="#reliable-data"><span class="toc-section-number">4.4</span> Reliable Data</a></li>
                <li><a href="#authorisation"><span class="toc-section-number">4.5</span> Authorisation</a></li>
                <li><a href="#supervised-data-access"><span class="toc-section-number">4.6</span> Supervised Data Access</a></li>
                <li><a href="#containerization"><span class="toc-section-number">4.7</span> Containerization</a></li>
                <li><a href="#open-development"><span class="toc-section-number">4.8</span> Open Development</a></li>
                </ul></li>
                <li><a href="#requirements"><span class="toc-section-number">5</span> Requirements</a></li>
                <li><a href="#design-discussion"><span class="toc-section-number">6</span> Design Discussion</a><ul>
                <li><a href="#authentication"><span class="toc-section-number">6.2</span> Authentication</a></li>
                <li><a href="#data-reliability"><span class="toc-section-number">6.3</span> Data Reliability</a></li>
                <li><a href="#access-management"><span class="toc-section-number">6.4</span> Access Management</a></li>
                <li><a href="#data"><span class="toc-section-number">6.5</span> Data</a></li>
                <li><a href="#architecture"><span class="toc-section-number">6.6</span> Architecture</a></li>
                <li><a href="#environment-and-setup"><span class="toc-section-number">6.7</span> Environment and Setup</a></li>
                <li><a href="#user-interfaces"><span class="toc-section-number">6.8</span> User Interfaces</a></li>
                </ul></li>
                <li><a href="#specification-draft"><span class="toc-section-number">7</span> Specification <em>(Draft)</em></a><ul>
                <li><a href="#overview"><span class="toc-section-number">7.2</span> Overview</a></li>
                <li><a href="#components"><span class="toc-section-number">7.3</span> Components</a><ul>
                <li><a href="#webserver"><span class="toc-section-number">7.3.2</span> Webserver</a></li>
                <li><a href="#user-interface-1"><span class="toc-section-number">7.3.3</span> User Interface</a></li>
                <li><a href="#storagepersistence"><span class="toc-section-number">7.3.4</span> Storage/Persistence</a></li>
                <li><a href="#notification-infrastructure-1"><span class="toc-section-number">7.3.5</span> Notification Infrastructure</a></li>
                <li><a href="#data-api"><span class="toc-section-number">7.3.6</span> Data API</a></li>
                </ul></li>
                <li><a href="#data-1"><span class="toc-section-number">7.4</span> Data</a><ul>
                <li><a href="#structure-types"><span class="toc-section-number">7.4.2</span> Structure &amp; Types</a></li>
                <li><a href="#read"><span class="toc-section-number">7.4.3</span> Read</a></li>
                <li><a href="#write"><span class="toc-section-number">7.4.4</span> Write</a></li>
                </ul></li>
                <li><a href="#protocols"><span class="toc-section-number">7.5</span> Protocols</a><ul>
                <li><a href="#data-management"><span class="toc-section-number">7.5.2</span> Data Management</a></li>
                </ul></li>
                <li><a href="#apis"><span class="toc-section-number">7.6</span> APIs</a></li>
                <li><a href="#security"><span class="toc-section-number">7.7</span> Security</a><ul>
                <li><a href="#environment"><span class="toc-section-number">7.7.2</span> Environment</a></li>
                <li><a href="#transport"><span class="toc-section-number">7.7.3</span> Transport</a></li>
                <li><a href="#storage"><span class="toc-section-number">7.7.4</span> Storage</a></li>
                <li><a href="#authentication-1"><span class="toc-section-number">7.7.5</span> Authentication</a></li>
                </ul></li>
                <li><a href="#recommendations"><span class="toc-section-number">7.8</span> Recommendations</a><ul>
                <li><a href="#software-dependencies"><span class="toc-section-number">7.8.2</span> Software Dependencies</a></li>
                <li><a href="#host-environments"><span class="toc-section-number">7.8.3</span> Host Environment(s)</a></li>
                </ul></li>
                </ul></li>
                <li><a href="#conclusion"><span class="toc-section-number">8</span> Conclusion</a><ul>
                <li><a href="#ethical-social-impact-todo-or-relevance"><span class="toc-section-number">8.2</span> Ethical &amp; Social Impact (TODO: or “Relevance”)</a></li>
                <li><a href="#business-models-monetisation"><span class="toc-section-number">8.3</span> Business Models &amp; Monetisation</a></li>
                <li><a href="#target-group-perspectives"><span class="toc-section-number">8.4</span> Target group perspectives</a></li>
                <li><a href="#challenges"><span class="toc-section-number">8.5</span> Challenges</a></li>
                <li><a href="#solutions"><span class="toc-section-number">8.6</span> Solutions</a></li>
                <li><a href="#attack-scenarios"><span class="toc-section-number">8.7</span> Attack Scenarios</a></li>
                <li><a href="#future-work"><span class="toc-section-number">8.8</span> Future Work</a></li>
                <li><a href="#summary"><span class="toc-section-number">8.9</span> Summary</a></li>
                </ul></li>
                <li><a href="#bibliography">Bibliography</a></li>
                </ul>
            </div>
                            <div id="LOF">
                true
            </div>
                            <div id="LOT">
                true
            </div>
                

<section id="introduction" class="level1">
<h1><span class="header-section-number">2</span> Introduction</h1>
<section id="motivation" class="level2">
<h2><span class="header-section-number">2.2</span> Motivation</h2>
<p>Nowadays it is rare to find someone that does not collect data about some kind of thing; particularly humans are the targets of choice for the <em>Big Data Movement</em> <span class="citation" data-cites="web_2016_privacy-international-about-big-data">[<a href="#ref-web_2016_privacy-international-about-big-data">1</a>]</span>. Since humans are all individuals, they are - more or less - distinct from each other. However, subsets of individuals might share a minor set of attributes, but the bulk is still very unique to an individual, given that the overall variety of attributes is fairly complex. That small amount of shared attributes might seem to be less important, due to the nature of inflationary occurrence, but the opposite turns out to be true. These similarities allow to determine the individuals who are part of a subset and the ones who arn’t. Stereotypical patterns are applied to these subsets and thus to all relating individuals. Thus enriched information are then used to help predicting outcomes of problems or questions regarding these individuals. In other words, searching for causation where in best the case one might find correlations - or so called <em>discrimination</em>, which</p>
<blockquote>
<p>[…] refers to unfair or unequal treatment of people based on membership to a category or a minority, without regard to individual merit. <em><span class="citation" data-cites="paper_2008_discrimination-aware-data-mining">[<a href="#ref-paper_2008_discrimination-aware-data-mining">2</a>]</span></em></p>
</blockquote>
<p>When interacting directly with each other, discrimination of human beings is still a serious issue in our society, but also when humans leverage computers and algorithms to uncover formerly unnoticed information in order to include them in their decision making. For example when qualifying for a loan, hiring employees, investigating crimes or renting flats. Approval or denial, the decision is based on computed data about the individuals in question <span class="citation" data-cites="book_2015_ethical-it-innovation_ethical-uses-of-information-and-knowledge">[<a href="#ref-book_2015_ethical-it-innovation_ethical-uses-of-information-and-knowledge">3</a>]</span>, which is simply discrimination on a much larger scale and with less effort - almost parenthetically. The described phenomenon is originally referred to as <em>Bias in computer systems</em> <span class="citation" data-cites="paper_1996_bias-in-computer-systems">[<a href="#ref-paper_1996_bias-in-computer-systems">4</a>]</span>. What at first seems like machines going rouge on humans, is, in fact, the <em>cognitive bias</em> <span class="citation" data-cites="wikipedia_2016_cognitive-bias">[<a href="#ref-wikipedia_2016_cognitive-bias">5</a>]</span> of human nature, modeled in machine executable language and made to reveal the patterns their creators were looking for - the <em>“Inheritance of humanness”</em> <span class="citation" data-cites="web_2016_big-data-is-people">[<a href="#ref-web_2016_big-data-is-people">6</a>]</span> so to say.</p>
<p>In addition to the identity-defining data mentioned above, humans have the habit to create more and more data on a daily basis - pro-actively (e.g by writing a tweet) and passively (e.g by allowing the twitter app accessing their current location while submitting the tweet). As a result, already tremendous amounts of data keep growing bigger and bigger, waiting to be harvested, collected, aggregated, analyzed and finally interpreted. The crux here is, the more data being made available <span class="citation" data-cites="video_2015_big-data-and-deep-learning_discrimination">[<a href="#ref-video_2015_big-data-and-deep-learning_discrimination">7</a>]</span> to <em>mine</em>, the higher the chances to isolate data sets, that differ from each other but are coherent in themselves. Then it is just a matter of how to distinguish the data set and thereby the related individuals from each other.</p>
<p>In order to lower potential discrimination we either need to erase responsible parts from the machines, thereby it’s crucial raising awareness and teaching people about the issue of discrimination, or we try to prevent our data from falling into these data silos. The latter will be addressed in this work.</p>
</section>
<section id="purpose-outcome" class="level2">
<h2><span class="header-section-number">2.3</span> Purpose &amp; Outcome</h2>
<p>From an individual’s perspective providing data to third parties might not seem harmful at all. Instead eventually one get improved services in return, e.g. more adequate recommendations and fitting advertisement, or more helpful therapies and more secure environments. That said, though it is a matter of perception what’s good and bad, what’s harmful and what’s an advantage. Computing data to leverage decision making is essentially just science and technology and it’s up to the humans how such tools are getting utilized and what purposes they are serving. Hence it should be decided by the data creators, how their data get processed and what parts of them are used.</p>
<p>To tackle the described issue the initial idea here is (1) to equip individuals with the ability to control and maintain their entire data distribution and (2) thus reducing the amount of <em>potentially discriminatory</em> <span class="citation" data-cites="paper_2008_discrimination-aware-data-mining">[<a href="#ref-paper_2008_discrimination-aware-data-mining">2</a>]</span> attributes leaking into arbitrary calculations. To do so people need a reliable and trustworthy tool, which assists them in managing all their <em>personal data</em> and making them accessible for 3rd parties but under their own conditions. After getting permission granted these data consumers might have the most accurate and reliable one-stop resource to an individuals’s data at hand, while urged to respect their privacy at the same time. However this also comes with downsides in terms of security and potential data loss. Elaborating on that and discussing different solutions will be part of the [design process][Design].</p>
<p>The way how to solve the described dilemma is not new. Early days of work done in this field can be dated back to the Mid-2000s where studies were made e.g. about recent developments in the industry or user’s concerning about privacy, and the term <em>Vendor Relationship Management (VRM)</em> were used initially within the context of user-centric personal data management, which also led into the <em>ProjectVRM</em> <span class="citation" data-cites="web_2010_projectvrm_about">[<a href="#ref-web_2010_projectvrm_about">8</a>]</span> started by the <em>Berkman Klein Center for Internet &amp; Society at Hardvard University</em>. Since then a great amount of effort went into this research area until today, while also commercial products and business models trying to solve certain problems. For instance concepts such as the <em>Personal Data Store (PDS)</em> <span class="citation" data-cites="paper_2013_the-personal-data-store-approach-to-personal-data-security_2013">[<a href="#ref-paper_2013_the-personal-data-store-approach-to-personal-data-security_2013">9</a>]</span> or a <em>MyData</em> <span class="citation" data-cites="whitepaper_2014_mydata-a-nordic-model-for-human-centered-personal-data-management-and-processing">[<a href="#ref-whitepaper_2014_mydata-a-nordic-model-for-human-centered-personal-data-management-and-processing">10</a>]</span> implementation called <em>Meeco</em> <span class="citation" data-cites="web_2016_meeco-how-it-works">[<a href="#ref-web_2016_meeco-how-it-works">11</a>]</span>, which will all be covered in a more detailed way within the following chapter.</p>
<p>The work and research done for this thesis will be the foundation for an <em>Open Specification</em>, which by itself is a manual to implement a concept called <em>Personal Data as a Service</em>. Important topics like how the architecture will look like, where the actual data can be stored, how to obtain data from the external API or what requirements a user interface for data management need to satisfy, will be examined. After the thesis will be finished, the majority of core issues should already be addressed and can then get outlined in the specification document. Only then the task to actual implement certain components can begin. The reason for that is, when sensitive subjects especially like people’s privacy is at risk, all aspects in question deserve a careful considerations and then get addressed properly. Thus it is indispensable to put adequate effort primarily into the theoretical work. To be clear though, that doesn’t mean writing code to test out theories and ideas can’t be done during research and specification development. It might even help to spot some flaws and eventually trigger evolvement.</p>
<p>To ensure a great level of trust to this project and the resulting software, it is vital to make the development process fully transparent and encourage people to get involved. Therefore it is required to open source all related software and documents <span class="citation" data-cites="repo_2016_pdaas-spec">[<a href="#ref-repo_2016_pdaas-spec">12</a>]</span> from day one on.</p>
<p>In summary, this document is meant to be the initial step in a development process fabricating a tool to manage all data defining a data subject’s identity, that is controlled and administrated by that individual, so that maybe she is giving a more precise understanding about where her personal information flows and how this might effect her privacy.</p>
</section>
<section id="scenarios" class="level2">
<h2><span class="header-section-number">2.4</span> Scenarios</h2>
<p>The following use cases shall depict different situations and possible ways such emerging software might be applicable or useful, while providing it’s user with more control over her personal data. Some of them are more practical and realistic, like ordering and purchasing online a product, others might have no current usage, but showing a certain potential to become more relevant when new technologies and business models emerge, followed by new demands of data.</p>
<section id="ordering-a-product-online" class="level4">
<h4><span class="header-section-number">2.4.1.1</span> Ordering a product online</h4>
<p>The data subject searches through the web to find a new toaster, since her old one recently broke. After some clicks and reviews, she found her soon-to-become latest member of the household’s kitchenware. After putting the model name in a price search engine, hoping to save some money, the first entry, offering a 23% discount, caught her attention. She decides to have a deeper look into the toasters and thus has heading towards the original web shop entry. Finally she came around and put the item onto her card, despite tha fact, that she has never bought something from that online shop before. Then she proceeded to checkout to place her order. The shop-interface is asking her to either insert her credentials, proceed without registration or sign-in, or insert s URI to an endpoint of her <em>Personal Data as a Service</em>. TODO: the following description might need some adjustments according data flow / process description She opens up the management panel of her <em>PDaaS</em> and creates a new entry in a list of data consumers, that already have access to characteristics of her personal data. As a result, she receives a URI, which she inserts according, as mentioned before; after she assures herself that the data exchange with the shop through the browser is based on a secure connection (HTTPS). Under this URI, the shop-system can then request data, that is required for a successful transaction. Moving on to the next step after submitting the URI, the data subject is ask to decide how she would like to pay. The choices are: credit card, invoice, online payment provider of choice or bank transfer. She chooses the last one, submits her selection and thereby completes her order. After a moment, a push notification pops up on her mobile device, which is a permission request from her <em>PDaaS</em>, asking for granting the shop-system, she just places the order, access to her full name, address and email. Additionally she can decide between three states of how long the permission wil be valid: <em>only one time</em>, <em>expires on date</em> and <em>granted, until further notice</em>. Since she never ordered at this shop before and might never again, she decided to grant access only for this specific occasion. After the shop-system receives the data, it sends an email to the data subject, containing some information about her order, including the shop’s bank details. which then enables her to actually pay the amount due. After the system recognizes the payment has coming in, it triggers the shipment of the toaster. In order to get a full impression of how the whole process might have look like when the data subject had chosen one of the other payment methods, the differences will be describes in the following. If the data subject would have wanted to pay with her credit card, the only difference would have been, that the shop-system had requested also to access the credit card number and it’s belonging secret, and when sending the email the system would have omitted the information about the shop’s bank details. Being able to choose paying with invoice where possible only because the <em>PDaaS</em> response has indicated, that it’s containing <em>profile data</em> is certified and therefore trustworthy. Which reduces the shop owner’s risk and would have enabled him in case of fraud or misuse to take action. Choosing to involve paypal as a <em>middleman</em> to process the payment, requires the data subject to had already granted paypal certain access to her <em>PDaaS</em>. If that’s the case, then the shop-system would have ask also for her paypal-ID, which then the system will use to request the payment directly from paypal. This on the other side will cause paypal to consult the <em>PDaaS</em>, which results in a second notification, asking the data subject for permission to proceed. After the payment transfer was successful, the shipment will gets initiated. And with the package arriving at the data subject’s doorstep the whole transaction has finished.</p>
</section>
<section id="interacting-with-a-social-network" class="level4">
<h4><span class="header-section-number">2.4.1.2</span> Interacting with a social network</h4>
<p>Entering a social network for the first time, only take the URI to the data subject’s <em>PDaaS</em> and a password. The data subject receives a notification on her mobile device asking for permission to access certain data about her. If her mobile device is currently not at hand, she can also use the administration panel provided by her <em>PDaaS</em> and reachable with a web browser on every internet-enabled device. Within that panel pending permission reviews will be indicated. Whether the data subject has already reviewed the request or not, she should be able to login to the social network. After doing so, she should not be able to see any of her information. After granting permissions to the social network to accessing certain data <em>until-further-notice</em> and reloading the session, she then should see all her So every time, someone on that network tries to access her information, whom she has allowed to see that information (which is managed by the user only from within the network), the network pulls the data from the data subjects’s <em>PDaaS</em>, if it’s still permitted to do so. It’s also imaginable, that the social network and a <em>PDaaS</em> are establishing a backward channel. This channel could be used to send all the content she would create over time while interacting with the social network and it’s participants back to her <em>PDaaS</em>. The network itself only stores a reference to all content object, whether it’s for example an image, a post or comment on somebody else’s post and if it’s needed the actual content will be fetched from the data subject’s <em>PDaaS</em>.</p>
</section>
<section id="applying-for-a-loan-and-checking-creditworthiness" class="level4">
<h4><span class="header-section-number">2.4.1.3</span> Applying for a loan and checking creditworthiness</h4>
<p>The data subject would like to buy an apartment. In order to finance such a acquisition, she needs a funding, which in her case, will be based on a loan. During a conversation in a credit institute of her choice, an account consultant describes to her what data will be required in order to decide about her creditworthiness. While giving a consensual nod, she takes out her smartphone and brings up the management panel of her <em>PDaaS</em>. With a few taps she has just created a new <em>data consumer</em>. The panel then shows a QR-Code, that holds a URI to a dedicated endpoint of the data subject’s <em>PDaaS</em>. She shows that code to her consultant, who then scans it. While handling some more formalities and talking about several issues and possible products she might be interested it, she gets a notification on her phone, informing her about a permission request the institute just made. It lists all the different data points the institute would like to access in order to calculate her scoring, such as address, monthly income, relationship status and family, history of banking or other current loans. After some back and forth and solving some misunderstandings with the help of her consultant, she decided to just partially allow access to the requested data and just for this time and purpose. The consultant kindly pointed out, that these decisions might have an impact on the scoring and thereby on the lending and it’s terms. After the consultant got a signal from the computer system, the two then finishing up their meeting and the consultants informed the data data subject about the next steps, which includes a note, that the institute will contact her within the next few days, when they have come to a conclusion. In case of a positive outcome a new appointment need to be made, for doing all the paperwork and signing the contract. From a technical point of view, two different ways of computing the score are imaginable. The first one would be, transferring only the plain data - request, containing the query and response containing the data - including the expire date and information regarding the signature state. But the actual computations and analytics to obtain the score, will happen within the infrastructure of the credit institute. When this process is over, all transferred personal data has to be deleted. An alternative could prevent the data from leaving the <em>PDaaS</em>, in which the institute’s request won’t consists of a data query. Instead it would came along with an chunk of software and some information on how to run it. The <em>PDaaS</em> server will provide an isolated runtime in which the software then gets executed. After the process has finished, the result will be send back to the credit institute’s infrastructure.</p>
</section>
<section id="maintain-and-provide-its-own-medical-record" class="level4">
<h4><span class="header-section-number">2.4.1.4</span> Maintain and provide it’s own medical record</h4>
<p>Some time ago on a hiking trip in a moment of carelessness the data subject has accidently broke her leg. She came into a hospital and went straight into surgery, where the physicians could fix the injury. Time went by and the leg has healed completely. After she woke up today she felt some pain coming from that area where her leg was broken. She decided to call in sick and went straight to a doctor nearby. During her recovery she visited that doctor regularly. At the reception desk, she opens up the <em>PDaaS</em>’s management panel on her smartphone and searched through the list of data consumers. After she found the entry for this clinic, she flipped her phone to show the receptionist the corresponding QR-Code, which she started to scans immediately. However the receptionist couldn’d see any data on the screen, because the access has already expired. The data subject only had permitted access for the estimated time of recovery, which was over some time ago. That’s why she got a notification, to re-grant some access. Going through the data points the clinic-system has requested, she noticed that her address is incorrect. Last month she moved out and into a bigger apartment just down the street. She must have forgot to change that data, which she corrects immediately right before submitting the access configurations for the clinic-system. She also included the access to all the data originated from that time after her accident. A moment later the receptionist confirms to now being able to see all necessary data. The data subject takes a seat in the waiting room. While passing some time, she had a deeper look into her list of data consumers; some of them she couldn’t even remember and for others she was surprised to what data she has granted access to and started to reduce certain permissions, if it was appropriate in her eyes. She even removed some of the entries. The appointment with her doctor went great. He even had to review the x-ray images in order to make a adequate differential diagnosis. After the visit, she had to make a quick stop at a pharmacy along the way to pickup the drugs her doctor had prescribed for her to reduce the pain. She had to wait in the queue with two other customers being in front of her. She realized, that it’s the first time she has been here. So she prepared a new entry in her data consumer list, including all information about her prescriptions. So by the time she get served, she just let the person behind the register scan her code. In the next seconds the data subject gets a quick confirmation notification about the request that just happened. A moment later the pharmacist come back with her drugs, which she then pays in cash and the transaction is done.</p>
</section>
<section id="vehicle-data-and-mobility" class="level4">
<h4><span class="header-section-number">2.4.1.5</span> Vehicle data and mobility</h4>
<p>Assuming a car itself has no hardware on board in order to establish a wireless wide area connection to an outside access node. Only from the inside one can connect to the car (wired or wireless). After entering a car, on the data subject’s mobile device pops up a notification asking for permission to connect to that device. In addition to the expiration date, the data subject can choose to en- or disable two more options. First, a wifi network with an uplink to the internet can be provided to everyone inside the car. Secondly, connections, the car might want to establish, in order to emit data via internet - which, regardless, have to go through the currently linked mobile device. Thus the device owner gains full control over any external data transfer that might happen. This again would allow two things: (A) permission management for all outgoing data and (B) funnel all data generated and provided by the car into the <em>PDaaS</em> associated with that linked device. It might also be feasible to deny any connection the car is trying to make. Thus the data will only be stored in the <em>PDaaS</em>. If somebody is interested in such then have to ask for access permission. That same concept about movement tracking and vehicle data could also be applied to driving (motor) bicycle.</p>
</section>
</section>
<section id="terminologies" class="level2">
<h2><span class="header-section-number">2.5</span> Terminologies</h2>
<dl>
<dt>Web Service</dt>
<dd>TODO
</dd>
<dt>Open Specification</dt>
<dd>TODO
</dd>
<dt>Big Data</dt>
<dd>deep learning, neural networks
</dd>
<dt>Profile Data</dt>
<dd>individual’s inherent data; TODO
</dd>
<dt>Personal Data (TODO)</dt>
<dd>Personal Information predominantly static data points related to an individual
</dd>
<dt>Personal Data as a Service (PDaaS)</dt>
<dd>a web service controlled, owned and maybe even hosted by an individual, that provides access to the data subject’s personal data and offers maintainability as well as permission management. It can be seen as her personal agent; sometimes also referred to as <em>the system</em>
</dd>
<dt>Personal Data Store</dt>
<dd>TODO
</dd>
<dt>Vendor Relationship Manager</dt>
<dd>The <em>ProjectVRM</em> defines the a VRM as follows: “TODO” <span class="citation" data-cites="web_2010_projectvrm-wiki_about-vrm">[<a href="#ref-web_2010_projectvrm-wiki_about-vrm">13</a>]</span>
</dd>
<dt>Personal Information Management Systems (PIMS)</dt>
<dd>TODO <span class="citation" data-cites="web_2010_projectvrm-wiki_pims-example-list">[<a href="#ref-web_2010_projectvrm-wiki_pims-example-list">14</a>]</span>
</dd>
<dt>serverless</dt>
<dd>TODO https://auth0.com/blog/2016/06/09/what-is-serverless/
</dd>
<dt>Digital Footprints</dt>
<dd>TODO
</dd>
<dt>Data Subject</dt>
<dd>an individual who first and foremost is the owner of all of her personal data; sometimes referred to as <em>owner</em>
</dd>
<dt><span id="terminologies--operator">Operator</span></dt>
<dd>a <em>data subject</em> using a PDaaS to control (and probably host) her personal data; sometimes referred to as <em>data controller</em>
</dd>
<dt><span id="terminologies--consumer">(Data) Consumer</span></dt>
<dd>Third party, external entity requesting data, authorized by the data subject to do so; sometimes referred to as <em>(data) collector</em>
</dd>
<dt>Data Broker(s)</dt>
<dd>entities with commercial interests, that collect, aggregate and analyze information/data of any kind - in this case about human beings - from different sources in order to enrich the data sets, to finally license the resulting corpora to other organisations. <span class="citation" data-cites="report_2014_data-brokers">[<a href="#ref-report_2014_data-brokers">15</a>]</span>
</dd>
<dt>Permission Request</dt>
<dd>initial attempt to request permissions for accessing certain data from the <em>PDaaS</em>; third party registers as <em>data consumer</em>
</dd>
<dt>Access Request</dt>
<dd>obtain/request actual data from the system (requires a third party to be registered as a <em>data consumer</em>)
</dd>
<dt>Permission Profile</dt>
<dd>a data set about a third party that already made a permission request. The set contains additional information and access rules
</dd>
<dt>Data Access</dt>
<dd>after a third party’s <em>permission request</em> got reviewed and saved, that entity is then able to make an attempt to access data.
</dd>
<dt>Endpoint</dt>
<dd>an endpoint is defined as the part of the URI that is unique to every <em>data consumer</em>, or to be more precise, unique to every <em>permission profile</em>. Usually it is the first part of a URI, whereas following parts stand for different resources that might be available within that endpoint It can also be seen as group of resources that all can be accessed by under specific circumstances
</dd>
</dl>
</section>
</section>
<section id="fundamentals" class="level1">
<h1><span class="header-section-number">3</span> Fundamentals</h1>
<p>The following chapter shall provide the foundational knowledge about concepts like <em>Personal Identity</em> or <em>Big Data</em> and therefore ensures a common understanding on their relation to the problem this work tries to solve. Additionally it is given a brief overview on what existing standards and technologies might be used, and summarizes the research already been made as well as it’s current state.</p>
<section id="digital-identity-personal-data-and-ownership" class="level2">
<h2><span class="header-section-number">3.2</span> Digital Identity, Personal Data and Ownership</h2>
<ul>
<li><em>Digital Identity</em>
<ul>
<li>what is a <em>DI</em>? and in comparison to <em>Personal Data</em>?</li>
<li>what is required to make the PDaaS used or seen as a <em>DI</em>?</li>
</ul></li>
<li><em>Personal Data</em> definition
<ul>
<li>general - freely spoken</li>
<li>as of EU law (incl citation)</li>
<li>as of US law (incl citation)</li>
<li>is it just policy/guideline or enforceable too (law/rule)? what relevance/impact have companies <em>terms and conditions</em>?</li>
<li>EU and USA (since server might be located outside the state or effective range)</li>
</ul></li>
<li><em>Ownership</em> of personal data
<ul>
<li>who is the owner in what situation or under what circumstances?</li>
<li>am I the owner when I was the one who was collecting them? Does it depend on whether the resource was public or somewhat private?</li>
<li>what will happen with her data service after a person died?</li>
</ul></li>
</ul>
<section id="section" class="level100">
<p><span class="header-section-number">3.2.1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.1</span> </p>
<ul>
<li><p>A <strong>Digital Identity</strong> is a non-physical abstraction of an entity, such as an organisation, an individual, a device or even software, which allows bidirectional association. In the context of this document, it only refers to human beings. Therefore a <em>digital identity</em> is the individual’s representation in digital systems, consisting of identity-defining data, such as <em>personal information</em> and it’s history and preferences <span class="citation" data-cites="whitepaper_2012_the-value-of-our-digital-identity_definition">[<a href="#ref-whitepaper_2012_the-value-of-our-digital-identity_definition">16</a>]</span>. <em>Personal information</em>, in this case, refers to inherent (date of birth) and imposed (credit card number) characteristics.</p></li>
<li><p>From a technical perspective a DI is essentially a collection of characteristics, attributes and time series data (e.g. interaction logs or bank account history). A subset of those attributes combined can form unique fingerprint, like certain single data points (e.g. social security number) in their own context might be, too. Thus it might not be necessary to know the values of all attributes in order to identify a person as the rightful owner and physical counterpart. It can also be seen as an avatar in the digital world or as the digital part of a human’s identity. Therefore it’s important to not view the <em>DI</em> as a reduction of a living individual to some bits and bytes, but rather as a appropriate representation for certain purposes and contexts.</p></li>
<li>It is also possible to provide an additional level of authenticity insurance for data related to an entity. Therefor an unrelated third party, which needs to be approved not only by the related individual, but also by all entities participating in a context, which might be relevant e.g. for some administration purposes.</li>
<li><p>But the concept would also impose a new level of attacking vectors to the identity owner, such as identity theft. The attacker is no longer required to be physically present to be able to steal certain unique identifiers from a person. It is sufficient to gain access to area where the sensitive data is stored.</p></li>
<li><p>In the context of this document and all related work, <strong>Personal Data</strong> is specified as a combination of an individual’s <em>Digital Identity</em> and all of it’s ever created intellectual property <span class="citation" data-cites="web_2016_wikipedia_intellectual-property">[<a href="#ref-web_2016_wikipedia_intellectual-property">17</a>]</span> (e.g. posts, images, tweets or comments). This includes all sorts of tracking data and interaction monitoring, as well as metadata manually or automated enriching content (e.g.geo-location attached to a tweet as meta information). Data, captured by someone ore something on or about the individual’s private living space and property. Simply every data point reflecting the individual’s personality - partly or as a whole - is seen as <em>personal data</em>.</p></li>
<li><p>The european <em>Data Protection Regulations</em> defining <em>Personal Data</em> as follows: &gt; ‘personal data’ means any information relating to an identified or identifiable natural person &gt; (‘data subject’); an identifiable natural person is one who can be identified, directly or &gt; indirectly, in particular by reference to an identifier such as a name, an identification &gt; number, location data, an online identifier or to one or more factors specific to the physical, &gt; physiological, genetic, mental, economic, cultural or social identity of that natural person; &gt; <em><span class="citation" data-cites="regulation_2016_eu_general-data-protection-regulation_definition">[<a href="#ref-regulation_2016_eu_general-data-protection-regulation_definition">18</a>]</span></em></p></li>
<li>The U.S.A. has little legislation on defining and protecting consumer’s privacy. At least they have no explicit bills addressing such area <span class="citation" data-cites="web_2016_wikipedia_information-privacy-law_us">[<a href="#ref-web_2016_wikipedia_information-privacy-law_us">19</a>]</span>. Though some of the existing sectoral laws consist of partially applicable policies and guidelines <span class="citation" data-cites="web_2016_data-protection-laws-in-the-us">[<a href="#ref-web_2016_data-protection-laws-in-the-us">20</a>]</span>; most of them addressing specific types of data. In 2015 the White House made an attempt to fill the gap with the <em>Consumer Privacy Bill of Rights Act</em>, but to this date it didn’t passes the draft state. According to the critics, it lags of concrete enforceable rules consumers can rely on <span class="citation" data-cites="web_2015_white-house-releases-consumer-privacy-bill-draft">[<a href="#ref-web_2015_white-house-releases-consumer-privacy-bill-draft">21</a>]</span>. The draft contains a general definition of <em>Personal Data</em>: &gt; “Personal data” means any data that are under the control of a covered entity, not otherwise &gt; generally available to the public through lawful means, and are linked, or as a practical matter &gt; linkable by the covered entity, to a specific individual, or linked to a device that is &gt; associated with or routinely used by an individual, including but not limited to […] &gt; <em><span class="citation" data-cites="bill-draft_2015_us_consumer-privacy-bill-of-rights-act_definition">[<a href="#ref-bill-draft_2015_us_consumer-privacy-bill-of-rights-act_definition">22</a>]</span></em></li>
<li><p>followed by a list of concrete data points, e.g. email or postal address, name, social security number and alike. Aside from the legislation with bills, a few third-party organisation can also participate by and add new or overwriting existing rules and policies. Namely for example the <em>Federal Communications Commission</em> (FCC), recently releasing <em>Rules to Protect Broadband Consumer Privacy</em> including a list of categories of sensitive information <span class="citation" data-cites="rules_2016_fcc_to-protect-broadband-consumer-privacy_sensitive-types-of-data">[<a href="#ref-rules_2016_fcc_to-protect-broadband-consumer-privacy_sensitive-types-of-data">23</a>]</span>, which wants <em>Personally Identifiable Information</em> (alias Personal Data) to be understood as: &gt; […] any information that is linked or linkable to an individual. […] information is &gt; “linked” or “linkable” to an individual if it can be used on its own, in context, or in &gt; combination to identify an individual or to logically associate with other information about a &gt; specific individual. &gt; <em><span class="citation" data-cites="rules_2016_fcc_to-protect-broadband-consumer-privacy_personally-identifiable-information">[<a href="#ref-rules_2016_fcc_to-protect-broadband-consumer-privacy_personally-identifiable-information">24</a>]</span></em></p></li>
<li><p>Despite minor difference in detail, they all have similar ideas of personal data and their belonging. Even though, the version proposed by EU is almost identical with the definition introduced for the context of this work. Although the FCC’s statutory authorities might be somewhat debatable regarding certain topics, the <em>Communications Act</em> as a U.S. federal law equips the FCC with power to regulate and legislate.</p></li>
<li><p>Having a common opinion on what data points are belonging to person is the foundation to define a set of rules on how deal with <em>Personal Data</em> accordingly. Every business, operating within the EU, is required<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> to provide it’s users with a <em>Privacy Policy</em>, while e.g. in the U.S. - as mentioned above - only partially and depending on context and data type users must be informed about which and how their data get processed <span class="citation" data-cites="web_2016_privacy-policies-are-mandatory-by-law">[<a href="#ref-web_2016_privacy-policies-are-mandatory-by-law">25</a>]</span>.</p></li>
<li>A user commonly agrees on the privacy policy, by starting to interact with the author’s business, thus every <em>Privacy Policy</em> is required to be publicly accessible; e.g. before creating an account. &gt; By clicking Create an account, you agree to our <a href="https://www.facebook.com/legal/terms">Terms</a> &gt; and that you have read our <a href="https://www.facebook.com/about/privacy">Data Policy</a>, including &gt; our <a href="https://www.facebook.com/policies/cookies/">Cookie Use</a>. &gt; <em>[web_2016_facebooks-landing-page_policy-acknowledgement]</em></li>
<li>It can be seen more likely an information notice, that translates and specifies general given law, rather then a contract.</li>
<li><p>With such knowledge at hand, it is up to each individual, if the service’s benefits are worth sharing some personal data, while simultaneously acquiescing potential downsides concerning the privacy of such data.</p></li>
<li><p>Every entity who is doing so, muss process Personal data according to the law and their <em>Privacy Policy</em>. If they policies are violating existing law or the entity effectively goes against the law with their actual doing, penalties might follow. Depending on the level and impact of their infringement in addition the law itself, aside from revising their wrong-doings the entity might have to compensate the affected individuals, pay a fine or get revoked their license.</p></li>
<li><p>Not only privacy laws, but every legal jurisdiction has it’s limitations - concerning their territorial nature - which makes legislation not exactly an appropriate tool when it comes to fixing existing issues and strengthen the individual’s privacy and rights in a global context like the <em>world wide web</em>. If no international agreement is in place <span class="citation" data-cites="web_2016_international-privacy-standards">[<a href="#ref-web_2016_international-privacy-standards">26</a>]</span>, only those laws are considered valid and enforcible where the organisation is registered, and maybe the fact where (meaning in which area of jurisdiction) the their servers are located or the data is processed and stored.</p></li>
</ul>
<p>Whereas <strong>Ownership</strong> of <em>Personal Data</em> has no legal ground foundation what so ever. The concepts of intellectual property protection and copyright might intuitively be applicable, because the data, created by the data subject, seems to be her <em>intellectual property</em>. Such property implies to be a result of a creative process though, but unfortunately there is no <em>threshold of originality</em> in facts, like <em>personal information</em> is <span class="citation" data-cites="paper_2014_who-owns-yours-data">[<a href="#ref-paper_2014_who-owns-yours-data">27</a>]</span>.</p>
<ul>
<li><p>Ownership in the sense of having exclusive control over it’s personal data and how they get processed at any given point in time; this not only comes with high costs, but is also very inconvenient for both parties - data subject and data consumer. It consists of two <span id="def-ownership">concepts</span>: (A) the right to do what every is desired with their property and (B) in which rules and mechanisms the ownership can be assigned to someone <span class="citation" data-cites="book_1987_private-ownership_definition">[<a href="#ref-book_1987_private-ownership_definition">28</a>]</span>.</p></li>
<li><p>The european DPR<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> contains only one occurrence of the word <em>ownership</em>, which is not even related to the context of <em>personal data</em> or the <em>data subject</em>. It only stats, that <em>“Natural persons should have control of their own personal data.”</em> <span class="citation" data-cites="regulation_2016_eu_general-data-protection-regulation_ownership">[<a href="#ref-regulation_2016_eu_general-data-protection-regulation_ownership">29</a>]</span>. Whereas Commissioner J. Rosenworcel of the FCC wants <em>“consumers […] to […] take some ownership of what is done with their personal information.”</em> <span class="citation" data-cites="rules_2016_fcc_to-protect-broadband-consumer-privacy_ownership">[<a href="#ref-rules_2016_fcc_to-protect-broadband-consumer-privacy_ownership">30</a>]</span></p></li>
<li><p>Typically the question of data ownership is addressed in data consumer’s <em>Terms of Service</em> (ToS), which an individual might have to accept in order to establish a (legal) relationship with it’s author. I should be kept in mind, that <em>ToS</em> might change over time; not necessarily to the users advantage. All addressed issues (by the ToS) must not violate any applicable or related law, otherwise the <em>ToS</em> might not be legally recognized. Taking the following excerpts from different <em>ToS</em>:</p></li>
</ul>
<blockquote>
<p>You own all of the content and information you post on Facebook, and you can control how it is shared […]. <em>(under “2. Sharing Your Content and Information”, by Facebook <span class="citation" data-cites="web_2016_facebook_terms-of-service">[<a href="#ref-web_2016_facebook_terms-of-service">31</a>]</span>)</em></p>
</blockquote>
<blockquote>
<p>You retain your rights to any Content you submit, post or display on or through the Services. What’s yours is yours — you own your Content. <em>(under “3. Content on the Services”, by Twitter <span class="citation" data-cites="web_2016_twitter_terms-of-service">[<a href="#ref-web_2016_twitter_terms-of-service">32</a>]</span>)</em></p>
</blockquote>
<blockquote>
<p>Some of our Services allow you to upload, submit, store, send or receive content. You retain ownership of any intellectual property rights that you hold in that content. In short, what belongs to you stays yours. <em>(under “Your Content in our Services”, by Google <span class="citation" data-cites="web_2016_google_terms-of-service">[<a href="#ref-web_2016_google_terms-of-service">33</a>]</span>)</em></p>
</blockquote>
<blockquote>
<p>Except for material we may license to you, Apple does not claim ownership of the materials and/or Content you submit or make available on the Service “(under”H. Content Submitted or Made Available by You on the Service“, by Apple <span class="citation" data-cites="web_2016_apple-icloud_terms-of-service">[<a href="#ref-web_2016_apple-icloud_terms-of-service">34</a>]</span>)*</p>
</blockquote>
<p>All these statements are followed by the same term, stating that the user grants the author a worldwide license to do almost any imaginable thing with her data. This even applies to Apple, if the user is <em>“submitting or posting […] Content on areas of the Service that are accessible by the public or other users with whom [the user] consent to share […] Content”</em> <span class="citation" data-cites="web_2016_apple-icloud_terms-of-service">[<a href="#ref-web_2016_apple-icloud_terms-of-service">34</a>]</span>.</p>
<ul>
<li>It is worth noticing, that in every <em>ToS</em> it is only referred to the data subject’s content, not all her personal data. As mentioned above, personal information are no intellectual property, but playing an important role in data analytics though. Which is why <em>privacy policies</em> are in place, to ensure at least some user enlightenment, even though it doesn’t compensate the lack of control.</li>
<li><p>In addition to that, the meaning of <em>ownership</em> used in the quoted <em>ToS</em> is missing a clear outline and thus causing ambiguity and leaving room for interpretation. Nor the actual definition of <em>ownership</em>, as described earlier, is applicable for these kind of cases, since the user losing all its control is by design. Handing over data to the consumer annihilates the exclusive control over the data and revokes the ability of assigning such control. There is no (legislation based) way to establish a feasible concept of <em>ownership</em>, if the data consumer has no motivation to promote the user the a comprehensive owner of her data.</p></li>
<li><p>Leaving all the legal layer aside for a moment and switching the perspectives a bit; Data consumers might argue, that they had invested in enabling themselves to collect, process and store personal data, so it belongs to them. But from the data subject’s point of view it might only be the case as long as as she would benefit as well somehow, e.g. using products, services or features, offered by consumers, which quality depends on personal data. If the data subject chooses to move to a competitor might what to bring her personal data with her. But then again the former data consumer would object, competitors would benefit from all investments the consumer has made, but without any effort. Though, not entirely wrong, two aspects need to be emphasize. (A) In order to archive a high level of quality for their analytics and therefore in making right decisions to gain improvement, it’s vital to huge amount of effort in developing these underlying technologies, not only in acquiring personal data. Which again only constitutes (B) the foundation of various subsequential computations followed by an ongoing collecting, aggregation and analytics of actively and passively created data and metadata (e.g. food deliver history or platform interactions and tracking). Given the initially introduced definition of <em>personal data</em> it appears to only be a fraction of the involved data belonging to its owner. The larger part consists of highly valuable metadata <span class="citation" data-cites="web_2013_why-metadata-matters">[<a href="#ref-web_2013_why-metadata-matters">35</a>]</span> <span class="citation" data-cites="web_2016_why-you-need-metadata-for-big-data-to-success">[<a href="#ref-web_2016_why-you-need-metadata-for-big-data-to-success">36</a>]</span> and therefore should remain to the data collector and either be deleted or sufficiently anonymized, if the owner cancels the relationship. The data subject should not depend on the collector’s willingness when it comes to handing over her personal data (e.g. list of favorites or delivery history). Instead, using her own tool to provide the consumer with required data (e.g. list of favorites) or tap into her data creating interactions (e.g. food deliveries) on her own.</p></li>
<li><p>Whether an individual dies or a user deletes her account, as long as certain data point are shared with / connected to other users, the data will remain. At least when it comes to facebook.</p></li>
<li><p>Generally speaking, all data solely associating with an individual, is in the ownership of the same. But since it doesn’t exist any legal concepts on <em>personal data</em> ownership, a technical solution could help to regain some control.</p></li>
</ul>
</section>
</section>
<section id="personal-data-in-the-context-of-the-big-data-movement" class="level2">
<h2><span class="header-section-number">3.3</span> Personal Data in the context of the Big Data Movement</h2>
<ul>
<li>big data itself initially can be seen as a <em>huge blob of data</em> containing more or less structured data sets <span class="citation" data-cites="web_2016_oxford_definition_big-data">[<a href="#ref-web_2016_oxford_definition_big-data">37</a>]</span>, whose size might have exceeded the capabilities of retrieving certain information almost only by hand. Such high data haystacks usually come along with new challenges in logistic and resource management, when information retrieval needs to get automated on a large scale <span class="citation" data-cites="web_2016_wikipedia_definition_big-data">[<a href="#ref-web_2016_wikipedia_definition_big-data">38</a>]</span>. Theses practices are commonly referred to <em>Big Data (Analysis)</em> including distributed computing and machine learning.</li>
<li>Big Data, or to be more precise, collecting and analyzing big data, serves the prior purpose to extract useful information, which on the other hand depends on what was the opening question about, but also what data sets the corpus is containing.</li>
<li><p>At first, (A) formalizing question(s) that the results have to answer. Secondly, (B) deciding what data is needed and appropriate and then start collecting. Third, (C) designing data models accordingly and correlate with the data (D) next, analyse and interpret the results. (E) last but not least, make business decisions based und the analyses (<span class="citation" data-cites="paper_2015_big-data-analytics_a-survey">[<a href="#ref-paper_2015_big-data-analytics_a-survey">39</a>]</span> Fig. 3).</p></li>
<li><p>machine learning/data mining –&gt; computers trained to find coronations</p></li>
<li>since quite a few businesses (in terms of purpose or intention) are based around the concept of customers, which are generally somewhat entities consisting of at least one human being, personal data takes a major part in what <em>Big Data</em> can be about. In the context of this thesis, these entities are individuals with a unique identity. And to understand the behaviour, decision making and needs of her customers a vendor, who owns the business, needs to know as much as possible about them, when she wants to know what changes she needs to address in order to move towards the most lucrative business.</li>
<li><p>personal data and information are reflecting all this knowledge. It starts with profile (or sensitive) data, such as gender, age, residency or income, goes on with time series events like geo-location changes, or web search history and goes all the way up to health data and self-created content like <em>Tweets</em><a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> or videos.</p></li>
<li>all these classes of personal data hold a major share<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> in the field of data analytics (TODO: find statistics showing shares of data types/classes/categories, <span class="citation" data-cites="book-chapter_1999_Principles-of-knowledge-discovery-in-databases_introduction-to-data-mining">[<a href="#ref-book-chapter_1999_Principles-of-knowledge-discovery-in-databases_introduction-to-data-mining">40</a>]</span> <span class="citation" data-cites="web_2013_big-data-collection-collides-with-privacy-concerns">[<a href="#ref-web_2013_big-data-collection-collides-with-privacy-concerns">41</a>]</span>)</li>
<li>but, depending on the specific attributes, they might be not that easy to acquire. in general most businesses obtain data from within their own platforms. some data might be in the user’s rang of control (e.g. customer or profile data), but most of the data comes from interacting directly (content creation, inputs) or indirectly (transactions, meta information). the level of sensitivity is mainly based on the purpose of the platform (benefit for the user) and what is the provider’s demand from the users commitment (e.g. required inputs or usage requires access to location)</li>
<li>from a technical perspective collecting passively created data is as simple as integrating logging mechanisms in the program logic. since the industry moved towards the cloud<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> most scenarios utilized server-client architectures. Furthermore the <em>always-on</em> philosophy evolved to an imperative state. standalone software is starting to call the author’s servers from time to time, just to make sure the user behaves properly. For browsers it was already a common narrative to make here and then requests to the server - still preventable though, but when it comes to native mobile apps it is almost impossible <span class="citation" data-cites="web_2016_answers-io">[<a href="#ref-web_2016_answers-io">42</a>]</span> to notice such behaviour and therefore preventing apps from doing so.</li>
<li><p>these architectural developments were inducing the gathering of potentially useful information from all over the system on a large scale <span class="citation" data-cites="web_2016_big-data-enthusiasts-should-not-ignore">[<a href="#ref-web_2016_big-data-enthusiasts-should-not-ignore">43</a>]</span>. Logging events, caused by the user’s interactions, on the client, which then get forwarded to backend servers. Or keeping track of all kinds of transactions, which is done directly in the backend. Before running together in a designated place, all these collected chucks of data (TODO or “data points”) are getting enriched with meta information. Finally get stored and probably never removed again - all for later analyses.</p></li>
<li><p>The mindset in the <em>Big Data Community</em> is grounded on the basic assumption of <em>more data is more helpful</em>, which already is emphasised by the often-cited concept of the three <em>Vs</em> (Volume, Velocity, Variety) <span class="citation" data-cites="report_2001_3d-data-management-controlling-data-volume-velocity-and-variety">[<a href="#ref-report_2001_3d-data-management-controlling-data-volume-velocity-and-variety">44</a>]</span>. which is not entirely wrong, because it lies in the nature of pattern and correlation discovery, to provide increasing quality results <span class="citation" data-cites="paper_2015_big-data-for-development-a-review-of-promises-and-challenges:more-data">[<a href="#ref-paper_2015_big-data-for-development-a-review-of-promises-and-challenges:more-data">45</a>]</span>, while enriching the overall data with more precise data sets. But when new technologies are emerging, questioning the downsides and possible negative mid- or long-term impacts are typically not very likely to be a high priority. The focus lies on e.g. trying to to reach and eventually breach boundaries while beginning to evolve. So non-technical aspects such as privacy and security awareness doesn’t come in naturally, instead a wider range of research needs to be done alongside the evolution process and the increasing adoption rate in order to uncover such issues. Only then they can addressed properly on different levels - technical, political as well as social. So that the <em>Big Data Community</em> itself is able to evolve, too. All in all it’s a balancing act between respecting the user’s privacy and having enough data at hand to satisfy the initial questioning with the computed results. Therefore people working in such contexts need to have advanced domain knowledge, be aware of any downsides or pitfalls and need to be sensible about the ramifications of their approaches and doings. Such improvements are already happening, not only originating from the field’s forward thinkers <span class="citation" data-cites="web_2016_the-state-of-big-data">[<a href="#ref-web_2016_the-state-of-big-data">46</a>]</span>, but also advocated by governments, consumer rights organisations and even leading Tech-Companies start trying to do better <span class="citation" data-cites="web_2016_apple_customer-letter">[<a href="#ref-web_2016_apple_customer-letter">47</a>]</span> <span class="citation" data-cites="web_2016_what-is-differential-privacy">[<a href="#ref-web_2016_what-is-differential-privacy">48</a>]</span> <span class="citation" data-cites="web_2016_eff_whatsapp-rolls-out-emd-to-end-encryption">[<a href="#ref-web_2016_eff_whatsapp-rolls-out-emd-to-end-encryption">49</a>]</span> - as discussed in the section [TODO see personal data as of the law],</p></li>
<li>earlier in the text a difference was made between actively created and passively created data</li>
<li>based on that one could say <em>profile/account data</em> is actively created, because it got into the system by the user’s actively made decision to insert these information into a form and submit it - for whatever reason. whereas detecting the user’s current location and adding this information to the submitted form is <em>meta data</em></li>
<li>of cause, it is debatable whether these kind of data belongs, in the sense of being the rightful owner, to the user or to the author or owner of the software containing the code that effectively created the data.</li>
<li>maybe personal data is every data/information whose creation (or digital existence) is a direct result of user interaction/engagement?</li>
<li><p>lets have a look into what the rule book says about that –&gt; next topic (law)</p></li>
</ul>
</section>
<section id="personal-data-as-a-product" class="level2">
<h2><span class="header-section-number">3.4</span> Personal Data as a Product</h2>
<ul>
<li><em>Big Data Analytics</em> by itself just comprises a structured and technical-aided procedure, serving the purpose of finding invisible information, that might be helpful to make (right) (business) decisions. Though, if one would ask data collectors about their motivation, most likely the answer would be something along the lines of PR phrasing like <em>“We want to have a better understanding of our customers”</em>. But to do what exactly? To predict what might be the next thing I am supposed to buy Or what things I probably would like to consume but most certainly not yet know of?</li>
<li><p>Let’s take a look at some examples. An advertising service uses tracking data for targeted advertising. The more information they have about an individual, the more accurate decisions they are able to make about what ads are the ones the individual most likely will click on and disclose with a successful purchase. As a result this makes the placed advertisement more valuable for ad service and therefore more expensive to the advertisers, because of a high precision. Or a streaming provider’s content recommendation is also based on heavy user profiling done by looking at her consumption history, tracked platform interactions and probably many more vectors. Another example is <em>Google Traffic</em> <span class="citation" data-cites="web_2007_introducing-google-traffic">[<a href="#ref-web_2007_introducing-google-traffic">50</a>]</span> <span class="citation" data-cites="web_2016_wikipedia_google-traffic">[<a href="#ref-web_2016_wikipedia_google-traffic">51</a>]</span>, a service, integrated as a feature in <em>Google Maps</em>, which is Google’s web mapping service. <em>Google Traffic</em> visualises real-time traffic conditions, when using <em>Maps</em> as a navigation assistant, to provide the user with a selection of possible paths, but enriched with duration, that takes such conditions into account. The data, required to offer these information, is supplied by mobile devices, constantly sending GPS coordinates with a timestamp into Google’s infrastructure. This, however, only is made possible, because Google’s services are widely used in addition to the fact that the majority of mobile devices <span class="citation" data-cites="graphic_2016_global-mobile-os-market-share">[<a href="#ref-graphic_2016_global-mobile-os-market-share">52</a>]</span> is driven by Android, an mobile operating system developed by Google, that deeply integrates with it’s services. For this case the same assertion can be made - the more constantly streaming geo-location data, the more precise the information are about traffic conditions. Since this information demands the real-time aspect, adding time to the equation, add a other dimension of complexity to problem.</p></li>
<li><p>while the impact on our society of this first example group might be doubtable, a change of perspective opens up a different range of application areas. Such as</p>
<ul>
<li>planing and managing human resources for situations, like e.g. big events or emergency situations where attendees might need some help <span class="citation" data-cites="estimating-the-locations-of-emergency-events-from-twitter-streams_2014">[<a href="#ref-estimating-the-locations-of-emergency-events-from-twitter-streams_2014">53</a>]</span></li>
<li>predicting infrastructure workloads [TODO http://ieeexplore.ieee.org/document/7336197/]</li>
<li>making more accurate diagnostics to improve their therapy <span class="citation" data-cites="the-practice-of-predictive-analytics-in-healthcare_2013">[<a href="#ref-the-practice-of-predictive-analytics-in-healthcare_2013">54</a>]</span></li>
<li>finding patters in climate changes, which otherwise wouldn’t be detected <span class="citation" data-cites="data-collection-for-climate-changes_2014">[<a href="#ref-data-collection-for-climate-changes_2014">55</a>]</span>.</li>
</ul></li>
<li><p>Through all these examples, some of them might not necessarily founded on personal data, whereas others primarily depend on them and yet others only implicitly rely on data collected from individuals. As always, it depends on the purpose - also known as <em>business model</em> - but it seems to be consensual, that it all comes down to improving and enhancing the collector’s product in order to satisfy the customers - and that on the other hand depends on what is meant to be the product and who is seen as customers.</p></li>
<li><p>Putting a top 10 list of industries using utilizing <em>Big Data</em> <span class="citation" data-cites="graphic_2015_applications-of-big-data-in-10-industry-verticals">[<a href="#ref-graphic_2015_applications-of-big-data-in-10-industry-verticals">56</a>]</span> right next to visualization showing categories of personal data targeted by data collectors<br />
<span class="citation" data-cites="graphic_2012_personal-data-ecosystem">[<a href="#ref-graphic_2012_personal-data-ecosystem">57</a>]</span>, at least 7<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> of these industries can be identified as data collectors, whereas less then a half<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a> are taking part of being a <em>Data Broker</em>, but almost all of them are using people’s personal data, whether collected by themselves or acquired from <em>Data Broker</em>.</p></li>
<li>At this point it’s save to say, that <em>Personal Data</em> is either seen directly as a product, especially from a Dater Broker’s point of view, or indirectly due to it’s essential part in <em>Big Data</em> practices. The former generates direct revenue by selling these data and the latter might affect a business’s product quality in a positive manner and thereby increasing revenue as well.</li>
<li><p>At the end it all comes down to understanding the human being and why she behaves as she does. The challenge is not only to compute certain motives but rather concluding to the right ones. When analyzing computed results with the corresponding data models and trying to conclude, it is important to keep in mind, that correlation is by far no proof of causation.</p></li>
<li><p>individuals then get in role of selling/offering it’s own data to those who were previously collecting them</p></li>
</ul>
</section>
<section id="related-work" class="level2">
<h2><span class="header-section-number">3.5</span> Related Work</h2>
<p>The idea of a digital vault, controlled and maintained by the data subject, the individual, isn’t that new. Holding her most sensitive and valuable collections of bits and bytes, protected from all these data brokers and authorities, while interacting with the digital and physical world, opening and closing it’s door from time to time, to either put something important for her inside or retrieving an information important for someone else. While in the mid and late 2000s the growth of computer performance and capacity were crossing it’s zenith (see Moore’s Law <span class="citation" data-cites="paper_1965_moors-law">[<a href="#ref-paper_1965_moors-law">58</a>]</span>), at the same time the internet was starting to become a key part in many people’s lives and in society as a whole. Facilitated by these circumstances, <em>cloud computing</em> has been on the rise, causing the shift towards parallel distributed processing and patterns alike. Thereby making it possible to rethink solutions from the past and trying to go new ways, namely the breakthrough 2007 in <em>neuronal networks</em> cutesy of G. Hinton <span class="citation" data-cites="podcast_2015_cre-neuronale-netze">[<a href="#ref-podcast_2015_cre-neuronale-netze">59</a>]</span>. As a result, fields like <em>deep machine learning</em>, <em>big data analytics</em> and most recently <em>data mining</em>, were gaining a wide range of attention. In almost any industry a greater amount of resources is invested in these areas <span class="citation" data-cites="web_2016_industries-intention-to-invest-in-big-data">[<a href="#ref-web_2016_industries-intention-to-invest-in-big-data">60</a>]</span>.</p>
<p>The initial research motivation can be seen as a counter-movement away from the <em>cloud</em>, starting to focus again on privacy, the individual and it’s digital alter ego.</p>
<p>From simple middleware-solutions, via full-fledged software-based platforms, through embedded hardware devices, a great variety of approaches were starting to appear in the mid 2000s until this day. A side effect was, that over time various research teams and projects have invented and coined different terms, all referring to the same concept. The following list shows some examples <em>(alphabetical order)</em>:</p>
<ul>
<li>Databox</li>
<li>Identity Manager</li>
<li>Personal …
<ul>
<li>Agent</li>
<li>Container</li>
<li>Data Store/Service/Stream (PDS)</li>
<li>Data Vault</li>
<li>Information Hub</li>
<li>Information Management System (PIMS)</li>
</ul></li>
<li>Vendor Relationship Management (VRM)</li>
</ul>
<p>One of the first research projects is <em>ProjectVRM</em>, which originated from <em>Berkman Center for Internet &amp; Society</em> at <em>Harvard University</em>. As it’s name implies, it was inspired by the idea of turning the concepts of a <em>Customer Relationship Management</em> (CRM) upside down. This puts the vendor’s customers back in charge of their data priorly managed by the vendors. It also solves the problem of unintended data redundancy. Over time the project has growing to the largest and most influential in this research field. It transformed into an umbrella and hub for all kinds of projects and research related to that topic <span class="citation" data-cites="web_2016_projectvrm_development-work">[<a href="#ref-web_2016_projectvrm_development-work">61</a>]</span>, whether it’s frameworks or standards, services offering e.g. privacy protection, reference implementations, applications, software or hardware components. <em>VRM</em> became more and more a synonym for a set of principles <span class="citation" data-cites="web_2016_projectvrm_principles">[<a href="#ref-web_2016_projectvrm_principles">62</a>]</span>, including for example <em>“Customers must have control of data they generate and gather. [They] must be able to assert their own terms of engagement.”</em> These principles can be found in various ways across a lot of research done within this area.</p>
<p>Another research that is worth mentioning, because of the foundational work it has been done, is the european funded project called <em>Trusted Architecture for Securely Shared Service</em> (TAS3). The project led to a open source reference implementation called <em>ZXID</em>.<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a> The major goal was, to develop an architecture, that takes all involved parties into account, whether it’s commercial businesses (vendors) or it’s users (customers), in order to fit into more sophisticated and dynamic processes, but at the same time demanding a high level of user-centric security facilitate i.a. by a developed policy framework. Due to these requirements the architecture ended up being rather complex <span class="citation" data-cites="graphic_2011_architecture_components-of-organization-domain">[<a href="#ref-graphic_2011_architecture_components-of-organization-domain">63</a>]</span>. <em>ZXID</em> as it’s implementation incorporates several standards like SAML 2.0<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a> and XACML,<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a> has only three third-party dependencies which are <em>OpenSSL</em>, <em>cURL (libcurl)</em> and <em>zlib</em> and as of now it supports Java, PHP and Perl. The project lasted for a period of 4 years, but after it ended in 2011, the research work has pursued i.a. by the <em>Liberty Alliance Project</em>, which is now part of the <em>Kantara Initiative</em> <span class="citation" data-cites="web_kantara-initiative">[<a href="#ref-web_kantara-initiative">64</a>]</span>, including all documents and results. These results were taken up occasionally, recently from the IEEE <span class="citation" data-cites="paper_2014_personal-data-store-approach">[<a href="#ref-paper_2014_personal-data-store-approach">65</a>]</span>.</p>
<p>A research project, which is probably the closest to what this document aims to create, bears the name <em>openPDS</em> <span class="citation" data-cites="paper_2012_openpds_on-trusted-use-of-large-scale-personal-data">[<a href="#ref-paper_2012_openpds_on-trusted-use-of-large-scale-personal-data">66</a>]</span> and is done by <em>Humans Dynamics Lab</em> <span class="citation" data-cites="web_mit_openpds-safeanswers-project-page">[<a href="#ref-web_mit_openpds-safeanswers-project-page">67</a>]</span>, which is part of <em>MIT Media Laboratories</em>. Despite the usual concepts of a <em>PDS</em>, it introduces multi-platform components and user interfaces including a mobile devices and separating the persistence layer physically at the same time. This facilitates administrative tasks regardless of the data subject’s position and time. Moreover, with their idea of <em>SafeAnswers</em> <span class="citation" data-cites="paper_2014_openpds_protecting-privacy-of-meta-data-through-safeanswers">[<a href="#ref-paper_2014_openpds_protecting-privacy-of-meta-data-through-safeanswers">68</a>]</span>, the team even goes a step further. The concept behind that, is based around <em>remote code execution</em>, briefly described in <a href="#header-applying-for-a-loan-and-checking-creditworthiness">one of the user stories during the first chapter</a>. It abstracts the concept of a data request to a more human-understandable level, a simple question. This question consists of two representation: (A) a short explanation of what the data consumer wants to know and which data might be involved and thus what information a data consumer actually will receive, instead of raw data the consumer could then use for all kinds of purposes e.g. data aggregation or mining. Aside from that, the request payload also includes (B) a code-based representation, which gets executed in a sandbox on the data subjects’s <em>PDS</em> system with the necessary data as arguments. The resulting output is answer and response all in once.</p>
<p>Aside from all the research projects done within the scientific context, applications with a commercial interest were starting to occur in a variety of sectors, too. Microsoft’s HealthVault <span class="citation" data-cites="web_microsoft_healthvault">[<a href="#ref-web_microsoft_healthvault">69</a>]</span>, for example, which aims to replace all the paper-based patient medical record and combine them in one digital version. This results in a patient-centered medical data and documents archive, helping doctors to make the most accurate decisions on medical treatment.</p>
<p><em>Meeco</em> <span class="citation" data-cites="web_meeco_how-it-works">[<a href="#ref-web_meeco_how-it-works">70</a>]</span> <span class="citation" data-cites="slides_2015_meeco-case-study">[<a href="#ref-slides_2015_meeco-case-study">71</a>]</span>, based on the MyData-Project [whitepaper_2014_mydata-a-nordic-model-for-human-centered-personal-data-management-and-processing], which essentially just cuts out the advertisement service provider as a middle man inherits that role by itself. The platform does provide the data subjects with more control over what information they reveal, but it doesn’t go the so eagerly demanded next step, which would means real uncoupling from the advertisement market and finding a suitable business model that focuses on the data subject, instead of surrounding them with just another walled garden.</p>
<p>A recently announced project, sponsored by Germany’s <em>Federal Ministry of Education and Research</em>, but developed and maintained primarily by <em>Fraunhofer-Gesellschaft</em> in cooperation with several private companies like <em>PricewaterhouseCoopers AG</em>, <em>Volkswagen AG</em>, <em>thyssenkrupp AG</em> or <em>REWE Systems GmbH</em>, is the so called <em>Industrial Data Space</em> <span class="citation" data-cites="web_industrial-data-space">[<a href="#ref-web_industrial-data-space">72</a>]</span>. The project unifies both, research and commercial interests and runs over time period of three years until the third quarter of 2018. It aims to <em>“[…] to facilitate the secure exchange and easy linkage of data in business ecosystems”</em>, where at the same time <em>“[…] ensuring digital sovereignty of data owners”</em> <span class="citation" data-cites="whitepaper_2016_industrial-data-space">[<a href="#ref-whitepaper_2016_industrial-data-space">73</a>]</span>. It will be interesting to see how these two, yet rather distinct objectives, will come together in the future. Based on the white paper, the project’s focus mainly seems to lie in enabling and standardizing the way companies collect, exchange and aggregate data with each other across process chains to ensure high interoperability and accessibility.</p>
<p>Hereafter a selective list can be found of further research projects, work and commercial products regarding the issue around <em>personal data</em>:</p>
<p><strong>Research</strong></p>
<ul>
<li>Higgins [https://www.eclipse.org/higgins/]</li>
<li>Hub-of-All-Things [http://hubofallthings.com/what-is-the-hat/]</li>
<li>ownyourinfo [http://www.ownyourinfo.com]</li>
<li>PAGORA [http://www.paoga.com]</li>
<li>PRIME/PrimeLife [https://www.prime-project.eu, http://primelife.ercim.eu/]</li>
<li>databox.me (reference implementation of the <em><a href="https://github.com/solid/solid">Solid framework</a></em>)</li>
<li>Polis (greek research project from 2008) [http://polis.ee.duth.gr/Polis/index.php]</li>
</ul>
<p><strong>Organisations</strong></p>
<ul>
<li>Open Identity Exchange [http://openidentityexchange.org/resources/white-papers/]</li>
<li>Qiy Foundation [https://www.qiyfoundation.org/]</li>
</ul>
<p><strong>Commercial Products</strong></p>
<ul>
<li>MyData [https://mydatafi.wordpress.com/]</li>
<li>RESPECT network [https://www.respectnetwork.com/]</li>
<li>aWise AEGIS [http://www.ewise.com/aegis]</li>
</ul>
</section>
<section id="standards-specifications-and-related-technologies" class="level2">
<h2><span class="header-section-number">3.6</span> Standards, Specifications and related Technologies</h2>
<p>The overall attempt is to involve as much standards as possible, because it increases the chances of interoperability and thereby it lowers the effort, that might be needed, in order to integrate with third parties or other APIs. Hereinafter, some of these possible technologies will be touched on just briefly, why they might be a reasonable choice and what purposes they might going to service.</p>
<p><strong><span id="link_http">HTTP</span></strong> <span class="citation" data-cites="web_spec_http1">[<a href="#ref-web_spec_http1">74</a>]</span>, well known as the stateless <em>“transport layer”</em> for the <em>World Wide Web</em>, is most likely going to fulfill the same purpose in the context of this work, because it implements a server-client pattern in it very core. Whether internal components (local or as part of a distributed system) talk to each other or data consumers interact with the system, this protocol transfers the data hat need to be exchanged. Features introduced with Version 2 <span class="citation" data-cites="web_spec_http2">[<a href="#ref-web_spec_http2">75</a>]</span> of the protocol are yet to be known of their relevance of use cases within this project. <em>WebSockes</em> <span class="citation" data-cites="web_spec_websockets">[<a href="#ref-web_spec_websockets">76</a>]</span> might also be a possibility to communicate between components or even with external parties, which has the advantage of high efficient ongoing bidirectional connections using for real-time data exchange or remotely pending process responses, while at the same time avoiding HTTP’s long-polling abilities.</p>
<p><strong>JSON</strong><a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a> is an alternative data serialization format to XML, heavily used in web contexts to transfer data via <em>HTTP</em>, whose syntax is inspired by the JavaScript object-literal notation.</p>
<p>The open standard <strong><span id="link_oauth">OAuth</span></strong> defines a process flow for authorizing third parties to access externally hosted resources, such as the user’s profile image from a social media platform. The authorisation validation is done by the help of a previously generated token. However, generating and supplying such token can be initiated in a variety of ways depending on the already existing architecture and design, e.g. with the user entering her credentials (<code>grant_type=authorization_code</code>). This design tends <span class="citation" data-cites="web_2012_problem-with-oauth-for-authentication">[<a href="#ref-web_2012_problem-with-oauth-for-authentication">79</a>]</span> to integrate <em>OAuth</em> mistakenly but intentionally<br />
as an authentication service rather then a authorization service; regardless if as an alternative or as an addition to existing in-house solutions. Therewith the application authors pass the responsibility on to the OAuth-supporting data providers. While <em>version 1.0a</em> <span class="citation" data-cites="web_spec_oauth-1a">[<a href="#ref-web_spec_oauth-1a">80</a>]</span>, commonly seen as a protocol, provides integrity for transferred data by using signatures and confidentiality by encrypting data ahead of transfer. <em>Version 2.0</em> <span class="citation" data-cites="web_spec_oauth-2">[<a href="#ref-web_spec_oauth-2">81</a>]</span>, labeled as a framework, on the other side requires <em>TLS</em> and thus hands off the the responsibility to confidentiality to the transport layer below. It also includes certain process flows for specific platforms, such as <em>“web applications, desktop applications, mobile phones, and living room devices”</em> <span class="citation" data-cites="web_2016_oauth-2">[<a href="#ref-web_2016_oauth-2">82</a>]</span>.</p>
<p>With <strong>OpenID</strong> on the other side, the authenticity of a requesting user gets verified, which is by design. An in-depth description of the whole process can be found in the protocol’s same-titled open standard. With decentralisation kept in mind, the protocols’s nature encourages to design a distributed application architecture, similar to the idea behind <em>microservices</em>, but without owning all services involved, <em>decentralized authentication as a service</em> so to speak. An application owner doesn’t have to write or implement it’s own user management system, instead it is sufficient to just integrate these parts from the standard need to support signing in with <em>OpenID</em>. Equally the user is not required to register a new account whenever it is necessary, instead she can use her <em>OpenID</em>, already created by another identity provider, to authenticate with the application. The extension <em>OpenID Attribute Exchange</em> allows to import additional profile data. <em>OpenID Connect</em> <span class="citation" data-cites="web_spec_openid-connect-1">[<a href="#ref-web_spec_openid-connect-1">83</a>]</span> is the third iteration of the OpenID technology. <em>Connect</em> is to OpenID what <em>facebook connect</em> is to <em>facebook</em>, except for the additional authentication layer, which is build upon <em>OAuth2.0</em> and JWT. It therefore enables, aside from authorisation mechanisms, third parties to authenticate an OpenID-user and makes certain data available about that account via REST interface.</p>
<p>If it’s necessary for certain components, as part of a distributed software, to make them stateless, apart from changing the architecture so that the state at that point is not needed anymore, the only other option would be to carry the state along (TODO: or “passing the state around”). This is a common use case for a <strong><span id="link_jwt">JSON Web Token</span></strong> <em>(JWT)</em> <span class="citation" data-cites="web_spec_json-web-token">[<a href="#ref-web_spec_json-web-token">84</a>]</span>. A <em>JWT</em>, as it’s name implies, is syntactically speaking formatted as <em>JSON</em>, but URI-safe into <em>Base64</em> encoded, before it gets transferred. The token itself holds the state. Here is where the use of <em>HTTP</em> comes in handy, because the token can be stored within the HTTP header and therefore can be passed through all communication points, where then certain data could be readout and therewith get verified. Such a token typically consists of three parts: information about itself, a payload, which can be arbitrary data such as user or state information, and a signature; all separated with a period. Additional standards define encryption <em>(JWE<a href="#fn12" class="footnoteRef" id="fnref12"><sup>12</sup></a>)</em> to ensure confidentiality and signatures <em>(JWS<a href="#fn13" class="footnoteRef" id="fnref13"><sup>13</sup></a>)</em> to preserve integrity of it’s contents. Using a <em>JWT</em> for authentication purposes is described as <em>stateless authentication</em>, because the verifying entity doesn’t need to be aware of session IDs nor any information about a state. So instead of the backend interface being constrained to check a state (<code>isLoggedIn(sessionId)</code> or <code>isAuthorized(sessionId)</code>) on every incoming request in order to verify permissions, it just needs</p>
<p>When transferring data over a potential non-private channel several properties might be desired, which eventually provide an overall trust to that data. One important aspect might me, that no one else expect sender and receiver are able to know and see what the actual data is. To achieve this, <strong>Symmetrical Cryptography</strong> is used for. It states that the sender encrypts the data with the help of a key and the receiver decrypts that data also with that key. That is, sender and receiver, both need to know that one key, but everyone else should not . To agree on a key without compromising the key during that process, both entities either change the medium (e.g meet physically and exchange) or have to use a procedure, in which at any point in time the entire key is not exposed to others then sender and receiver. This procedure is called <strong>Diffie-Hellman-Key-Exchange</strong> <span class="citation" data-cites="paper_1976_d-h-key-exchange">[<a href="#ref-paper_1976_d-h-key-exchange">87</a>]</span> and is based on rules for modulo operations when prime numbers are involved. It is designed with the goal to agree on a <em>secret</em> while at the same time using a non-private channel. The data exchanged during the process alone can’t be used to deduce the secret. Such behaviour is similar to the concepts of <strong><span id="link_asym-crypto">Asymmetrical Cryptography</span></strong> <em>(or public-key cryptography)</em> <span class="citation" data-cites="book_2014_chapter-9-1-public-key-crypto">[<a href="#ref-book_2014_chapter-9-1-public-key-crypto">88</a>]</span>, which is underpinned by a <em>key-pair</em>; one key is <em>public</em> and the other one is <em>private</em>. Depending on which of keys is used to <em>encrypt</em> the data, only the other one can be used for <em>decrypting</em> the cipher. If then this technology gets combined with the concept of digital signatures (encrypted fingerprints from data), together it would provide integrity and authentication.</p>
<p>Wrapping <em>HTTP</em> in the <em>Transport Layer Security</em> <span class="citation" data-cites="web_spec_tls">[<a href="#ref-web_spec_tls">89</a>]</span> (<em>TLS</em>) results in <strong>HTTPS</strong>. TLS provides encryption during the data transport, which reduces the vulnerability to <em>man-in-the-middle</em> attacks and thus ensures not only confidentiality but data integrity as well. <em>Asymmetric cryptography</em> is the foundation for the connection establishment, hence <em>TLS</em> also allows to verify integrity of the entity on the the connection’s counterside, and, depending on the integration, it could even be used for authentication purposes. But relying on those cryptographical concepts requires additional infrastructure. Such an infrastructure is known as <em>Public Key Infrastructure</em> (or <em>PKI</em>) <span class="citation" data-cites="book_2014_chapter-14-5-pki">[<a href="#ref-book_2014_chapter-14-5-pki">90</a>]</span>. It manages and provides public keys in a directory, including related information to the owners of these certificates. A Certificate Authority (or <em>CA</em>), as part of that infrastructure, issues, maintains and revokes digital certificates. The infrastructure that is needed to provide secure HTTP connections for the internet is one of those <em>PKI</em>s - a public one and probably the largest. It is based on the widely used IETF<a href="#fn14" class="footnoteRef" id="fnref14"><sup>14</sup></a> standard <em>X.509</em> <span class="citation" data-cites="web_spec_x509">[<a href="#ref-web_spec_x509">91</a>]</span>.</p>
<p><strong>REST(ful)</strong><a href="#fn15" class="footnoteRef" id="fnref15"><sup>15</sup></a> is a common set of principles to design web resources communication, primarily server-client relations, in a more generic and thereby interoperable way. Aside from hierarchically structured URIs, which reflect semantic meanings, it involves a group of rudimentary vocabulary<a href="#fn16" class="footnoteRef" id="fnref16"><sup>16</sup></a> to provide basic Create-Read-Update-Delete operations across distributed systems. The entire request need to contain everything that is required to get proceeded, e.g. state data and possibly authentication. These operation normally wont get applied directly to the responsible component. Instead the whole system (or certain services) exposes a restful API, with which a third party can then interact.</p>
<p>The <em>QL</em> in <strong><span id="link-graphql">GraphQL</span></strong> <span class="citation" data-cites="web_spec_graphql">[<a href="#ref-web_spec_graphql">94</a>]</span> stands for <em>query language</em>. Developed by Facebook Inc., it’s goal is to abstract multiple data sources into a unified API or resource, so that different storage technologies are seamlessly queryable without using it’s native <em>QL</em>. The result is provided in a JSON format, which naturally supports graph-like data structures. This is utilized in GraphQL and implicitly embraced through it’s purpose of abstraction. Data points that might be somehow related but stored in different locations, can be obtained so that both end up in the same object through which they are related, or indirectly linked, to each other. The shape of a query is later mirrored by the result. GraphQL not only is an abstraction layer by itself, it also moved almost any operations and flow controls into an additional layer. This so called <em>GraphQL</em> server is then responsible for resolving and executing queries.</p>
<p>The term <strong><span id="link-semantic-web">Semantic Web</span></strong> bundles a conglomerate of standards released by the W3C,<a href="#fn17" class="footnoteRef" id="fnref17"><sup>17</sup></a> that is based around an idea called <em>web of data</em>, which aims to <em>“allow data being shared and reused across”</em> [web_2016_w3c_semantic-web-activity]. Those standards address syntax, schemas, formats, access control and integrations for several scopes and contexts. Among others, the following three technologies are essential for the <em>Semantic Web</em>. RDF<a href="#fn18" class="footnoteRef" id="fnref18"><sup>18</sup></a> basically defines the syntax. OWL<a href="#fn19" class="footnoteRef" id="fnref19"><sup>19</sup></a> provides the guidelines on how the semantics and schemas should be defined and with <span id="link-sparql">SPARQL</span> <span class="citation" data-cites="web_w3c-tr_sparql">[<a href="#ref-web_w3c-tr_sparql">97</a>]</span>, the query language, data can be retrieved. One could not help but picture the web as a database, queryable data with URIs that is embedded in arbitrary websites. For example, a person’s email address, which is available under a specific domain (preferably owned by that person) - or to be more precise, a URI <em>(WebID) <span class="citation" data-cites="web_w3c-draft_webid">[<a href="#ref-web_w3c-draft_webid">98</a>]</span></em> - provided in a certain syntax <em>(RDF)</em> and tagged with the semantic <em>(OWL)</em> of a email address, all together embedded in an imprint of a website. This information can then be queried <em>(SPARQL)</em>, if the URI that works as a unique identifier, is known. While defining the standards, a main focus was to design a syntax, that is at the same time valid markup. The vision behind this: embracing the concept of a single source of truth and embedding or linking data points rather then creating instances, which might only be valid at that point in time, in short preventing redundant work. Related to the <em>Semantic Web</em> is the a project called <strong>Solid</strong>.<a href="#fn20" class="footnoteRef" id="fnref20"><sup>20</sup></a> Based on the <em>Linked Data</em> principles and backed the <em>WebAccessControl</em> <span class="citation" data-cites="web_2016_wiki_webaccesscontrol">[<a href="#ref-web_2016_wiki_webaccesscontrol">100</a>]</span> system and the standards just mentioned, that project focuses on decentralization and personal data. A reference implementation called <em>databox</em> <span class="citation" data-cites="web_2016_demo_databox">[<a href="#ref-web_2016_demo_databox">101</a>]</span> combines all these technologies and is build on top of the.</p>
<p>The concept of application (or software) <strong><span id="link-container">container</span></strong> is about encapsulating runtime environments by introducing an additional layer of abstraction. A container bundles just the software dependencies (e.g. binaries) that are absolutely necessary so that the enclosed program is able to run properly. The actual container separation is done, aside from others, with the help of two features provided by the Linux kernel. <em>Cgroups</em>,<a href="#fn21" class="footnoteRef" id="fnref21"><sup>21</sup></a> which define or restrict how much of the existing resources a group of processes (e.g. CPU, memory or network) can use. Whereas <em>namespaces</em> <span class="citation" data-cites="web_2016_kernel-namespace">[<a href="#ref-web_2016_kernel-namespace">103</a>]</span> define or restrict what parts of the system can be accessed or seen by a process (e.g. filesystem, user, other processes). The idea of encapsulating programs from the operating system-level is not new, Technologies, such as <em>libvirt</em>, <em>systemd-nspawn</em>, <em>jails</em>, or <em>hypervisors</em> (e.g. VMware, KVM, virtualbox) have been used for years, but were usually too cumbersome and never reached a great level of convenience, so that only people with a certain expertise were able to handle systems build upon virtualization, but people with other backgrounds couldn’t and weren’t that much interested. Until <em>Docker</em> and <em>rkt</em> emerged. After some years of separated work, both authors, and others, recently joined forces in the <em>Open Container Initiative</em> <span class="citation" data-cites="web_2016_open-container-initiative">[<a href="#ref-web_2016_open-container-initiative">104</a>]</span>, which aims to harmonize the diverged landscape and start building common ground to ensure a higher interoperability, and that in turn is requisite for orchestration. It also marks the initial draft of the specifications for runtime <span class="citation" data-cites="web_oci-spec_runtime">[<a href="#ref-web_oci-spec_runtime">105</a>]</span> and image <span class="citation" data-cites="web_oci-spec_image">[<a href="#ref-web_oci-spec_image">106</a>]</span> definition, on which the work is still ongoing. This concept of <em>containerization</em> also inherits the a ability known from <em>emulation</em>, because it allows a certain set of software to run on a system that otherwise is not supported, e.g. mobile devices. It only requires the runtime to be working.</p>
<p>In the past years different countries around the world started to introduce <em>information technology</em> to the day-to-day processes, interactions and communications between public services and their citizens, for example changing residence information or filing tax report, which is summarized under the term <em>E-government</em>.<a href="#fn22" class="footnoteRef" id="fnref22"><sup>22</sup></a> One of those developments is the so called <strong>Electronic ID Card</strong>{#link_eid-card}, hereinafter called <em>eID card</em>. Equipped with storage, logic and interfaces for wireless communication, those <em>eID cards</em> can be used to store certain information and digital keys or to authenticate the owner electronically to a third party without being physically present. Such an <em>eID card</em> was also introduced in Germany in 2010. The so called <em>nPA</em><a href="#fn23" class="footnoteRef" id="fnref23"><sup>23</sup></a> was an important step towards an operational <em>e-government</em>. Aside from minor flaws <span class="citation" data-cites="web_2013_npa-sicherheitsdefizit">[<a href="#ref-web_2013_npa-sicherheitsdefizit">107</a>]</span> and disadvantages <span class="citation" data-cites="web_2014_test-qes-support-in-npa">[<a href="#ref-web_2014_test-qes-support-in-npa">108</a>]</span> an <em>eID card</em> can come with, the question here is, how can such technology be usefully integrated in this project and does it even makes sense. As an official document the card has one major advantage over selfconfigured or generated authentication mechanisms like passwords, fingerprints or TANs.<a href="#fn24" class="footnoteRef" id="fnref24"><sup>24</sup></a> It is <em>signed</em> by design, which means, by creating this document and handing it over to the related citizen, the third party (or <em>“authority”</em>) - in this case the government - has verified the authenticity of that individual.</p>
<p>When communication via email it is already common to encrypted the transport channel, but using <em>asymmetric cryptography</em> for encrypting emails end-to-end is rather unusual. The equivalent to a <em>PKI</em> would be basically a <em>public key server</em> that follows a concept called <em>web of trust</em>. In which all entities (user; senders and recipients) are signing each other’s public keys. The more users have signed a public key, the higher the trust that this key actually belongs to the user that it says it does. That public key is then simply uploaded by the owner to public servers where another user, who wants to write that key owner an email can obtain keys. Related to that topic, another technology emerging as part of the <em>e-government</em> development, is the german <strong>De-Mail</strong> <span class="citation" data-cites="web_2017_about-de-mail">[<a href="#ref-web_2017_about-de-mail">109</a>]</span>. It’s an eMail-Service that is meant to provide infrastructure and mechanisms to exchange legally binding electronic documents. One would expect a <em>public key cryptography</em>-based implementation all the way from sender through to the recipient <span class="citation" data-cites="statement_2013_de-mail">[<a href="#ref-statement_2013_de-mail">110</a>]</span>, maybe even with taking advantage of the <em>nPA’s</em> capability to create <em>QES</em>, which refers to the ability of using the <em>nPA</em> to sign arbitrary data. Instead, the creators of the corresponding law decided that it’s enough to prove the author’s identity if the provider signs the document on the email server and that this implementation results in a legally binding document by definition of that law.</p>
</section>
</section>
<section id="core-principles" class="level1">
<h1><span class="header-section-number">4</span> Core Principles</h1>
<p>Right from the start a set of principles have build the cornerstones and orientation marks of the idea behind the <em>PDaaS</em>. Those, who meant to be reflected also by the arising <em>Open Specification</em>, will be explained further within the following sections.</p>
<section id="data-ownership" class="level2">
<h2><span class="header-section-number">4.2</span> Data Ownership</h2>
<p>Depending on the standpoint, the question about ownership of certain data might not that trivial to answer. As stated in the <a href="#digital-identity-personal-data-and-ownership">previous section</a>, ownership requires a certain amount of originality to become intellectual property, which is not the case for personal data - at least for all the non-creative content. Thus there is no legal ground for an individual to license those data, that obviously belongs to her. Switching the perspective from the <em>data subject</em> to the data <em>consumer</em>; for them, several laws exist addressing conditions and rules regarding data acquisition, processing and usage. Leaving aside the absence of any legislation regarding data ownership, it cannot be denied, that is seems unnatural not being the owner of all the data that reflects her identity and her as an individual. So instead of defining those rules meant to protect data subjects, but demanding data consumers to comply with, the proposal here is to put the entity, to whom the data is related to, in control of defining, who can access her data and what accessor is allowed to do with it. This would make the <em>data subject</em>, <a href="#def-ownership">per definition</a> and effectively to the owner of those data. Although, it is to be noted, that the legal rulebook for data consumers mentioned before, remains a highly important, since this project is not able to cover every use case, that might occur.</p>
<p>Promoted from the data subject to the data owner, hence being the center of the <em>PDaaS</em>, the operator gains abilities to have as much control as possible over all the data related to her, to determine in a very precise way what data of hers can be accessed by third parties at any point in time and to literally carry all her personal data with her.</p>
</section>
<section id="identity-verification" class="level2">
<h2><span class="header-section-number">4.3</span> Identity Verification</h2>
<p>When an instance of this system is going to be the digital counterpart of an individuals identity or it’s <em>personal agent</em> <span class="citation" data-cites="book_2015_ethical-it-innovation">[<a href="#ref-book_2015_ethical-it-innovation">111</a>]</span>, then everyone who relies on the information that agent is providing, must as well be able to trust the source from where that data is coming from and vice versa; the <em>operator</em> too must be able to verify the authenticity of the requesting source; regardless if it’s the initial <em>permission request</em> or further <em>access attempts</em>. Based on these mechanisms, the system can also provide an authentication services to all sorts of generic or restricted platforms for the associated identity, including second factor abilities.</p>
</section>
<section id="reliable-data" class="level2">
<h2><span class="header-section-number">4.4</span> Reliable Data</h2>
<p>Being able to verify the authenticity of a communication partner means only to be half-way through. Data consumers also need to trust the data itself, which is attributed to the following properties.</p>
<ol type="A">
<li><em>integrity</em> - which means the recipient can verify, that the data, sent to her, is still the same, or if someone has tampered with the obtained data. (B) <em>authenticity</em> - it is somehow ensured, or the recipient must be certain, that the received data belongs to the individual from whom the data comes from. A negative result of that check should not cause a termination of the process, but instead should warn the recipient about the lack of authenticity, so that she, herself, can decide if and how to proceed.</li>
</ol>
</section>
<section id="authorisation" class="level2">
<h2><span class="header-section-number">4.5</span> Authorisation</h2>
<p>Controlling it’s own data might probably be the most important ability of such a system, because the data owner gets enabled to grant permission to any entity who want to obtain certain information about her in a semi-automated way. She can authorise as precise as desired how long and what data (sets, points or fields) is accessible by a single entity. Thereby, the data owner is able to change the <em>access permissions</em> for any entity at any point in time, for example motivated by a noticed incident.</p>
</section>
<section id="supervised-data-access" class="level2">
<h2><span class="header-section-number">4.6</span> Supervised Data Access</h2>
<p>Rules and constraints might be one way to handle <em>personal data</em> demands of <em>third parties</em>. But this plain <em>query and response data</em> approach could be replaced by a more supervised concept, that prevents data from leaving the system. It allows to execute a small program within a locally defined environment, computing only a fraction of a larger computation that was initiated by the <em>data consumer</em> beforehand; similar to a distributed Map-Reduce concept <span class="citation" data-cites="paper_2004_distributed-mapreduce">[<a href="#ref-paper_2004_distributed-mapreduce">112</a>]</span>. The opposite approach, to provide some software to the <em>data consumer</em> that is necessary to access the contents of a response or provides a runtime environment querying the system by itself, would be conceivable as well. In general, it is not very likely that <em>data consumers</em>, who already got granted certain access, would renounce their privileges. Thus it is vital that the <em>data owner</em> is the one who is able of cancel the <em>access permissions</em> or applying appropriate changes. Supervising methods provide an appropriate ways to make data available to those who are eager to consume them.</p>
</section>
<section id="containerization" class="level2">
<h2><span class="header-section-number">4.7</span> Containerization</h2>
<p>Abstracting an operating system by moving the bare minimum of required parts into a virtualization results into an environment that can be, depending on the configuration, fully encapsulate it’s internals from the host environment. This approach yields to some valuable features. Such as:</p>
<ol type="A">
<li>Effortless portability, which reduces the requirements on environment and hardware to a minimum.</li>
<li>Thereby gaining higher flexibility in placing components, through which advantages can be made out of other devices characteristics. while not necessarily increasing the overall complexity of the system</li>
<li>Isolation and reduction of shared spaces and scopes, which for example can prevent side effects.<br />
All these in conjunction lead also to an overall security improvement or at least it enables new patterns to improve such aspects. Furthermore, it allows to suit more versatile and diverse scenarios, like storing data about a using data, providing sensitive profile data or getting used as a medical record. The convenience of a precise resource assignment might also become relevant for case where device’s hardware specification might be somewhat low. Building a system upon a container-based philosophy and enclosing components in their own environment brings a variety of design and architectural possibilities without the necessity of increasing the overall system complexity.</li>
</ol>
</section>
<section id="open-development" class="level2">
<h2><span class="header-section-number">4.8</span> Open Development</h2>
<p>When developing an <em>Open Specification</em> it only comes natural to build upon open technologies, which are understand as <em>open standards</em> and <em>open source</em>; <em>open</em> in the sense of <em>unrestricted accessible by everybody</em> and not to be confused with free - as in <em>freedom</em> - software. Advocating such a philosophy permits not only to develop implementations in a collaborative way, but enables<br />
also to work fully transparent on the specification itself. Such an open environment makes it possible for anyone who is interested, to participate or even to contribute to the project. Thus, to lower the barrier, usable and meaningful documentation is vital. Such an openness ensures the possibility of looking into the source code and getting a picture of what the program actually does and how it works. Thus, source code reviews become possible as well. Those might reveal certain security flaws, which then are able to get fixed very quickly. Furthermore, this approach allows data subjects to setup their own infrastructure and host such a system, which gains even more control over the data and increases the level of trust, instead of using a <em>SaaS</em><a href="#fn25" class="footnoteRef" id="fnref25"><sup>25</sup></a> solution that is host by another provider. It also encourages any kind of adjustments or customization to the system in order to serve the own’s needs. Enabling an open development allows users and contributors working together and thus improve the outcome in a variety of ways.</p>
</section>
</section>
<section id="requirements" class="level1">
<h1><span class="header-section-number">5</span> Requirements</h1>
<p>Derived from the <a href="#core-principles">Core Principles</a>, the subsequent requirements shall be served as a list of features on the one hand, to get an idea about how the open specification and thus the resulting software might look like, and to give an overview about priorities (can/could, may/might, should, must/have to) on the other hand. Other chapters may contain specific references to the requirements listed below.</p>
<section id="architecture-design" class="level4">
<h4><span class="header-section-number">5.1.1.1</span> Architecture &amp; Design:</h4>
<p><strong><em><span id="sa01">S.A.01</span></em> - Accessibility &amp; Compatibility</strong><br />
Since the internet is one of the most widely used infrastructure for data transfer and communication, it is assumed that all common platforms support underlying technologies, such as HTTP and TLS. Thus the emerging system should implement a web service, who provides supervised access to personal data.</p>
<p><strong><em><span id="sa02">S.A.02</span></em> - Portability</strong><br />
All major components should be designed and communicate between each other in a way to be able to get relocated while the system has to remain fully functional. It has to be possible to build a distributed system, that may require to place certain components into different environments/devices.</p>
<p><strong><em><span id="sa03">S.A.03</span></em> - Roles</strong><br />
The system has to define two types of roles. The first one is the <a href="#terminologies--operator">operator</a>, who is in control of the system and, depending on the architecture, must be at least on individual but can be more. The operator takes care of all the data that then get’s provided and decides about which third party get’s access to what data. The second type are the <a href="#terminologies--consumer">consumers</a>. These are external third parties that desire certain data about or from the operator. (see <a href="#terminologies">Terminologies</a>)</p>
<p><strong><em><span id="sa04">S.A.04</span></em> - Authenticity</strong><br />
Since they have to rely on the data, both entities - everyone who belongs to one of the <em><a href="#sa03">roles</a></em> - have to be able to ensure the authenticity of their identity and the data they are sending to the opponent. It should be possible to opt out to that level of reliability, if is not necessary, or to opt-in for certain aspects. However, if one of the parties demanding the other one of providing such level, but the other doesn’t, then the access attempt has to fail.</p>
<p><strong><em><span id="sa05">S.A.05</span></em> - Availability</strong><br />
When third parties are requesting data, it is very likely that those procedures are triggered automatically or at least machine-supported, hence those requests can arrive at the <em>PDaaS</em> at any point in time. Therefore the <em>PDaaS</em>, or at least parts of it, should to be available all the time. Even if the request won’t get proceeded completely, the <em>data subject</em> can still be informed about that event; a bit like an answering machine. This also enhances the <em>PDaaS</em> as a serious and reliable data source. It also relates to the topic of <em>failure safety and redundancy</em>.</p>
</section>
<section id="persistence" class="level4">
<h4><span class="header-section-number">5.1.1.2</span> Persistence:</h4>
<p><strong><em><span id="sp01">S.P.01</span></em> - Data Outflow</strong><br />
Data may only leave the system if it’s absolutely necessary and no other option exists to preserve the goal of that process. But if data still has to get transferred, no other than the data consumer must be able to access the data. Confidentiality has to be preserved at all cost.</p>
<p><strong><em><span id="sp02">S.P.02</span></em> - Data Relationship</strong><br />
Data structures and data models must show high flexibility and may not consist of strong relations and serration.</p>
<p><strong><em><span id="sp03">S.P.03</span></em> - Schema and Structure</strong><br />
The <em>Operator</em> can create new data types (based on a schema) in order to extend the capabilities of the data API. Structures and schemas can change over time (<a href="#sp04">S.P.04</a>). Every data set and data point has to relate to a corresponding and existing type, whether it’s a simple type (string, integer, boolean, etc.) or a structured composition based on a schema.</p>
<p><strong><em><span id="sp04">S.P.04</span></em> - Write</strong><br />
Primarily the operator is the only one who has the permissions to add, change or remove data. This is done either by using the appropriate forms provided by visual user interface or import mechanisms. The latter could be enabled through (A) support for file upload containing supported formats, (B) data API restricted to the operator or (C) defining an external source reachable via http (e.g. <em>RESTful URI</em>) in order to (semi-)automate additional an ongoing data import from multiple data sources (e.g. IoT, browser plugin). Additionally, it might be possible in the future to allow <em>data consumers</em> letting some data to flow back into the operator’s system, after she is certain about it’s validity and usefulness.</p>
<p><strong><em><span id="sp05">S.P.05</span></em> - Data Redundancy</strong><br />
Providing and managing data is the core task here. Hence the system needs to make backups or at least provide mechanisms and tool for the <em>operator</em> to do that. Different strategies are conceivable, but have to respect related requirements (<a href="#sp01">S.P.01</a>, <a href="#sa03">S.A.03</a>) and specific environment conditions though. The least feasible solution would be a manual backup only allowed by the <em>operator</em>.</p>
</section>
<section id="interfaces" class="level4">
<h4><span class="header-section-number">5.1.1.3</span> Interfaces:</h4>
<p><strong><em><span id="si01">S.I.01</span></em> - Documentation</strong><br />
The interfaces of all components have to be documented; in a way that the components themselves can be replaced without any impact to the rest of the system. This also involves comprehensive information on how to communicate and what endpoints are provided, including required arguments and result structure.</p>
<p><strong><em><span id="si02">S.I.02</span></em> - External Data Query</strong><br />
Data consumer can request a schema, in order to know how the response data will actually look like, since certain parts of the data structure might change over time (see <a href="#sp03">S.P.03</a>, <a href="#sp04">S.P.04</a>). After checking if the access request is permitted, the system first parses and validates the query and eventually proceeds to actually execute the included query. When querying data from the system, the <em>data consumer</em> might be required tp provide a schema, which should force him to be as precise as possible about what data is exactly needed. In addition to that, the consuming entity must provide some <em>meaningful</em> text, describing the purpose of the requested data. He should not be allowed to place wildcard selectors for data points in the query. Instead he must always define a more specific filter or a maximum number of items, if the query retrieves more then one element.</p>
<p><strong><em><span id="si03">S.I.03</span></em> - Formats</strong><br />
When components communicating between each other or interactions with the system from the outside take place, all data send back and forth should be serialized/structured in a JSON or JSON-like structure.</p>
</section>
<section id="visual-user-interface" class="level4">
<h4><span class="header-section-number">5.1.1.4</span> Visual User Interface:</h4>
<p><strong><em><span id="pviu01">P.VIU.01</span></em> - Responsive user interface</strong><br />
The visual user interface has to be responsive to the available space, because of the diversity of screen sizes nowadays.</p>
<p><strong><em><span id="pviu02">P.VIU.02</span></em> - Platform support</strong><br />
The user interface must be at least implemented based on web technologies, that is provided by a server and is thus available on any platform that comes with a modern browser. To enable additional features and behavior, at least for mobile devices it is recommended to build a user interface upon native supported technologies, such as <em>Swift</em> and <em>Java</em>. The operator would benefit from capabilities such as <em>push notifications</em> and storing data on that device.</p>
<p><strong><em><span id="pviu03">P.VIU.03</span></em> - Permission Profiles</strong><br />
The operator should be capable of filtering, sorting and searching through the list of <em>access profiles</em>; for a better administration experience and to easily find certain entries while the overall amount increases over time.</p>
<p><strong><em><span id="pviu04">P.VIU.04</span></em> - Access History</strong>  The operator must be provided with a list of all past permission requests and data accesses, in order to monitor who is accessing what data and when, and thus being capable of evaluating and eventually stopping certain access and data usage. This tool should have filter, search and sort capabilities. It is build upon and therefore requires the <a href="#pb01">access logging</a> functionality.</p>
</section>
<section id="interactions" class="level4">
<h4><span class="header-section-number">5.1.1.5</span> Interactions:</h4>
<p><strong><em><span id="pi01">P.I.01</span></em> - Effort</strong><br />
Common interactions processes, like changing <em>profile data</em>, importing data sets or manage <em>permission request</em> have to require as little effort as possible. This means short UI response time on the one hand and as less single input and interaction steps as possible to complete a task. Given these circumstances, the <em>permission request review</em> and <em>permission profile creation</em> might become a special challenge.</p>
<p><strong><em><span id="pi02">P.I.02</span></em> - Design</strong><br />
The visual user interface must be designed and structured in such a way that is is highly intuitive for the user to operate. Thus, it is important e.g. to use meaningful icons and appropriate labels. It also means a flat and not crammed menu navigation. Context related interaction elements should be positioned within the area designated for that context. TODO: maybe emphasize more UI aspects (or not)</p>
<p><strong><em><span id="pi03">P.I.03</span></em> - Notifications</strong><br />
The user should be notified about every interaction with the <em>PDaaS</em> originated by a third party immediately after it’s occurrence, but she must get notified at least about every <em>permission request</em>. This behaviour should be configurable; depending on the <em>permission type</em> and on every <em>permission profile</em>. Regardless of the configuration the notifications themselves must show up and pending user interactions must be indicated in the user interface.</p>
<p><strong><em><span id="pi04">P.I.04</span></em> - Permission Request &amp; Review</strong><br />
A process involving data transaction must always be initiated by the data subjects. So before a <em>data consumer</em> is able to access data, first the <em>operator</em> need to <em>invite</em> him and tell him whereto address his requests. This has to be done by sending him a URI leading to an endpoint, that needs to be unique among all <em>data consumers</em> interacting with the same instance of the system. When a <em>data consumer</em> makes the first attempt to connect to the system, it must be a well formed <em>permission request</em>, which has to include information about the <em>consumer</em>, what data he wants to get access to, for what purpose and how log or how often the data need to be requested. The operator then reviews these information and creates an <em>permission profile</em> based on that information. A key configuration in such a profile has to be what defines when this permission expires. The operator should be able to decide between three <em>permission types</em>:</p>
<ul>
<li><em>one-time-only</em></li>
<li><em>expires-on-date</em></li>
<li><em>until-further-notice</em> After creating the profile, a response must be send to the <em>data consumer</em>, which should contain the review result and permission type set by the operator.</li>
</ul>
<p><strong><em><span id="pi05">P.I.05</span></em> - Templating</strong><br />
The operator should be able to create templates for <em>permission profiles</em> nad <em>permission rules</em> in order to (A) apply a set of configuration in advance before the <em>permission request</em> arrives and</p>
<ol start="2" type="A">
<li>reduce recurring redundant configurations.</li>
</ol>
</section>
<section id="behaviour" class="level4">
<h4><span class="header-section-number">5.1.1.6</span> Behaviour:</h4>
<p><strong><em><span id="pb01">P.B.01</span></em> - Access Logging</strong><br />
All interactions and changes in the persistence layer should be logged. At least all data request must be logged. Such log is the foundation of the <em>access history</em>, with this the user is able to keep track of and look up past accesses.</p>
<p><strong><em><span id="pb02">P.B.02</span></em> - Real time</strong><br />
Real time communication might be essential for time-critical data transaction. Hence at least one user interfaces should be connected to the server through an ongoing connection to enable real time support (example scenario: permission request got reviewed on mobile device, but notification indicator reflects “still pending”). But if just one client is associated to the system, real time (in the sense of keeping UI state up to date) would not be necessary. (see <a href="#pviu02%7D">P.VIU.02</a>)</p>
</section>
</section>
<section id="design-discussion" class="level1">
<h1><span class="header-section-number">6</span> Design Discussion</h1>
<p>The following chapter documents the processes of some design decision makings, examines possible issues emerging alongside and discuses different solutions obtained from several perspectives in order to evaluate their advantages and disadvantages. Probably not every issue will get it’s<br />
deserved room, but major aspects will be addressed. In short, the majority of the project’s conceptual work is done below.</p>
<p>The end of every subchapter includes a section containing a summary of conclusions, which is based on the prior discussions related to that topic.</p>
<section id="authentication" class="level2">
<h2><span class="header-section-number">6.2</span> Authentication</h2>
<p>First of all, the system has to support two <a href="#sa03">roles</a>. Any entity can be assigned to either one of them, hence entities that are trying to authenticate to the system might have different intentions. The <em>operator</em> for example wants to review <em>permission requests</em> in real time, so accessing the system from different devices is a common scenario. When inheriting the <em>operator role</em> an entity gains further capabilities to interact with the system, such as data manipulation. Whereas a <em>data consumer</em> always uses just one origin and processes requests sequentially. Those very distinct groups of scenarios would make it possible to apply different authentication mechanisms that do not necessarily have a lot in common.</p>
<p>With respect to the requirements (<a href="#sa01">S.A.01</a>), the most appropriate way to communicate with the <em>PDaaS</em> over the internet would be by using <em><a href="#link_http">HTTP</a></em>. Furthermore, to preserve confidentiality on every in- and outgoing data (<a href="#sp01">S.P.01</a>) the most convenient solution is to use <em>HTTP</em> on top of <em>TLS</em>. <em>TLS</em> relies i.a. on <a href="#link_asym-crypto">asymmetric cryptography</a>. During the connection establishment the initial handshake requires a certificate, issued and signed by a CA, which has to be provided by the server. This ensures at the same time a seasonable level of identity authentication, almost effortless. If the certificate is not installed, it can be installed manually on the client. If the certificate is not trusted (e.g. it is self-signed), it can either be ignored or the process fails to establish a connection, depending on the server configurations. The identity verification in TLS works in both directions, which means not only the client has to verify the server’s identity by checking the certificate. If the server insists on, the client has to provide a certificate as well, which then the server tries to verify. Only if the outcome is positive, the connection establishing succeeds. According to the specification <span class="citation" data-cites="web_spec_tls-12_client-auth">[<a href="#ref-web_spec_tls-12_client-auth">113</a>]</span> it is still optional though.</p>
<p><em>HTTP</em> as a comprehensive and flexible protocol enables to use several technologies for server-client authentication purposes. Some of them are build-in, others can simply be implemented on top of the protocol. Within the scope of this work, those technologies are categorized in the following types (TODO: maybe find other labels): (A) stateful and (B) stateless authentication. The first one (A) includes vor example <em>Basic access Authentication</em> (or <em>Basic Auth</em>) and authentication based on <em>Cookies</em>. Whereas the <em>two-way authentication</em> in TLS mentioned above and <a href="#link_jwt">authentication based on web-token</a> are associated with the latter (B). <em>Basic Auth</em> is natively provided by the <em>http-agent</em> and requires in it’s original form (<em>user:password</em>) some sort of state on the server; at least when the system has to provide multitenancy. If instead just a general access restriction for certain requests would suffice, no state is required. One of the most common implementations of user-specific states is a <em>session</em> on the server, that contains one or more values representing the state and a unique identifier, by which an entity can be associated with. A client has to provide that session ID in order to get provided with all the session-related data hold by the server. This is typically done in a HTTP header, whether as <em>Basic Auth</em> value, a <em>Cookie</em>, which is domain-specific, or in some other custom header. Since the <em>two-way authentication</em> (or <em>mutual authentication</em> <span class="citation" data-cites="web_2017_wikipedia_mutual-auth">[<a href="#ref-web_2017_wikipedia_mutual-auth">114</a>]</span>) is done based on files containing keys and certificates, which are typically not very fluctuant in it’s contents or state, this procedure is categorized as stateless. Order or origin of incoming requests have no impact on the result of the actual authentication process. The same applies to TLS features such as <em>Session [ID, Ticket] Resumption</em> <span class="citation" data-cites="book_2013_networking-101_tls-session-resumption">[<a href="#ref-book_2013_networking-101_tls-session-resumption">115</a>]</span>, thus they are left aside, because they serve the sole purpose of performance optimization. Similar to the <em>Session Ticket Resumption</em> <span class="citation" data-cites="web_spec_tls-session-ticket-resumption">[<a href="#ref-web_spec_tls-session-ticket-resumption">116</a>]</span> a web token, namely the <a href="#link_jwt">JSON Web Token</a>, also moves the state towards the client, but that’s about all they have in common. A <em>JWT</em> carries everything with it that’s worth knowing, including possible states, and if necessary the token is symmetrical encrypted by the server. That is, only the server is able to obtain data from it and reacting accordingly.</p>
<p>Keeping track of a state (or multiple states) on the server and keeping data that is involved<br />
synchronized between server and client is expensive and by fare trivial. Expensive in the sense of additional resources a server would require to remember all the data for those states, that otherwise won’t be needed. And it’s not trivial, because this pattern requires the server to be aware of all current states (sessions) and has to have them accessible at all time. This also means, that the contents responses for certain requests might depend on preceding requests and their incoming order. Furthermore those session data has to be safely stored from time to time. Otherwise if the server fails to run at some point, data only existing in the memory would be gone without any possibility to get recovered. To stateless authentications non of those aspects apply. Certificates and keys as well as web tokens are both carry the information that might be necessary with them. Thus, considering those disadvantages, <em>public key cryptography</em> and web tokens are the preferred technologies for all authentication processes.</p>
<p>Except for the <em>two-way authentication</em> all authentication technologies mentioned above require an initial step to obtain some sort of token that is used to authenticate all subsequent requests. This step is commonly known as <em>login</em> or <em>sign in</em> and requires the authorizing entity to provide some credentials consisting at least of two parts. One part, that uniquely relates to the entity but doesn’t have to be private, and another part only the entity knows or has. Typically that’s a username or email address and a password or some other secret bit sequence (e.g. stored and provided by a USB stick). As another possible secret (or unique object) an <em><a href="#link_eid-card">eID card</a></em> could be used. Conceivable applications would be (1) to let the <em>operator</em> login to the <em>PDaaS</em> Management Tool or</p>
<ol start="2" type="1">
<li>to approve or authorize <em>access requests</em> or <em>data access</em> attempts. How the actual login process (1) would look like partially depends on the <em>eID card</em>’s implementation, but in general this use case would make sense. When considering the german implementation <em>(nPA)</em>, accessing the management tool via desktop requires also a card reader, preferably with an integrated hardware keypad. Instead accessing the tool on a mobile device could be achieved with the card’s RFID-capabilities, as long as the used device is able to communicate with the RFID-chip. Both scenarios (1+2) need the <em>nPA</em> to have the <em>eID</em> feature enabled. If a service wants to provide <em>nPA</em>-based online authentication <em>(eID-Service)</em>, which is defined as a non-sovereign <em>(“nicht hoheitlich”)</em> feature, it has to comply with several requirements <span class="citation" data-cites="web_bsi-spec_eid">[<a href="#ref-web_bsi-spec_eid">117</a>]</span> starting with applying for a permission to send a certificate signing request to a BerCA.<a href="#fn26" class="footnoteRef" id="fnref26"><sup>26</sup></a> This request is send from an <em>eID-Server</em> <span class="citation" data-cites="web_2017_npa-eid-server">[<a href="#ref-web_2017_npa-eid-server">118</a>]</span> in order to get signed a public key,<br />
which previously has been generated on a dedicated and certified hardware. This hardware is required by the officials as part of a <em>eID-Server</em>. The key pair - re-generated and re-signed every three days - is needed to establish a connection to the <em>nPA</em>, which is then used to authenticate the owner of that <em>eID card</em>. The described procedure appears to be highly expensive (regarding effort, hardware costs etc.), especially because every single <em>operator</em> would needs to go through the whole process in order to support this authentication method; not mentioning the uncertainty of the official’s decision on the permission application. Another approach could be to integrate an external authentication provider supporting the <em>nPA</em>, which would not only add an additional dependency, but would also weaken the system. All two scenarios are fairly similar, insofar as they would use the same mechanism to initially authenticate to the system, but with different intentions.</li>
</ol>
<p>Because of it’s simplicity the concept of web tokens are fairly straightforward to implement into the <em>PDaaS</em>. But since web tokens ensure integrity and the optional confidentiality only of their own carriage but not the entire HTTP payload, both requirements need to be addressed separately. Serving HTTP over <em>TLS</em> solves this issue. For connections that use a web token, it should be sufficient to rely on the public PKI that drives the internet with <em>HTTP</em> over <em>TLS</em>, because all information required to authenticate is provided by the token itself. Though, the situation is different if instead <em>two-way authentication</em> is used. For this, the system has to provide it’s own <em>PKI</em> including a Certificate Authority that issues certificates for <em>data consumers</em>, because not only the <em>endpoints</em> on the <em>PDaaS</em> (server) need to be certified, all <em>data consumers</em> (clients) need to present a certificate as well. Only the <em>PDaaS</em> verifies and thus determines (supervised by the <em>operator</em>) who is authorized to get access to the system. Hence the <em>PKI</em> needs to be selfcontained without any external role in order to function independently so that only invited parties can get involved. With referring to the statement mentioned above, <em>data consumer</em> have to be able as well to verify the identity of the <em>PDaaS</em>, in order to prevent man-in-the-middle attacks. Address this issue basically means, <em>data consumers</em> have to verify the certificate presented by the <em>PDaaS</em>. This can be done in two ways. One is, a certificate has been installed on the <em>PDaaS</em> that is certified and therefore trusted by a trustworthy public CA, as mentioned above. Then <em>consumer</em> uses CA’s certificate to verify the <em>PDaaS</em> certificate. The other way is, to let the <em>PDaaS</em> create and sign a public key by itself. Before <em>consumers</em> then get presented with the self-signed certificate of the <em>PDaaS</em> during the initiation of the TLS connection, they already have to be aware of that certificate. That is, <em>consumers</em> need to be provided with that certificate on a private channel upfront.</p>
<p>If a public-key-based connection, performing a <em>two-way authentication</em>, establishes successfully, it implies that the identity originating the request is valid and the integrity of the containing data is given. Whereas on a token-based authentication every incoming request has to carry the token so that the system can verify and associate the request with an account. Furthermore data it not automatically encrypted and thus integrity is not preserved.</p>
<p>An advantage of token-based authentication over TLS-based <em>two-way authentication</em> is that the token can be used on multiple clients at the same time. Or an account, a token is associated with, can actually have more than one token. Whereas during the asymmetric cryptography-based <em>two-way authentication</em> the client’s private key is required. So if it’s likely that a <em>operator</em> has several clients, regardless for what purposes, then the private key has to be on those clients. Though, a private key typically does not leave it’s current system or least does not exist in multiple systems at the same time in order to prevent exposure, which any action of duplication implies. To reduce those risks, it’s common practice to generate a private key at that location where it is going to be used.</p>
<p>OpenID, a open standard for decentralized user authentication, also uses subdomains as unique identifiers for associating with entities that need to authenticated, similar to approach proposed in this work. But since it underpinned by a very distinct scenario it is also very related and therefore restricted to that. Trying to adopt the standard might result in various changes leading to an implementation that shares not much compliance, which is not the intention of a standard.</p>
<p>The technology <em>De-Mail</em> tries to ensure authenticity of an authors identity, by embedding a legal foundation into email-based communication. But instead of providing technically valid authenticity by end-to-end encryption so that a recipient can truly rely on that information, it only goes as far as legal definition and legislation reaches. Thus it has no relevance to this work, other then the concept of letting a server sign outgoing data, which might be the only solution to avoid an overhead in user interaction caused by recurring events.</p>
<p>Computations based on asymmetric cryptography usually is slower then the ones based on symmetric cryptography <span class="citation" data-cites="book_2014_chapter-10-5-asym-random-number-gen">[<a href="#ref-book_2014_chapter-10-5-asym-random-number-gen">119</a>]</span>, but since there are no timing constrains when interacting with the <em>PDaaS</em>, regardless of whether it’s external communication with <em>data consumers</em> or internal between components, parameters for cryptographic procedures can chosen as costly as the system resources allow them to be, thus the level of security can be increased.</p>
<p><em><strong>Conclusions:</strong></em> Based on the several requirements and distinct advantages of the two authentication mechanisms, it is preferred to use asymmetric cryptography in combination with <em>HTTPS</em> for the communication between the system and <em>data consumers</em>, where the system provides it’s own <em>PKI</em>. Whereas a token-based authentication on top of <em>HTTPS</em> and public CAs should be suitable for communication between the system and the <em>operator</em>, preferable based on <em><a href="#link_jwt">JSON Web Tokens</a></em>, because the session state is preserved within the token rather then having the system itself keeping track of it. Though, it is also worth mentioning, that a a JSON Web Token implementation is feasible as well to fully replace the approach consisting of <em>two-way authentication</em> on TLS level and a private <em>PKI</em>. The disadvantage here would be, that whether <em>data consumers</em> are able to authenticate themselves or not, a HTTPS connection will establish in any case. At the same point, authenticating the <em>operator</em> is doable on the TLS-level as well; by restricting this possibility to only trusted environments like native mobile applications, because browser-based applications are not considered trusted and they lack of certain capabilities. Addressing the need of <em>consumers</em> verifying whether the <em>PDaaS</em> provided certificate can be trusted or not, both solutions, providing self-signed certificate on a secure channel upfront or using certificates certified by publicly trusted entities are legitimate. Even though the latter requires a service or an automatism that provides a new signed certificate whenever a new <em>data consumer</em> registers, such dependencies should be kept to an absolute minimum. To hardening an authentication procedure often one or more factors are added, for example an <em>eID card</em> or one-time password. This adds complexity to the procedure and thus increases the effort that is needed to make an attack successful. But equally it also increases the effort to support those factors in the first place. Using multi-factor authentication is generally valued and will be briefly noted as an optional security enhancement for the <em>operator role</em>. However detailed discussions regarding this topic are left to follow-up work on the specification.</p>
</section>
<section id="data-reliability" class="level2">
<h2><span class="header-section-number">6.3</span> Data Reliability</h2>
<p>Within the section <a href="#authentication">about authentication</a> it was discussed how to preserve data integrity - referring to possible man-in-the-middle attacks and alike. Furthermore it was described how to authenticate the different user roles so that their identities are ensured, though, authenticity of the actual data a <em>PDaaS</em> provides has yet to be ensured. In this case, authenticity refers to authentic and reliable (<a href="#sa04">S.A.04</a>) data, which means a) the data really represent the entity that is associated to the originating <em>PDaaS</em> and is thus owned by that entity, and b) the data is true at that moment when the related responses leaves the system. Since the <em>operator</em> can change the data at any point in time, this property requires a process where a trustworthy third party has to somehow verify the reliability of the data in question. That process on the other hand, is in direct contrast to the discussion about the <a href="#authentication">authentication system</a> and why it should be designed so that it is selfcontained. If instead it’s not required to provide information on the data being reliable or not, it won’t be an issue anymore. The information can be defined in a response as an optional property. Within the request the <em>data consumer</em> has to indicate whether the response should contain information about it’s reliability or not. Depending on what data is requested, the <em>PDaaS</em> decides whether it’s necessary to test for reliability or not. Based on the procedures that are available, the data reliability gets verified somehow.</p>
<p>But how does this reliability check exactly should look like? It comes down to two general steps. The first one is matching the actual data involved in that request against a reference data set. The second step is optional, although important for the <em>data consumer</em> in order to evaluate the sufficiency of the provided level of reliability. It involves the party, that also runs the first step, to confirm the result of that audit. The result of that evaluation then gets included in the response.</p>
<p>The following proposed methods are distinguish in the provided level of reliability as well as in the amount of effort to support them and in the possible impact to its surrounding system. Not all data points are necessary to test for reliability. Profile data for example are more likely to be tested, whereas consumption lists or location histories are more or less hard to verify, because currently there is no reliable way to verify the origin of those data sets.</p>
<ol type="1">
<li><p><strong>Local Verification by matching</strong><br />
The probably simplest and at the same time least reliable method is to just look at the existing data stored in the database and matches them against those data that is used to create a response.</p></li>
<li><p><strong>Local Verification and signing</strong><br />
An electronic ID card can serve as an authentication token for the <em>operator</em>, but it can also be utilized to verify the reliability of certain data. Using the german implementation <em>(nPA)</em> as an example, the <em>eID</em> feature would provide access to the owner’s basic profile data, which thus can be used to match against those data points that are both, hold by that <em>nPA</em> and going to be used to create the response. If the result of that matching procedure is positive, the related data then gets signed with a <em>QES</em> courtesy of the <em>data subject’s</em> <em>nPA</em>. That signature also gets included in the response, so that the recipient can verify the reliability of the data.</p></li>
<li><p><strong>Remote Verification and signing</strong><br />
Another method involves a third party who also has the same data that needs to be tested. The idea is to hand the data in question over to that party, who then tries to match against all those data points available in that context. The party also has the ability to sign data. Which is what she does, if the matching procedure has a positive outcome. It is required to sign the whole response or at least a replicable data set that contains the data that were initially required. The party then hands everything back to the <em>PDaaS</em> for further processing.</p></li>
<li><p><strong>Recurring Certification</strong><br />
The following method describes a modification of (3). In this method involved no matching procedure. The external third party, verifies if the data in question are correct and if they relate to the <em>data subject</em> by either literally looking at the data or by automatically processing a matching against their databases. If that party is satisfied, a certificate will be issued. This certificate contains an expiration date, which implies the consequence of going through this process again in the future, much like an issuing process of a common <em>Certificate Authority</em>. This certificate is then served as part of a response, which enabled the <em>data consumer</em> to verify the data reliability on its own. This is done by hashing the data in question, decrypting the hash embedded in the certificate and matching one against the other. If they are equal, the data has not changed since the party’s review and is therefore reliable. If data has changed in the <em>PDaaS</em> and data points are affected, that are also included in this verification process, then a new certificate created, because the containing hash is now invalid.</p></li>
</ol>
<p>Only one method per request should be used to verify data reliability, because every method can imply a different level of confidence. As described above the response send back to the <em>data consumer</em> has to indicate the method that has been used. Based on that the <em>data consumer</em> is then able evaluate that level und can act accordingly (e.g. verify a signature).</p>
<p>Expanding those verification procedures is reasonable, but to keep it simple for now this aspect won’t receive further attention, since the current requirements are sufficiently met. It will left to future work, though.</p>
<p><em><strong>Conclusions:</strong></em> The signing procedure as part of local verification method involve private key and certificate stored on the operator’s <em>eID card</em>. Every time when the <em>PDaaS</em> verifies data reliability that method has to runs. Thus the <em>operator</em> is forced to interact wit the <em>PDaaS</em>. Otherwise the operators private key need to be stored somewhere within the <em>PDaaS</em>. No matter where or when, that would potentially expose a highly confidential part of a cryptographic procedure. Not only would this reduces the overall security level of the system, it also makes every task this method is involved vulnerable to certain attacks. Aside from that, it’s highly unlikely that an <em>eID card</em> would allow to extract it’s containing private keys. That is, increasing inconvenience is inevitable for this proposed method. The <em>Local Verification and signing</em> method also has the same dependencies mentioned in the discussion about the requirements for using the (german) <em>eID card</em> as an authentication token. And since it was rejected because of those dependencies and because of the inconvenience mentioned before, this verification method eventually will not being supported in the specification.</p>
<p>The <em>Remote Verification and signing</em> method would require the external party to be an official authority, because no other entity has a) the data in question (primarily profile data), which makes them b) legally binding. They are commonly trusted. The same goes for The <em>Recurring Certification</em>, but while the <em>Remote Verification and signing</em> method introduces a very strong dependency to that external party, the <em>Recurring Certification</em><br />
offers a simple loosely linking dependency. Whose design would make it even possible to obtain such a certificate manually but automate it on the other side. Nevertheless, both provide a trustworthy certification.</p>
<p>Finally the first method, which does just a matching of two data sets against each other. Those data sets are obtained from the same <em>PDaaS</em> storage, but at a different time; right before the request finally gets proceeded, though. The method is not very useful - in general and specifically to this issue, because not much happens within the system during that time (case were data in the storage changes during request processing are discussed in the section on <em><a href="#access-management">Access Management</a></em>). Even if the whole system would be compromised, this method has no use in that case, because a) if that’s the situation, other issues might need more urgent addressing then ensuring data reliability for <em>data consumers</em> and b) even then, the chances are insignificant that this method result is negative. Hence it provides the lowest level of reliability.</p>
<p>Certain fields of application of a <em>PDaaS</em> as a data resource might already impose some constraints about the level of reliability and maybe even how that can be provide. Determined by legislation or other rules, violation might prevent the <em>PDaaS</em> from being used. Others instead - depending on their guidelines and business model - don’t rely on any kind of confidence. In general, <em>data consumers</em> are expected to already have a basic confidence in a <em>PDaaS</em> and the data coming from there. Regardless of that, providing an indication about the data’s authenticity is valued as a first and important step towards a fully working feature. All of the proposed verification methods have some downsides, Though, the <em>Recurring Certification</em> method would be the least invasive and therewith an adequate choice.</p>
<p>For the <em>PDaaS</em> a primary goal is to preserve all data owned by the <em>data subject</em> and giving her control over where the data might go; not providing sufficient proof for the data authenticity.<br />
Though, it is still important, to provide <em>data consumers</em> with an information about the level of reliability, but it is up to them how to rate that information and how to proceed with the obtained data.</p>
</section>
<section id="access-management" class="level2">
<h2><span class="header-section-number">6.4</span> Access Management</h2>
<p>In the subsequent section it will be discussed, how several processes around the topic of <em>data consumers obtaining data from the PDaaS</em> can be modeled, what consequences certain variations might have and what issues need to be addressed.</p>
<p>Below it is proposed what a general design might look like for the process of how <em>data consumers</em> get authorized and thereby access the <em>data subject’s</em> personal data and how <a href="#standards-specifications-and-related-technologies">previous mentioned technologies</a> can be assembled in order to meet the specified <a href="#requirements">requirements</a>. OR Based on the <a href="#standards-specifications-and-related-technologies">outlined technologies</a> and specified <a href="#requirements">requirements</a> the general design for a process in which a <em>data consumer</em> gets authorized and thereby access the <em>operator’s</em> personal data is proposed as followed.</p>
<p><strong>Part One: consumer registration</strong><br />
0) The <em>operator</em> creates a new unique URI in the system</p>
<ol type="1">
<li><strong>Prepare registration</strong>; the <em>operator</em> has to tell third party were and how to register as a <em>data consumer</em> by handing over a URI that is unique to the current registration process. <em>Several things need to be noted here. First, the operator “pulls” consumers into the system. This is the only way for a consumer to establish a relation. If consumers were able initiate this process on their own without the operator’s involvement, it would be much harder for the system to detect spam or fraudulent requests. Second, handing over that URI must be done over a secure channel.</em></li>
</ol>
<p><em>NOTICE: the two initial steps could also be made from the opposite direction. Third parties put all information and data required for a registration together and present them to the </em>operator<em> in form of a QR-Code, so that the </em>operator* can obtain it and whereby is able to proceed. This approach would short cut and hence simplify the process.*</p>
<ol start="2" type="1">
<li><p><strong>Send permission request</strong>; The third party then makes the actual attempt to register as a <em>data consumer</em> by providing required information. Those information have to be include some kind of feedback channel (e.g. URI) so that the system can get back to that third party.</p></li>
<li><p><strong>Review permission request</strong>; the operator gets notified about new registration attempts, which she then has to review and decide whether to grant or refuse the requested data access.</p></li>
<li><p><strong>Create permission profile</strong>; if access has been granted a new <em>permission profile</em> is going to be created. Optionally, a new <em>permission profile</em> could also be created if the access has been refused. It’s just meant for the <em>operator</em> to keep track of her decisions.</p></li>
<li><p><strong>Respond to third party</strong>; regardless of the decision, the third party get’s then informed via feedback channel about that decision and is also provided with further details required to obtain actual data.</p></li>
</ol>
<p><strong>Part Two: obtain data</strong><br />
0) A successful registration as a <em>data consumer</em> is required</p>
<ol type="1">
<li><p><strong>Send request</strong>; <em>data consumer</em> sends <em>access request</em> to the system, containing a all information about what data is needed, how to process the data and what the response should contain.</p></li>
<li><p><strong>Parse and check request</strong>; after the system has received an <em>access request</em>, first it<br />
authenticates the <em>data consumer</em> and checks the related <em>permission profile</em>. According to the defined <em>access rules</em>, the system decides how to proceed. Either it pauses, because it needs further attention from the <em>operator</em>, or it can start to process and create the response.</p></li>
<li><p><strong>Compute response</strong>; How that would look like mainly depends on what the <em>access request</em> contains and also what the <em>permission profile</em> determines (see <em>access request types</em> below).</p></li>
<li><p><strong>Respond to consumer</strong>; handover the computed response back to the requester. There are two ways of responding to an <em>access request</em>. Either the system respond with a state of the process and where the <em>consumer</em> will/can find the demanded data, or the <em>consumer</em> includes a callback URI, which the system has to invoke with data in demand.</p></li>
</ol>
<p>With respect to the requirements (<a href="#sp01">S.P.01</a>), personal data should not leak into the outside. To tackle this issue, the following three types of <em>access requests</em> are defined, starting with the most sufficient solution:</p>
<ol type="A">
<li><strong>Supervised Code Execution</strong>; <em>access requests</em> additionally come with an executable program - binary or source code - potentially including information about provisioning. After the required data is retrieved from the storage, the program gets invoked with the data locally on the system but within a completely separated environment (<em>sandbox</em>). The result of that invocation gets returned to the system.</li>
<li><strong>Data DRM<a href="#fn27" class="footnoteRef" id="fnref27"><sup>27</sup></a></strong>; after data is retrieved from the storage it gets encrypted. The cipher is included in the response. Upfront, <em>data consumers</em> are equipped with a small program, that can connect to the <em>PDaaS</em> and has to wrap the <em>consumer’s</em> own software that is planned to proceed the requested data. Now when <em>consumers</em> receive the response, the program needs to get invoked with the cipher, so that, by priorly fetching the key from the <em>PDaaS</em>, the cipher gets decrypted from within the invocation. Thus the data is made available to the wrapped software and only during runtime. After the invocation has finished the program needs to propagate the results returned by the software back to the outer environment.</li>
<li><strong>Plain Forwarding (default)</strong>; retrieve data from the storage, quick-checking the result and forwarding it directly into response.</li>
</ol>
<p>So the data won’t leave, unless the <em>PDaaS</em> doesn’t support any of the proposed request types or the <em>data consumer</em> provides no alternative, so that the fallback type has to be applied. If that’s the case, the confidentiality of all personal data is already preserved, because all communications from and to the <em>PDaaS</em> are generally happening over HTTPS anyway, so that the data is encrypted during the transport.</p>
<p>The concept of authorizing a <em>data consumer</em> to get the ability of accessing personal data is fairly simple. During the <em>registration</em> consumers have to provide detailed information about their intentions, so that the <em>operator</em> is confident about their permissions when reviewing them. The created <em>permission profile</em> reflects the result of that review. Such a <em>permission profile</em> defines what data points are requested to access and how long those permissions last. The later is defined as <em>permission type</em> and can be one of the following:</p>
<dl>
<dt><em>one-time-only</em></dt>
<dd>access permissions are hereby granted for just a single <em>access request</em> (with respect to certain errors regarding the communication layer)
</dd>
<dt><em>expires-on-date</em></dt>
<dd>access permissions are hereby granted until the defined point in time has arrived
</dd>
<dt><em>until-further-notice</em></dt>
<dd>access permissions are hereby granted until the <em>permission type</em> has changed or the <em>permission profile</em> has been deleted
</dd>
</dl>
<p><em>NOTICE: The default </em>permission type* should be configurable. The <em>operator</em> can change all <em>permission profiles</em> at any point in time.*</p>
<p>Among other information, an <em>access request</em> contains the <em>data query</em> that shows very precisely what data points are affected by that request. So if an <em>access request</em> arrives at the <em>PDaaS</em>, assuming the <em>data consumer</em> has been authenticated sufficiently, the systems (0) searches for a <em>permission profile</em> that correspond to the <em>data consumer</em> and the requested data points. If it fails to find one, the access request gets refused. But if it does, then it checks (1) if the permission type suffices at that moment and (2) if the query only contains data points that are also enabled in the <em>profile</em>. Here the order does matter, because it is imaginable that the operation behind (1) is less complex then operation (2). So, at the end running (1) before (2) can result in a lower response-time, if operation (1) already results negative. If all operations have a positive result, access is granted.</p>
<p>As stated in the section about <a href="#data-reliability">data reliability</a>, the <em>data subject</em> is able to add, change or remove all her data or even the <em>permission profiles</em> at any point in time. This raises the question of how to solve the situation were <em>data requests</em> are being processed, while those changes are happening and might affect the result of those requests. The first and simplest approach would be to not address this issue at all, but that would be unreasonable, because providing data to the <em>consumer</em> normally means for the <em>data subject</em> get something in return or to somehow benefit from that. So that approach is no option. Using a failure of reliability verifications as a mechanism to re-request data won’t work either in that case, because it would be based on a wrong assumption, since that failure can have multiple causes, not only the issue here in question. A stateless solution seems to be not fitting due to the time-related dependency. So the only currently perceivable way is to keep track of all momentarily processing or pending <em>access requests</em>, to detect those who are affected by that changes so that each of them can be aborted and processed again. Here it is important to determine the right moment, when all changes are done, otherwise the system might end up restarting those computations repeatedly within a short amount of time. The described issue relates to both, <em>personal data</em> and <em>permission profiles</em>, because either can impact the response send to t <em>data consumer</em>. Furthermore, it needs to be ensured that only after the <em>permission requests</em> are being reviewed and the <em>permission profiles</em> are being created, the <em>data consumers</em> receive their credentials or a notification to get started.</p>
<p>It is up to the <em>data consumers</em> to decide which data they are requesting to access, but how do they know what data can be requested? The only option is to expose information about data availability, which can be done in a variety of ways. First, those information can be made publicly available via URI, providing a Machine-readable format, so that it can be processed automatically by <em>data consumers</em>. It is also feasible to restrict that access to only registered <em>consumers</em>, in order to prevent those information from being crawled. They might be valued as meta data and therefore used in unwanted computations that could raise privacy concerns. It is imaginable to let the <em>operator</em> restrict the access to these availability information on the level of individual <em>data consumers</em> or system-wide, and to set a default configuration for that behaviour. Depending on that configurations request might fail, thus requester need to be provided with meaningful errors. Http error codes <span class="citation" data-cites="web_spec_http-error-codes">[<a href="#ref-web_spec_http-error-codes">120</a>]</span> might be a a sufficient fit for that purpose.</p>
<p>An already standardized way to implement authorization would be <a href="#link_oauth">OAuth</a> Specification, and since the TLS layer is already in place to handle authentication, the choice would be to use version 2 of the standard, because it relies on HTTPS. Only two of the four <em>grant types</em> provided by OAuth would match with process design introduced above. The types are <code>password</code> and <code>client_credentials</code>, which basically require identifier(s) and secret or credentials to directly request the <code>token</code>. The other two types define additional steps and interactions involving client <em>(consumer)</em> and user <em>(operator)</em> before getting the<code>token</code>. This would make the proposed process undesirably more complicated. Although the proposal includes user interactions like selecting and confirming requested permissions as well. According to the documentations <span class="citation" data-cites="web_spec_oauth-1a_client-reg">[<a href="#ref-web_spec_oauth-1a_client-reg">121</a>]</span> <span class="citation" data-cites="web_spec_oauth-2_client-reg">[<a href="#ref-web_spec_oauth-2_client-reg">122</a>]</span>, both OAuth versions (1.0a and 2) require the client <em>(data consumer)</em> to register to the authorization server upfront (to obtain a <code>client_id</code>), before initializing the authorization process. However, as stated before, the concept of the <em>data subject</em> “pulling” a <em>data consumer</em> towards the <em>PDaaS</em> is preferred over letting <em>data consumers</em> try to “push” themselves towards the system. The reason is to prevent unwanted applications for data access, because they all have to get reviewed by the <em>data subject</em>. Furthermore, it is not within the scope of the OAuth Specification to define how this should be accomplished. Thus, such step needs to be added in addition to an entire OAuth-Flow, which might cause otherwise avoidable overhead in user interactions. Moreover, the proposed design does not include that step either. Instead, it is not needed process at all, because according to the former proposed process, identifying the client happens implicitly as a result of how the resource owner <em>(operator)</em> obtains the registration request from the client (Part One: consumer registration, step 0 and 1). Further investigations show that the <code>access_token</code> semantic as from the perspective of a resource server, which are a) authentication (does this token exist?) and b) authorization (is this token valid and what does it permit?), have in part already been provided by the proposed way of using the TLS layer. Because every <em>data consumer</em> has it’s own endpoint to connect with the <em>PDaaS</em> and the certificate used by the <em>consumer</em> is singed by a signature that is only used for that endpoint. This means, the <em>consumer</em> is already authenticated, when the TLS connection has successfully established. And since the endpoints relates to the <em>permission profiles</em> it would make providing an <code>access_token</code> to become obsolete. To summarize, implementing OAuth would introduce several mechanisms that otherwise can be provided by the combination of <em>two-way authentication</em> in TLS, dedicated endpoints and certification.</p>
<p><em><strong>Conclusions:</strong></em> In the preceding text, various solutions were developed, based on which the following three solutions are at disposal:</p>
<ol type="a">
<li>OAuth 1.0a and HTTP</li>
<li>OAuth 2 and HTTPS (public Certification and PKI)</li>
<li>HTTP over TLS with <em>two-way authentication</em>, private PKI, sub-domains as dedicated endpoints</li>
</ol>
<p>The solutions a) and b) require an extra step were <em>data consumers</em> would register themselves at the <em>PDaaS</em>. This already needs a secure channel to prevent man-in-the-middle attacks. Furthermore does option a) obtain a symmetric key for creating signatures used to ensue confidentiality and integrity in the subsequent steps. All those cryptographic procedures need to be adopted when implementing the specification emerging from this work and when interacting with those implementations. While this can cause much more harm, is is proposed to leave as much of these sensitive parts as possible to existing implementations that already have proven themselves. Thus HTTPS is mandatory, which makes</p>
<ol start="2" type="a">
<li>more suitable over a), because it’s also more flexible and easier to implement. Whereas solution c) moves the complete authentication procedure to a different layer. It hence results in separating authentication and authorization from each other, leaving no remains of relation. This opens the authorization design up to for example other implementations that might be more suitable for certain <em>data types</em>. In addition, it would only require little effort to support the case where multiple <em>data consumers</em> share the same <em>endpoint</em> and thereby the same <em>permission profiles</em>. And combining b) and c) would result in significant redundancy, since both solutions have much overlap in the features they are providing, even though b) aims to be a framework for authorization. The process description from the beginning of this section will be used as the foundation of <em>access management</em> in the <em>PDaaS</em>. Implementing OAuth based on this design would leave nothing from the framework, but a simple request returning an identifier for it’s permissions. And even these identifiers are obsolete when combining TLS with dedicated <em>consumer</em>-specific endpoint, as c) states. So there is not much benefit in using OAuth, other then developers might be somewhat familiar with the API. This can be addressed by a detailed specification for this project, hence c) is preferred over b). At the end, the only suitable use case from the specification would consists of just a request that obtains a token after authenticating with the provided credentials. And since OAuth only provides a framework for how to authorize third parties to access external resources, but leaves the procedure of how to actually verify those access attempts up to it’s implementers <span class="citation" data-cites="web_spec_oauth-1a_access-verification">[<a href="#ref-web_spec_oauth-1a_access-verification">123</a>]</span> <span class="citation" data-cites="web_spec_oauth-2_access-verification">[<a href="#ref-web_spec_oauth-2_access-verification">124</a>]</span>. In the context of this project OAuth doesn’t really match with the rest of the design aspects.</li>
</ol>
<p>How the first steps of a <em>consumer registration</em> are look like, is up to the <em>consumer</em>, even though the version involving a QR-Code might result in a nicer user experience from the <em>data subject’s</em> perspective. In any case, the secure channel is vital.</p>
<p>When obtaining personal data, at the same time preventing those data from leakage is almost impossible, because of the nature of digital data being able to get effortlessly copied. Nevertheless it is possible to make it much more difficult, so that it becomes inefficient to bypass those mechanism. At the same time it requires also some effort to establish, run and maintain the infrastructure needed for those mechanisms. In case of the <em>Data DRM</em> proposal that effort is not proportionate, because it requires additional infrastructure, interfaces and cryptographic procedures, thus introduces new attack scenarios. For now the only approach being considered, is the <em>Supervised Code Execution</em>, aside from the default forwarding. When implementing this approach, two directions might need to be considered. Alongside the executable program <em>data consumers</em> either provide all dependencies so that everything is bundled up, or don’t provide any dependency at all. The latter is preferred, because it reduces the amount of potentially malicious, flawed or needless components, so that the <em>data subject</em>, supported by her <em>PDaaS</em>, gains more supervising capabilities and thus more control over her personal data. Since the overall goal here is to prevent the <em>data subject</em> from loosing control over her data, it might also be conceivable, that certain categories of personal data with a higher level of sensitivity also require a least sufficient <em>request type</em>. If the <em>data consumer</em> does not comply, access will be refused. Also, depending on which category the personal data relates to, the <em>PDaaS</em> might be able to anonymize certain types of data somehow, if it’s capable of doing so all, because the <em>consumer</em> at least supposedly knows what individual is behind that <em>PDaaS</em> it currently interacts with. The field for <em>data anonymization</em> is a large research area on its own, which recently started to gains a lot of traction due to emerging privacy concerns about <em>big data</em>. Thus it will be left for future work.</p>
</section>
<section id="data" class="level2">
<h2><span class="header-section-number">6.5</span> Data</h2>
<p>The core task of a <em>PDaaS</em> is providing data, <em>personal data</em>, which in conjunction is the digital manifestation of an individual, a person. One party creates the data, another one obtains and processes it. Thus, both need to agree, or at least need to know, how that data looks like, how is it structured and what are their semantics. The following section is intended to discuss different technologies, used to create queries that obtain those data points that are desired. Further on, it describes some basic data types and schemas, that might be useful in the context of <em>personal data</em> as well as for previously introduces <a href="#scenarios">scenarios</a>.</p>
<p>First of all, to address the need of portability, which has to be satisfied by those components, that are storing and providing <em>personal data</em>, it is essential to abstract the actual storage from how it gets accessed. This makes it possible to relocate those storage into other platforms and environments. Thereby the <em>personal data storage</em> itself becomes platform-agnostic from an outside view, in other words portable. In order to reduce possible issues related to unsupported communication protocols it might be reasonable to enforce HTTP - over TLS, if they don’t share the same environment - even if the storage therefor requires an additional driver or proxy layer, like for example a mobile app.</p>
<p>Possible technologies are for example <em><a href="#link-graphql">GraphQL</a></em> or the <em><a href="#link-sparql">SPARQL</a></em>, which is part of the <em><a href="#link-semantic-web">Semantic Web Suite</a></em>. Both are query languages underpinned by the concept of a graph. This means, relations between data points are embedded within the data structure itself. That meant, in terms of a graph, relations are <em>edges</em> and data points are <em>nodes</em>. In consequence the structure of a query itself reappears in it’s result, which means the originator of that query knows exactly what to expect for the response. Therefore it’s not necessary to provide any additional information about how to handle and interpret the responded data. The example below gives a first impression of how it might look like, when a <em>consumer</em> obtains the name of the <em>data subject</em> and a bank account of hers, that supports online payment.</p>
<p><strong><span id="code-01_sparql-query">Code 01: Example query in SPARQL</span>:</strong></p>
<div class="sourceCode"><pre class="sourceCode sql"><code class="sourceCode sql"># <span class="kw">query</span> <span class="dv">1</span>: obtain <span class="kw">the</span> <span class="kw">data</span> subject<span class="st">&#39;s first and last name</span>
<span class="st">PREFIX person: &lt;http://pdaas.tld/schemas/person&gt;</span>

<span class="st">SELECT $firstname $lastname</span>
<span class="st">FROM &lt;https://unique-consumer-endpoint.pdaas.tld/sparql/profile&gt;</span>
<span class="st">WHERE {</span>
<span class="st">    $person person:firstname $firstname .</span>
<span class="st">    $person person:lastname $lastname .</span>
<span class="st">}</span>


<span class="st"># query 2: obtain all bank accounts that are available for online payment</span>
<span class="st">PREFIX bank-account: &lt;http://pdaas.tld/schemas/bank-account&gt;</span>

<span class="st">SELECT $accountId $bankName $paymentMethod</span>
<span class="st">FROM &lt;https://unique-consumer-endpoint.pdaas.tld/sparql/finance&gt;</span>
<span class="st">WHERE {</span>
<span class="st">    $bank-account bank-account:payment-method &quot;online-service&quot; .</span>
<span class="st">    $bank-account bank-account:payment-method $paymentMethod .</span>
<span class="st">    $bank-account bank-account:account-id $accountId . </span>
<span class="st">    $bank-account bank-account:bank-name $bankName .</span>
<span class="st">}</span></code></pre></div>
<p><strong><span id="code-02_sparql-query-results">Code 02: Results of Code 01 in JSON</span>:</strong></p>
<div class="sourceCode"><pre class="sourceCode json"><code class="sourceCode json"><span class="er">//</span> <span class="er">result</span> <span class="er">1:</span>
<span class="fu">{</span>
    <span class="dt">&quot;head&quot;</span><span class="fu">:</span> <span class="fu">{</span>
        <span class="dt">&quot;vars&quot;</span><span class="fu">:</span> <span class="ot">[</span>
            <span class="st">&quot;firstname&quot;</span><span class="ot">,</span>
            <span class="st">&quot;lastname&quot;</span>
        <span class="ot">]</span>
    <span class="fu">},</span>
    <span class="dt">&quot;results&quot;</span><span class="fu">:</span> <span class="fu">{</span>
        <span class="dt">&quot;bindings&quot;</span><span class="fu">:</span> <span class="ot">[</span>
            <span class="fu">{</span>
                <span class="dt">&quot;firstname&quot;</span><span class="fu">:</span> <span class="fu">{</span>
                    <span class="dt">&quot;type&quot;</span><span class="fu">:</span> <span class="st">&quot;literal&quot;</span><span class="fu">,</span>
                    <span class="dt">&quot;value&quot;</span><span class="fu">:</span> <span class="st">&quot;Doe&quot;</span>
                <span class="fu">},</span>
                <span class="dt">&quot;lastname&quot;</span><span class="fu">:</span> <span class="fu">{</span>
                    <span class="dt">&quot;type&quot;</span><span class="fu">:</span> <span class="st">&quot;literal&quot;</span><span class="fu">,</span>
                    <span class="dt">&quot;value&quot;</span><span class="fu">:</span> <span class="st">&quot;Jane&quot;</span>
                <span class="fu">}</span>
            <span class="fu">}</span>
        <span class="ot">]</span>
    <span class="fu">}</span>
<span class="fu">}</span>

<span class="er">//</span> <span class="er">result</span> <span class="er">2:</span>
<span class="fu">{</span>
    <span class="dt">&quot;head&quot;</span><span class="fu">:</span> <span class="fu">{</span>
        <span class="dt">&quot;vars&quot;</span><span class="fu">:</span> <span class="ot">[</span>
            <span class="st">&quot;accountId&quot;</span><span class="ot">,</span>
            <span class="st">&quot;bankName&quot;</span><span class="ot">,</span>
            <span class="st">&quot;paymentMethod&quot;</span>
        <span class="ot">]</span>
    <span class="fu">},</span>
    <span class="dt">&quot;results&quot;</span><span class="fu">:</span> <span class="fu">{</span>
        <span class="dt">&quot;bindings&quot;</span><span class="fu">:</span> <span class="ot">[</span>
            <span class="fu">{</span>
                <span class="dt">&quot;accountId&quot;</span><span class="fu">:</span> <span class="fu">{</span>
                    <span class="dt">&quot;type&quot;</span><span class="fu">:</span> <span class="st">&quot;integer&quot;</span><span class="fu">,</span>
                    <span class="dt">&quot;value&quot;</span><span class="fu">:</span> <span class="dv">0905553715</span>
                <span class="fu">},</span>
                <span class="dt">&quot;bankName&quot;</span><span class="fu">:</span> <span class="fu">{</span>
                    <span class="dt">&quot;type&quot;</span><span class="fu">:</span> <span class="st">&quot;literal&quot;</span><span class="fu">,</span>
                    <span class="dt">&quot;value&quot;</span><span class="fu">:</span> <span class="st">&quot;A. W. Fritter Institute&quot;</span>
                <span class="fu">},</span>
                <span class="dt">&quot;paymentMethod&quot;</span><span class="fu">:</span> <span class="fu">{</span>
                    <span class="dt">&quot;type&quot;</span><span class="fu">:</span> <span class="st">&quot;literal&quot;</span><span class="fu">,</span>
                    <span class="dt">&quot;value&quot;</span><span class="fu">:</span> <span class="st">&quot;online-service&quot;</span>
                <span class="fu">}</span>
            <span class="fu">}</span>
        <span class="ot">]</span>
    <span class="fu">}</span>
<span class="fu">}</span></code></pre></div>
<p>Without going into much details here, the syntax of this example (<a href="#code-01_sparql-query">Code 01</a>) already shows its nature of decentralization. This aspect at the same time introduces additional external dependencies. Because the query language itself has no concept of schemas or any kind of semantic, it needs to be made aware of them. SPARQL queries typically return XML which then can be rendered into (HTML) tables. JSON and RDF are supported as well. The reason for performing two queries instead of just one is, because otherwise the result might have returned multiple “rows” with redundant data, if more then one bank account would have supported online payment; varying in three columns containing data about bank accounts though, but being identical in the fields related to the profile information.</p>
<p><strong><span id="code-03_graphql-query">Code 03: Example query in GraphQL</span>:</strong></p>
<div class="sourceCode"><pre class="sourceCode js"><code class="sourceCode javascript"># URL<span class="op">:</span> https<span class="op">:</span><span class="co">//unique-consumer-endpoint.pdaas.tld/graphql</span>

query <span class="op">{</span>
    profile <span class="op">{</span>
        firstname
        lastname
    <span class="op">}</span>
    <span class="at">bankAccounts</span>(<span class="dt">paymentMethod</span><span class="op">:</span> <span class="st">&#39;online-service&#39;</span>) <span class="op">{</span>
        accountId
        bankName
        paymentMethod
    <span class="op">}</span>
<span class="op">}</span></code></pre></div>
<p><strong><span id="code-04_graphql-query-result">Code 04: Result of Code 03 in JSON</span>:</strong></p>
<div class="sourceCode"><pre class="sourceCode json"><code class="sourceCode json"><span class="fu">{</span>
    <span class="dt">&quot;profile&quot;</span><span class="fu">:</span> <span class="fu">{</span>
        <span class="dt">&quot;firstname&quot;</span><span class="fu">:</span> <span class="st">&quot;Jane&quot;</span><span class="fu">,</span> 
        <span class="dt">&quot;lastname&quot;</span><span class="fu">:</span> <span class="st">&quot;Doe&quot;</span>
    <span class="fu">},</span>
    <span class="dt">&quot;bankAccounts&quot;</span><span class="fu">:</span> <span class="ot">[</span>
        <span class="fu">{</span>
            <span class="dt">&quot;accountId&quot;</span><span class="fu">:</span> <span class="dv">0905553715</span><span class="fu">,</span>
            <span class="dt">&quot;bankName&quot;</span><span class="fu">:</span> <span class="st">&quot;A. W. Fritter Institute&quot;</span><span class="fu">,</span>
            <span class="dt">&quot;paymentMethod&quot;</span><span class="fu">:</span> <span class="st">&quot;online-service&quot;</span>
        <span class="fu">}</span>
    <span class="ot">]</span>
<span class="fu">}</span></code></pre></div>
<p>Whereas comparing the <em>GraphQL</em> query syntax (<a href="#code-03_graphql-query">Code 03</a>) with it’s result (<a href="#code-04_graphql-query-result">Code 04</a>) shows of a remarkable resemblance. By defining <code>paymentMethod</code> as an argument, the resolver for <code>bankAccounts</code> then implements an instruction to match the value of that argument (<code>'online-service'</code>) against the whole set. <em>GraphQL’s server</em> then knows from which resources the data in question need to be pulled and how they need to be aggregated. While SPARQL has a full-featured query language syntax including all sorts of controls (e.g. aggregation, operators, nested queries etc.), GraphQL’s syntax instead is more rudimental, because all it’s functions and logic was abandoned from the language itself and put into a server part. With this concept of separation it is straightforward to validate queries, because it essentially means matching against types. Both query languages share a comprehensive understanding of a type-system, that encourages to create all kinds of data types. However, when comparing the results of both languages, some distinctions appear. While in GraphQL the characteristics of graph-structured data are remain, <em>SPARQL’s</em> output is missing a certain level of depth. The reason for that originates in the design of the query language and it’s syntax. <em>SPARQL</em> is able to notice implicit relations between data points, though it’s query language is not capable of grabbing and presenting them. Thus the result only consists of two dimensions.</p>
<p>It is crucial for the <em>PDaaS</em> to provide the <em>data subject</em> with abilities to create her own data types and schemas (<a href="#sp03">S.P.03</a>). Thereby she is enabled to serve data points according to her own needs and terms. In order to interact with their customers or users, <em>data consumers</em> might develop and provide schemas for their requests as well. This can help <em>data subjects</em> to speedup the process of permission granting and to easier understand what data points are affected. Data types and schemas are the key to validate incoming and outgoing data. If data violates the underlying schema or no appropriate schema exists, the data transfer fails. Other missing data types could be developed by a community, because not every <em>data subject</em> might have the ability to model her own data types. Thus everyone can benefit from that effort taken by a few. As a result, the ones that are widely used might then become de facto standards. Moreover, it’s also possible that several data types will emerge, which are based on common standards, for example <em>medical record</em> <span class="citation" data-cites="web_spec_data-schemas_ehr">[<a href="#ref-web_spec_data-schemas_ehr">125</a>]</span>, <em>point of interest</em> <span class="citation" data-cites="web_spec_data-schemas_poi">[<a href="#ref-web_spec_data-schemas_poi">126</a>]</span> or <em>bank transfer</em> <span class="citation" data-cites="web_spec_data-schemas_bank-transfer">[<a href="#ref-web_spec_data-schemas_bank-transfer">127</a>]</span>. With this approach those data types can be viewed as something like a plugin or add-on for the <em>PDaaS</em>.</p>
<p>In order to avoid confusion about the differences between types and schemas and to simplify their relations, the following two definitions are henceforth being used. A (data) <em>type</em> is the superior term; hence refers to both of them.</p>
<pre><code>*Float* or *Nil (null)*</code></pre>
<pre><code>*primitives*, but can consist of other structs as well</code></pre>
<p>Based on these two concepts almost any imaginable data type can be modeled. A selection of such types can be found in the list of <a href="#list-01_suggested-structs">suggested structs (List 01)</a>, whereas an extract of (sub-)categories that might be useful in a <em>PDaaS</em> are specified in a list of <a href="#list-02_data-categories">data categories (List 02)</a>. Additional examples for <em>structs</em> include a <a href="#code-05_struct_profile"><em>data subject’s</em> profile (Code 05)</a>, a <a href="#code-06_struct_contact">contact (Code 06)</a> and bare <a href="#code-07_struct_position">position (Code 07)</a>. All those examples and lists are only meant as a starting point that should cover basic scenarios as well to give a first impression of what data types a <em>PDaaS</em> could provide.</p>
<p><strong><span id="list-01_suggested-structs">List 01: Suggestions for useful structs</span></strong></p>
<ul>
<li>Address</li>
<li>Contact</li>
<li>Location
<ul>
<li>Country</li>
<li>City</li>
<li>Position</li>
</ul></li>
<li>Media
<ul>
<li>Audio</li>
<li>Video</li>
</ul></li>
<li>Organisation</li>
<li>Date</li>
<li>TimeRange</li>
<li>Language</li>
<li>Diseases</li>
</ul>
<p><em>NOTICE: schema notation is based on the rules underpinning the schema definition provided by the SimpleSchema project <span class="citation" data-cites="web_2017_repo_node-simple-schema">[<a href="#ref-web_2017_repo_node-simple-schema">128</a>]</span>.</em></p>
<p><strong><span id="code-05_struct_profile">Code 05: Struct - Profile (example)</span></strong></p>
<div class="sourceCode"><pre class="sourceCode js"><code class="sourceCode javascript"><span class="op">{</span>
    <span class="dt">firstname</span><span class="op">:</span> String<span class="op">,</span>
    <span class="dt">lastname</span><span class="op">:</span> String<span class="op">,</span>
    <span class="dt">pseudonym</span><span class="op">:</span> String<span class="op">,</span>
    <span class="dt">birth</span><span class="op">:</span> Date<span class="op">,</span>
    <span class="dt">gender</span><span class="op">:</span> String<span class="op">,</span>
    <span class="dt">religion</span><span class="op">:</span> String<span class="op">,</span>
    <span class="dt">motherTongue</span><span class="op">:</span> Language
    <span class="dt">photo</span><span class="op">:</span> File<span class="op">,</span>
    <span class="dt">residence</span><span class="op">:</span> Address<span class="op">,</span>
    <span class="dt">employer</span><span class="op">:</span> Organisation
<span class="op">}</span></code></pre></div>
<p><strong><span id="code-06_struct_contact">Code 06: Struct - Contact (example)</span></strong></p>
<div class="sourceCode"><pre class="sourceCode js"><code class="sourceCode javascript"><span class="op">{</span>
    <span class="dt">label</span><span class="op">:</span> String<span class="op">,</span>
    <span class="dt">type</span><span class="op">:</span> <span class="at">String</span>(<span class="st">&#39;phone&#39;</span><span class="op">|</span><span class="st">&#39;email&#39;</span><span class="op">|</span><span class="st">&#39;url&#39;</span><span class="op">|</span><span class="st">&#39;name-of-social-network&#39;</span>)<span class="op">,</span>
    <span class="dt">prio</span><span class="op">:</span> <span class="at">Integer</span>(<span class="dv">0-2</span>)<span class="op">,</span>
    <span class="dt">uid</span><span class="op">:</span> String
<span class="op">}</span></code></pre></div>
<p><strong><a href="#code-07_struct_position">Code 07: Struct - Position (example)</a></strong></p>
<div class="sourceCode"><pre class="sourceCode js"><code class="sourceCode javascript"><span class="op">{</span>
    <span class="dt">lat</span><span class="op">:</span> Float<span class="op">,</span>
    <span class="dt">lon</span><span class="op">:</span> Float<span class="op">,</span>
    <span class="dt">radius</span><span class="op">:</span> <span class="op">{</span>
        <span class="dt">value</span><span class="op">:</span> Float<span class="op">,</span>
        <span class="dt">unit</span><span class="op">:</span> Distance
    <span class="op">},</span>
    <span class="dt">description</span><span class="op">:</span> String
    <span class="dt">ts</span><span class="op">:</span> Date
<span class="op">}</span></code></pre></div>
<p><strong><span id="list-02_data-categories">List 02: relevant (sub-)categories of data</span></strong></p>
<ul>
<li>Finance
<ul>
<li>Income</li>
<li>Bank transfers</li>
</ul></li>
<li>Shopping history</li>
<li>Things/Objects</li>
<li>Media consumption
<ul>
<li>Music playlist</li>
<li>Watchlist</li>
</ul></li>
<li>Favorites/Interests
<ul>
<li>Music genres</li>
<li>Songs</li>
<li>Movies</li>
<li>Books</li>
<li>Travel destinations</li>
<li>Topics</li>
</ul></li>
<li>Curriculum vitae (CV)
<ul>
<li>Educational level</li>
<li>Visited schools</li>
</ul></li>
<li>Visited …
<ul>
<li>points of interest</li>
<li>countries</li>
<li>websites/URLs (browser history)</li>
</ul></li>
<li>Units (measurements)</li>
<li>Organisations
<ul>
<li>Company</li>
<li>Bank</li>
<li>…</li>
</ul></li>
<li>Medical/Health Record
<ul>
<li>Diseases</li>
<li>Treatments</li>
<li>Visits to the doctor</li>
<li>Medication</li>
</ul></li>
</ul>
<p>The available <em>primitives</em> mainly depend on those who are supported by the query language itself. In this case, all <em>primitives</em> mentioned above are supported by <em>SPARQL</em> <span class="citation" data-cites="web_spec_xml_types">[<a href="#ref-web_spec_xml_types">129</a>]</span> and <em>GraphQL</em> <span class="citation" data-cites="web_spec_graphql_types">[<a href="#ref-web_spec_graphql_types">130</a>]</span>. When choosing a database system it has to be ensured that either the system already supports the required <em>primitives</em> or they can be emulated somehow with a least amount of drawbacks. When modelling relations between data point one can use for example keys (or identifiers) to make reference, or additional syntactical tools like <em>lists</em> (or arrays) and maps (or objects). Those tools facilitate readability so that relations are almost intuitively observable, therefore they should be enforced. Whereas another know concept in data modelling, inheritance, isn’t required, but could help to reason about certain <em>structs</em> and their representations, it might add complexity though.</p>
<p>Aside form the <em>subject’s</em> <em>personal data</em> other information and data must be persist as well. This includes for example:</p>
<ul>
<li>Application data
<ul>
<li>Templates (<a href="#pi05">P.I.05</a>)</li>
<li>permission profiles (incl. versioning)</li>
<li>consumer information</li>
<li>meta data</li>
<li>notifications</li>
<li>states</li>
<li>tokes</li>
<li>access logs</li>
</ul></li>
<li>Files
<ul>
<li>cryptographic keys</li>
<li>executable program</li>
<li>container images</li>
<li>configurations</li>
<li>user interfaces</li>
<li>documentations</li>
</ul></li>
</ul>
<p>The list revels that not only a database system is needed to satisfy the requirements, but the environments filesystem might need to be utilized as well. This leads to the the question what requirements a database system has to satisfy. But first of all it is pivotal to distinguish between the needs of a <em>personal data storage (PDS)</em> and a general <em>persistence layer (PL)</em> for the system’s backend.</p>
<a name="tbl:dbs-features"></a>
<table style="width:81%;">
<caption>Table 1: selection of characteristics that a database system has to feature in order to be suitable for either of the defined purposes </caption>
<colgroup>
<col style="width: 40%" />
<col style="width: 22%" />
<col style="width: 18%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Characteristic</th>
<th style="text-align: center;">Personal Data Storage</th>
<th style="text-align: center;">Persistence Layer</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">portable</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">advanced user &amp; permission management</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>X</strong></td>
</tr>
<tr class="odd">
<td style="text-align: left;">document-oriented</td>
<td style="text-align: center;"><strong>X</strong></td>
<td style="text-align: center;"><strong>X</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">support common primitives</td>
<td style="text-align: center;"><strong>X</strong></td>
<td style="text-align: center;"><strong>X</strong></td>
</tr>
<tr class="odd">
<td style="text-align: left;">replication</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>X</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">efficient binary storage and serialization</td>
<td style="text-align: center;"><strong>X</strong></td>
<td style="text-align: center;"><strong>X</strong></td>
</tr>
<tr class="odd">
<td style="text-align: left;">high performance</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>X</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">operations and transactions</td>
<td style="text-align: center;"><strong>X</strong></td>
<td style="text-align: center;"><strong>X</strong></td>
</tr>
<tr class="odd">
<td style="text-align: left;">background optimization</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>X</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">version control</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Although, most of the characteristics (in Table <a href="#tbl:dbs-features">1</a>) are self explanatory, certain aspects need to be commented on. Fist, portability, an important requirement (<a href="#sa02">S.A.02</a>), which is oddly not marked in the Table <a href="#tbl:dbs-features">1</a>. That’s because of the priorly introduced concept of abstracting the <em>personal data storage</em> with a additional query language. This makes the access to the <em>PDS</em> platform-agnostic. Whereas the database system storing that data can be implemented with respect to the requirements while considering the environment constraints at the same time. Basic permission management should suffice the <em>PDS</em>, since it’s not differently accessed in multiple ways. It’s only relates to the query language abstraction. Data and especially it’s structure is expected to be highly fluctuant (<a href="#sp02">S.P.02</a>), thus advantages of relational databases (e.g. schema-oriented and -optimized) would instead harm the performance and flexibility, because they are not primarily designed to handle schema changes. Database systems, whose storage engine is build upon a document-oriented approach, would be a better choice. Replication can be used for horizontal scaling, federation and backups (<a href="#sp05">S.P.05</a>). Here it is focused on the latter, because without <em>PL</em> the <em>PDaaS</em> wont be able to function. In case of irreversible data loss, the whole system state is gone, which then has to be reconfigured and reproduced from the ground up. Such effort can be spared by introducing a reliable backup strategy. With the <em>PDS</em> on the other hand replication is not necessary, but ensuring no data loss still needs to be addressed. Therefor every database system that might be used for the <em>PDS</em> must provide a mechanism to backup or at least to export the data, which can be triggered and obtained through the <em>operator’s</em> management tool. Another approach could be to not only store the actual data written to the <em>PDS</em> but also to save all queries used to write that data in a chronological order. Therefore the current state can be restored just by running those writing queries against the <em>PDS</em>. It is reasonable to store the the queries from the abstracted query language not the ones the query language is transformed into. If a mobile device is part of the <em>PDaaS</em>, another approach would be for the <em>operator</em> could be to perform regular device backups. These are all just initial thoughts which might be sufficient only as a starting point. Other solutions are imaginable, but elaborating on those is beyond the scope of this work. Depending on what technologies are being used, it might be necessary from a conceptional perspective to split the <em>PL</em> into two parts. One part is a database system and the other is represented by the environment’s filesystem. This might be no alternative, when it comes to configuration files certain technologies or key files, which are typically accessed as files. In any case, both have to be able to store files of any kind, which is required for instants to support the use case of medical records. File size restriction should be mandatory though. The <em>PDaaS</em> has no intention to replace existing <em>file hosting</em> solutions.</p>
<p>Being able to revert certain data points or to review the change-history of those data, can be very useful; not only when those changes were persisted mistakenly. This behaviour might not be necessary for every data, especially when it comes to application configuration or logs. Also, not every <em>operator</em> might require those features. Therefore and because database systems with no alternative might not be able to provide this capability, it’s not required by either the <em>PDS</em> or the <em>PL</em>. If it not natively supported but still desired, it needs to be considered if for example high frequently backups would already suffice or if a implementation on the application is required.</p>
<p>Before serving data it first needs to be put into the <em>PDS</em>. This can be done in three different ways:</p>
<ol type="1">
<li>the <em>data subject</em> is provided with forms by the visual user interface, which she is using to insert data about her, for example her <a href="#code-05_struct_profile">profile information (Code 05)</a>. This data is then submitted into the <em>PDaaS</em> which takes care of storing it.</li>
<li>the <em>data subject</em> is in possession of file(s) or string(s) that contain a data format that is supported by the system. The visual user interface provides a mechanism to either upload the file(s) or insert the string(s), thereby the data is then send into the system. If this raw data is not self-explaining to the system the <em>data subject</em> has to elaborate on the context of those data.</li>
<li>Third party software, for example a browser plugin, is used to provide the <em>PDaaS</em> with data; in this case it’s a browser history. This software uses a restricted API which is provided by the <em>PDaaS</em>, to let data flow into the system.</li>
</ol>
<p>These three concepts, especially 2. and 3. are required to be inspected for malicious content and extensively validated against existing <em>structs</em>. Only if these are matching, the submitted data can be stored. In the second version the <em>data subject</em> need to be ask to review the imported data to make sure everything is as expected. When enabling third party software to submit data, appropriate authentication and permission mechanisms must be in place. That software is classed like all other <em>operator</em> clients, but without permissions to obtain data.</p>
<p><em><strong>Conclusions:</strong></em> In order to gain flexibility in choosing technology and location for the <em>personal data storage</em>, the logical consequence is to abstract the interface to to the database system. Introducing a separate query language is proposed as a reasonable approach. It can be chosen between two suggested query languages, <em>GraphQL</em> or <em>SPARQL</em>. Both provide the necessary features required to integrate them in a distributed system; <em>SPARQL</em> with it concepts of URIs as identifiers and resources, and <em>GraphQL</em> with it’s separation of query definition and execution. This also has an effect on the process of query validation, which is much harder to do for <em>SPARQL</em>, because its syntax is more flexible and allows some shorthands. In general <em>SPARQL’s</em> syntax is harder to reason about compared to <em>GraphQL</em>. And even though the result of both languages is formatted in JSON, only <em>GraphQL</em> preserves all the relations which are embedded in the query syntax, in the output as well. Therefore <em>GraphQL</em> (and its implementations) is the query language of choice for this project.</p>
<p>Engaging a user community when it comes to creating new structs can compensate the lack of certain types. Examples for a potential start point of <em>PDaaS</em> supported data types were showed before. Data Modelling in general is a large research field for it’s own. With regards to the <em>PDaaS</em> it needs much more work, though tt’s beyond the scope of this document. The basic approaches within this section should only be viewed as an introduction that gives an outlook of how it’s imagined.</p>
</section>
<section id="architecture" class="level2">
<h2><span class="header-section-number">6.6</span> Architecture</h2>
<p>By taking all previous sections, their discussions and the requirements as well into account, this section serves the sole purpose of figuring out how all the different concepts and conclusions discussed before can fit together in an overall system architecture that is organized in either a distributed or a monolithic manner. This type of changes should not impact how the system’s interfaces behave from a user perspective.</p>
<p>The foundation of this project is a server-client Architecture, which is chosen for a) providing availability (<a href="#sa05">S.A.05</a>) and b) separating some concerns <span class="citation" data-cites="web_2016_wikipedia_separation-of-concerns">[<a href="#ref-web_2016_wikipedia_separation-of-concerns">131</a>]</span>. Such a distributed system provides various locations to place these concerns, which are in fact different environments with different properties. Those combinations of locations and environments are herein after called <em>platforms</em>. To further describe these <em>platforms</em> characteristics such as architectural layer and access possibilities to it’s internals are taken into account. This results in the following three types of <em>platforms</em>:</p>
<a name="tbl:platforms-characteristics"></a>
<table>
<caption>Table 2: All platform types where components of the <em>PDaaS</em> architecture can be placed </caption>
<colgroup>
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 12%" />
<col style="width: 35%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Type</th>
<th style="text-align: center;">trusted</th>
<th style="text-align: center;">private</th>
<th style="text-align: center;">controlled by</th>
<th style="text-align: center;">Layer</th>
<th style="text-align: left;">Purpose</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><p>Server</p></td>
<td style="text-align: center;"><p>yes</p></td>
<td style="text-align: center;"><p>yes</p></td>
<td style="text-align: center;"><p>data subject</p></td>
<td style="text-align: center;"><p>back end</p></td>
<td style="text-align: left;"><ul>
<li>business logic</li>
<li>third-party interfaces</li>
<li>data storage</li>
</ul></td>
</tr>
<tr class="even">
<td style="text-align: left;"><p>Desktop</p></td>
<td style="text-align: center;"><p>no</p></td>
<td style="text-align: center;"><p>no</p></td>
<td style="text-align: center;"><p>data subject</p></td>
<td style="text-align: center;"><p>front end</p></td>
<td style="text-align: left;"><ul>
<li>based on web technologies</li>
</ul></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><p>Mobile</p></td>
<td style="text-align: center;"><p>no</p></td>
<td style="text-align: center;"><p>conditionally</p></td>
<td style="text-align: center;"><p>data subject</p></td>
<td style="text-align: center;"><p>front end</p></td>
<td style="text-align: left;"><ul>
<li>typically mobiles devices</li>
<li>based on host-specific native technologies</li>
<li>data storage</li>
</ul></td>
</tr>
</tbody>
</table>
<p>The next step is to determine those components, that are required in order to cover most of the defined use cases. The conglomeration below highlights all major components, including the platforms in which they could be positioned, in addition to further details about their purpose(s) and relation(s) to each other.</p>
<section id="web-server" class="level5">
<h5><span class="header-section-number">6.6.1.0.1</span> Web server</h5>
<p><em>Platform:</em> Server</p>
<p><em>Purpose:</em></p>
<ul>
<li>serve web-based user interface(s)</li>
<li>handle all in- &amp; outgoing traffic (outmost layer)</li>
<li>revers proxying certain traffic to different components</li>
<li>en- &amp; decrypt HTTPS traffic, thus authenticate <em>consumers</em></li>
<li>load balancing (if necessary)</li>
<li>web client notification</li>
</ul>
<p><em>Technologies:</em></p>
<ul>
<li>HTTP</li>
<li>TLS</li>
<li>WebSockets</li>
</ul>
</section>
<section id="permission-manager" class="level5">
<h5><span class="header-section-number">6.6.1.0.2</span> Permission Manager</h5>
<p><em>Platform:</em> Server</p>
<p><em>Purpose:</em></p>
<ul>
<li>creating <em>permission profiles</em></li>
<li>permission validation</li>
<li>examine data queries</li>
<li>queue <em>consumer</em> requests</li>
</ul>
<p><em>Technologies:</em></p>
</section>
<section id="pki" class="level5">
<h5><span class="header-section-number">6.6.1.0.3</span> PKI</h5>
<p><em>Platform:</em> Server</p>
<p><em>Purpose:</em></p>
<ul>
<li>CA</li>
<li>manage keys and certificates per <em>endpoint</em></li>
<li>obtain trusted certificates from public CAs</li>
</ul>
<p><em>Technologies:</em></p>
<ul>
<li>X.509</li>
<li>ACME <span class="citation" data-cites="web_spec_acme">[<a href="#ref-web_spec_acme">132</a>]</span> (Let’s Encrypt)</li>
</ul>
</section>
<section id="storage-connector" class="level5">
<h5><span class="header-section-number">6.6.1.0.4</span> Storage Connector</h5>
<p><em>Platform:</em> Server</p>
<p><em>Purpose:</em></p>
<ul>
<li>abstracts to system agnostic Query Language</li>
<li>queries personal data, regardless of where it’s located</li>
</ul>
<p><em>Technologies:</em></p>
<ul>
<li>driver for used database</li>
</ul>
</section>
<section id="operator-api" class="level5">
<h5><span class="header-section-number">6.6.1.0.5</span> Operator API</h5>
<p><em>Platform:</em> Server</p>
<p><em>Purpose:</em></p>
<ul>
<li>authenticates <em>operator</em></li>
<li>writes personal data through Storage Connector</li>
<li>provides relevant data, such as history</li>
<li>system configuration</li>
<li>automated data inflow</li>
</ul>
<p><em>Technologies:</em></p>
<ul>
<li>JWT</li>
</ul>
</section>
<section id="code-execution-environment" class="level5">
<h5><span class="header-section-number">6.6.1.0.6</span> Code Execution Environment</h5>
<p><em>Platform:</em> Server</p>
<p><em>Purpose:</em></p>
<ul>
<li>isolated runtime (sandbox) for computations/programs provided by <em>consumers</em></li>
<li>restrict interaction with outer environment to absolute minimum (e.g. no shared filesystem or network)</li>
<li>one-time use</li>
<li>monitor sandbox during computation</li>
<li>examine and test the provided software</li>
</ul>
<p><em>Technologies:</em></p>
<ul>
<li>Virtualization</li>
<li>Container (OCI)</li>
</ul>
</section>
<section id="tracker" class="level5">
<h5><span class="header-section-number">6.6.1.0.7</span> Tracker</h5>
<p><em>Platform:</em> Server</p>
<p><em>Purpose:</em></p>
<ul>
<li>log all changes made with <em>Storage Connector</em></li>
<li>tracks states for ongoing consumer requests</li>
<li>log all <em>access requests</em></li>
</ul>
<p><em>Technologies:</em></p>
</section>
<section id="personal-data-storage" class="level5">
<h5><span class="header-section-number">6.6.1.0.8</span> Personal Data Storage</h5>
<p><em>Platform:</em> Server, Mobile</p>
<p><em>Purpose:</em></p>
<ul>
<li>stores the <em>operator’s</em> personal data</li>
</ul>
<p><em>Technologies:</em></p>
<ul>
<li>non relational database</li>
<li>depending on host environment</li>
</ul>
</section>
<section id="persistence-layer" class="level5">
<h5><span class="header-section-number">6.6.1.0.9</span> Persistence Layer</h5>
<p><em>Platform:</em> Server</p>
<p><em>Purpose:</em></p>
<ul>
<li>stores Permission Profiles, History, Tokens, Configurations and other application data</li>
<li>cache runtime data and information</li>
<li>holds keys</li>
</ul>
<p><em>Technologies:</em></p>
<ul>
<li>non relational database</li>
<li>Filesystem</li>
</ul>
</section>
<section id="notification-infrastructure" class="level5">
<h5><span class="header-section-number">6.6.1.0.10</span> Notification Infrastructure</h5>
<p><em>Platform:</em> Server</p>
<p><em>Purpose:</em></p>
<ul>
<li>notifies about everything that needs <em>operator’s</em> approval (e.g. new registrations, new <em>permission requests</em>)</li>
</ul>
<p><em>Technologies:</em></p>
<ul>
<li>WebSockets for web UIs via local web server</li>
<li>mobile device manufacturer’s Push Notification server for mobile apps</li>
</ul>
</section>
<section id="user-interface" class="level5">
<h5><span class="header-section-number">6.6.1.0.11</span> User Interface</h5>
<p><em>Platform:</em> Desktop, Mobile</p>
<p><em>Purpose:</em></p>
<ul>
<li>access restricted to <em>operator</em> only</li>
<li>access &amp; permission management</li>
<li>data management (editor, types &amp; import)</li>
<li>history and log viewer</li>
<li>system monitoring</li>
</ul>
<p><em>Technologies:</em></p>
<ul>
<li>HTML, CSS, Javascript</li>
<li>Java</li>
<li>Swift, Objective-C</li>
</ul>
<p>After outlining all different components while keeping the aspect of portability (<a href="#sa02">S.A.02</a>) in mind, it needs to be figured out which arrangements make sense and what variations might be possible. The result are two, more or less, distinct designs that are proposed. As stated above, one is a more monolithic approach and the other involve more platform types and demonstrates the flexibility.</p>
<figure>
<img src="./assets/figures/TODO_pdaas_component-composition_monolithic.jpg" alt="Figure 1: PDaaS Architecture, monolithic composition" id="fig:composition-monolithic" /><figcaption>Figure 1: PDaaS Architecture, monolithic composition</figcaption>
</figure>
<figure>
<img src="./assets/figures/TODO_pdaas_component-composition_distributed.jpg" alt="Figure 2: PDaaS Architecture, distributed composition" id="fig:composition-distributed" /><figcaption>Figure 2: PDaaS Architecture, distributed composition</figcaption>
</figure>
<p>The main difference between the two compositions is the lack of the mobile platform in the more monolithic approach (Figure <a href="#fig:composition-monolithic">1</a>). Although <em>monolithic</em> refers only to the components arrangement on the <em>server</em> platform. It is also imaginable that all server components not necessarily have to be placed into one server environment, but being distribute over several virtual machines or containers, so that they can scale and run more independently. This can improve <em>redundancy</em> as well.</p>
<p>In theory, a possible version of the arrangement would be to move all components to either the client or the mobile platform. This comes along with some downsides and major issues that are anything but trivial to solve. Aside from ensuring a nearly 100% uptime and localization in a landscape where NAT<a href="#fn28" class="footnoteRef" id="fnref28"><sup>28</sup></a> and dynamic IPs are still common practice, not only on the mobile platform but on the client platform as well, all component, but the user interface, needs to be implemented with native technologies. Nevertheless, from a <em>operator’s</em> perspective it would mean having all components at hand and therefore full control over the <em>PDaaS</em>, it still would lack of major requirements, though.</p>
<p>Aside from providing the <em>operator</em> with a non-stationary and instantly accessible interface to her <em>PDaaS</em>, involving a <em>mobile platform</em> has the purpose of enabling the <em>data subject</em> to carry all her sensitive data along. This is considered a major advantage over the monolithic approach, were all the personal data is located in the <em>“cloud”</em>. Depending on the perspective, it can either be seen as a <em>singe source of truth</em> or a <em>single point of failure</em>. Regardless of that, it introduces the demand of a backup or some redundancy concept, which has briefly been touched on in the discussion about database system requirements within the <a href="#data"><em>data</em> section</a>. A mobile platform being part of the system makes it more easier for the <em>data subject</em> to establish a security concept, in which the relation the between personal data storage and the rest of the system is much more liberated, so that all access attempts only happen under full supervision. It is debatable whether to place the <em>permission profiles</em> in the <em>persistence layer</em> among all other domain-related information, or put it into the <em>personal data storage</em> as well or define it as an own storage component, in order to be flexible regarding it’s location.</p>
<p>Authenticating <em>consumers</em> is performed based on TLS by the web server and it’s configured subdomains including their individual keys and certificates provided by the <em>PKI</em>. The <em>operator</em> authentication is either done by the <em>Operator API</em> or by the <em>web server</em>, depending on the <em>web server’s</em> capabilities. Though, it makes more sense, to entrust the <em>web server</em> with that task, because it’s the outmost component and it would prevent unauthorized and potential malicious requests from getting further into the system. And since a native client on a mobile platform is considered <em>private</em>, it is reasonable to change the <em>operator</em> authentication from JWT-based to TLS-based <em>two-way authentication</em>, which would otherwise be inconvenient when using web-based clients.</p>
<p>If there are components that are only placed on the server and that have to communicate between each other, but are separated into independent processes, then some inter-process communication need to be established (e.g. sockets). It is also conceivable that inter-communication between server components could be unidirectional only. Approaches like changing configuration files by writing to the filesystem can therefor be feasible in some cases. Components that can vary in terms of their platform, have to communicate to the other components via <em>HTTPS</em>.</p>
<p>The architecture implicitly distinguishes between two different groups of endpoints. These endpoints are made available by the <em>web server</em>, which reverse-proxys incoming connections to role-related (<em>operator</em> or <em>data consumer</em>) components. Starting from that, this separation can be driven further by simply encapsulating those components into services, that either are related to one of the roles or used by both. This basically results in the <em>web server</em> communicating with the two role-services in a bidirectional manner. The group of endpoints for <em>data consumers</em> mainly consists of those were <em>access requests</em> and <em>permission requests</em> are coming in and the public one, that is used for <em>consumer</em> registrations. The other one is a small group of endpoints required for all the tools the <em>operator</em> might need; from data API or notification through to authentication and web-based user interface.</p>
<p>Considering the rapid growth of emerging website and applications, which all require user registration, users are getting tired of creating new accounts. Hence they tend to reuse their password(s). Providers started outsource that sensitive topic of user management by integrating third party authentication services, which not only makes is almost effortless to implement, but also leaves the responsibility as well as the accessibility to those service owners. Whereas users get the benefit of just using one account for all her apps - a universal key so to say, but only one exemplar. So the downside here is, only a handful of third parties <span class="citation" data-cites="web_2009-success-of-facebook-connect">[<a href="#ref-web_2009-success-of-facebook-connect">133</a>]</span> provide those authentication services.<br />
OpenID is designed with a very specific type of scenarios in mind, namely the one just described - bringing decentralisation to the market of authentication services - which differs from those addressed by the <em>PDaaS</em>; at least, when it comes to <em>data consumer</em> interactions. Although, the <em>PDaaS</em> has the ability to become the digital representation of it’s <em>operator</em>. Hence it can and also should be used to authenticate that individual against an external parties.</p>
<p><em><strong>Conclusions:</strong></em> Considering amount of effort a single-platform version, namely client or mobile, would take to get fully operational with respect to the specification, it is not only reasonable but also more secure to involve a server environment with proper security measures, static IP and high availability. Even if that server is a local machine connected to the <em>data subject’s</em> private network. That said, it is sufficient to start with the <em>monolithic</em> approach and as suitable mobile applications emerge that are supporting major administration features, notifications and <em>personal data storage</em>, it should be possible to migrate effortlessly towards the <em>distributed</em> approach that comes with a higher level , because all the sensitive personal data somewhere on a computer machine. As of the proposed architecture all components (or group of components) are portable and therefore relocatable among the suggested platforms; and with the introduced authentication method for <em>operators</em> using multiple clients the for the same <em>PDaaS</em> are thereby supports and can be implemented with almost no effort, which covers more use cases. As a supplement, an <em>identity provider</em> based on the OpenID standard would fit nicely into the existing arrangement and not interfering with the other components. However, it is beyond the scope of this work to make elaborate on this topic. For now it is stated as a feasible and logical addition to the <em>PDaaS</em>.</p>
</section>
</section>
<section id="environment-and-setup" class="level2">
<h2><span class="header-section-number">6.7</span> Environment and Setup</h2>
<p>As stated in the project’s core principles <em>Open Development</em> is vital for the project to gain trust. Interestingly, this has a significant impact on how a <em>PDaaS</em> might be deployed or installed. All its components can just get taken and used as it suits everyone’s needs; of cause, while respecting their licenses. Furthermore, enforcing <em>portability</em> leads to a more simplified and independent development process that can be organized in a way so that the primary division into components can be leveraged.</p>
<p>The range of environment systems for <em>server</em> platforms is highly diverse but the main shares belong to either the UNIX or LINUX family, even though almost every platform is POSIX-compliant.<a href="#fn29" class="footnoteRef" id="fnref29"><sup>29</sup></a> When it comes to <em>mobile</em> platforms the market is fare less divers. Native applications are either developed in <em>Java</em> (for Google’s Android) or in Swift (for Apple’s iOS). Whereas the environment systems has nearly no relevance for the <em>client</em>, other then the screen size and maybe which browser and version the environment system runs. But that’s probably something the user can change.</p>
<p>As a result, being able to use certain components on a <em>server</em> platform depends on what <em>server</em> environment is provided. And vice versa, in order to decide on what implementation of a component is suitable, it’s crucial in what environment that component has to run in. Either way, not to forget all the dependencies a component might have. Such constraints can be avoided by abstracting the runtime of those components and either embed every required software dependency or provide them in separate runtimes, if that’s possible. Depending on the technologies used, this concept is commonly known as <em>virtualization</em> or <em>containerization</em>. It isolates software by putting them into so called <em>container</em>. But since those container-wrapped components still have to interact with each other, they need to be supervised or at least managed. This is done by an orchestration software, which not only allocates system resources but also emulates a whole network infrastructure (e.g. DNS, TCP/IP, routing). Thereby, it is used to determine how certain container (and its containing component) are allowed to communicate and what resource are accessible from inside (e.g. filesystem). This complete abstraction to the surrounding environment means it quasi is the only dependency the <em>PDaaS</em> would have, regardless of how its components are implemented. They just have to be <em>“containerizable”</em> - satisfy the <em><a href="#link-container">container image specification</a></em> <span class="citation" data-cites="web_oci-spec_image">[<a href="#ref-web_oci-spec_image">106</a>]</span>. This concept can be utilized for the <em><a href="#supervised-data-access">supervised code execution</a></em> (<a href="#sa01">S.A.01</a>) mentioned before without any restraints.</p>
<p>Migrating from a server-located <em>personal data storage</em> to the <em>mobile</em> based version introduces another challenge. The subsequent approach is a first and more general solution to that problem.</p>
<p><em>NOTICE: it is assumed that a running instance of a </em>PDaaS* is in place, the <em>operator</em> owns a modern mobile device and on this device a <em>PDaaS</em> client application is installed.*</p>
<ol type="1">
<li><p>After starting the app, the <em>operator</em> needs to establish a connection between the server and mobile application. Therefor the <em>operator</em> either has to scans a QR-Code with the help of that app. THe QR-Code is presented to the <em>operator</em> within her personal management interface of the <em>PDaaS</em> running in a browser. Or the <em>operator</em> inserts her credentials in to a form presented by the mobile application.</p></li>
<li><p>After the connection has established, the <em>operator</em> can trigger a progress that duplicated all her <em>personal data</em> to the device that just has been associated with the <em>PDaaS</em>.</p></li>
<li>At this point one of two ways can be proceeded, depending on whether a complete write log for the <em>personal data</em> (<a href="#data">see discussion about backup strategies</a> does exist or not.
<ol type="a">
<li><em>[LOG-EXISTS]</em> query by query the whole log is obtained from the existing storage and is then again executed in chronologically order by the query language abstraction. The only difference here is that the target storage,on which that query is actually performed on, is located on that newly introduced platform</li>
<li>If the <em>[LOG-NOT-EXISTS]</em>, the situation is more complicated, if the database systems are not based on exactly the same technology. Hence, additional migration software is required. If both database systems provide import and export mechanisms that support at least one interoperable data format, the migration software can leverage this features simply by exporting all the data and saving it to the filesystem. The software then transfers dump to the target environment and triggers the import process. Otherwise, the software not only needs to be aware of both database systems and their native query, it also has to have a comprehensive understanding of how their data structuring concepts work, in order to reliably transform one into the other. So to be more specific, at first the software has to analyse the structure of source database. Based on this result it might need to perform some configuration on the target database, before actually obtaining the data from the source database. The received data then need to be transformed into queries that are supported by the target system. Those transformed queries are transferred to the target environment, where those incoming queries get executed until all data is migrated.</li>
</ol></li>
<li><p>After thr duplication process has finished, the <em>operator</em> can decide which <em>PDS</em> the <em>PDaaS</em> should use to serve <em>access requests</em> and what should happen with the other storage(s).</p></li>
</ol>
<p>So to conclude, a migration process of moving <em>personal data</em> from one platform instance to another can be much more simplified and robust, if a complete query log would exist. It is also worth mentioning, that the migration process described above is not restricted to exactly this source or migration direction. As long as target and source are either a <em>server</em> or a <em>mobile</em> platform, any variant is imaginable.</p>
<p><em><strong>Conclusions:</strong></em> Installing a <em>PDaaS</em> should be straightforward with the least possible effort being used for preparations. Package manager of all popular operating systems should offer (semi-)automated installations. Additionally, components themselves and the project as whole have to provide detailed documentations for various ways of how those parts or the entire system need to be installed. Alternatively, <em>data subjects</em> might be are willing to entrust external third parties with hosting a <em>PDaaS</em> instance for them. In that case the distributed approach involving a <em>mobile</em> platform might come in handy, so that the actual data is not stored somewhere beyond their reach. THe <em>PDaaS</em> as an open source development encourages anybody who is interested or even wants to contribute to checkout the source code of the various implementations, get it to run and play around with it. But for that at least the components of the <em>server</em> platform are required to have documented on what other software they depend on, so that the target environment can be prepared accordingly. Aside from hardware on which the <em>PDaaS</em> needs to run, the only other requirement is owning a internet domain that is registered on a public DNS<a href="#fn30" class="footnoteRef" id="fnref30"><sup>30</sup></a> server and has no subdomains configured yet.</p>
<p>If a component needs to get segregated from its host environment, <em>containerization</em> is the recommended technique, since it causes less overhead compared to <em>virtualization</em> and is generally a lightweight approach. Though, additional abstraction might also introduce new problems instead of solving them.</p>
</section>
<section id="user-interfaces" class="level2">
<h2><span class="header-section-number">6.8</span> User Interfaces</h2>
<p>conceiving visual user interfaces is beyond the scope of this work and the specification.</p>
<ul>
<li>has to be visual?</li>
<li>what about an api? e.g. for third party apps (for operator) - maybe self fulfilling because open source</li>
<li>Internal:
<ul>
<li>UI for Management &amp; Administration</li>
<li>Authentication/login</li>
</ul></li>
</ul>
<p>list all different features (w/ respect to the requirements) and give a suggestion on how a solution would look like; e.g. graph data structure with accordion menus/dropdowns</p>
<ul>
<li>when a data point is a Date or location, some kind of accuracy should be able to defined (in user interface)</li>
</ul>
<p>TOD: data Consumption (data inflow) - how data will get into the system - hwo is the user able to do that, and how does it works - manually and automated</p>
<p><em><strong>Conclusions:</strong></em></p>
</section>
</section>
<section id="specification-draft" class="level1">
<h1><span class="header-section-number">7</span> Specification <em>(Draft)</em></h1>
<p>This chapter hold the first draft of what might become a specification. As for now it has therefore no claim of completeness, continuity or accuracy. The contents is based on and a result of all previous discussions and developed solutions.</p>
<p>TODO: should might must n stuff in table (see dark mail spec)</p>
<section id="overview" class="level2">
<h2><span class="header-section-number">7.2</span> Overview</h2>
<ul>
<li>purpose</li>
<li>architectural overview</li>
<li>short description of the whole process</li>
</ul>
</section>
<section id="components" class="level2">
<h2><span class="header-section-number">7.3</span> Components</h2>
<section id="webserver" class="level3">
<h3><span class="header-section-number">7.3.2</span> Webserver</h3>
</section>
<section id="user-interface-1" class="level3">
<h3><span class="header-section-number">7.3.3</span> User Interface</h3>
</section>
<section id="storagepersistence" class="level3">
<h3><span class="header-section-number">7.3.4</span> Storage/Persistence</h3>
</section>
<section id="notification-infrastructure-1" class="level3">
<h3><span class="header-section-number">7.3.5</span> Notification Infrastructure</h3>
</section>
<section id="data-api" class="level3">
<h3><span class="header-section-number">7.3.6</span> Data API</h3>
</section>
</section>
<section id="data-1" class="level2">
<h2><span class="header-section-number">7.4</span> Data</h2>
<section id="structure-types" class="level3">
<h3><span class="header-section-number">7.4.2</span> Structure &amp; Types</h3>
<ul>
<li>henceforth only two things: primitive and struct</li>
<li>supported date types</li>
</ul>
</section>
<section id="read" class="level3">
<h3><span class="header-section-number">7.4.3</span> Read</h3>
</section>
<section id="write" class="level3">
<h3><span class="header-section-number">7.4.4</span> Write</h3>
</section>
</section>
<section id="protocols" class="level2">
<h2><span class="header-section-number">7.5</span> Protocols</h2>
<section id="consumer-registration" class="level6">
<h6><span class="header-section-number">7.5.1.0.0.1</span> Consumer registration</h6>
<ol start="0" type="1">
<li><p>[OPTIONAL] <em>data subject</em> provides URI to <em>data consumers</em></p></li>
<li><em>data consumers</em> create <em>permission request</em> that includes
<ul>
<li>X.509 based CSR<a href="#fn31" class="footnoteRef" id="fnref31"><sup>31</sup></a></li>
<li>callback URI via HTTPS as feedback channel</li>
<li>[OPTIONAL] information about what data points wanted to be accessed</li>
</ul></li>
<li><p>depending on 0), <em>data consumer</em> provides <em>operator</em> with priorly created <em>permission request</em> either as QR-Code or via HTTPS by given URI</p></li>
<li><em>operator</em> reviews request and decides to either refuse or grant assess; the latter results in:
<ol type="a">
<li>creating new <em>endpoint</em>
<ul>
<li>create new unique subdomain and a related asymmetric key pair signed by the system’s root CA (self-signed)</li>
<li>issue <em>consumer</em> certificate based on it’s CRS and sign it with the key pair related to this <em>endpoint</em></li>
</ul></li>
<li>if information is provided, creating new <em>permission profile</em> by either applying existing draft/template or configuring <em>permission type</em> (incl. expiration date if required) and permitted data endpoints; associate to specific <em>endpoint</em></li>
</ol></li>
<li><em>data consumers</em> gets informed about the decision via callback channel
<ul>
<li>on grant, response includes
<ul>
<li><em>consumer’s</em> certified certificate</li>
<li>certificate that’s associated with the created endpoint</li>
<li>information on what data points are allowed to be accessed;</li>
</ul></li>
<li>on refusal: error code/message</li>
</ul></li>
<li><em>data consumer</em> handles the response appropriately
<ul>
<li>[OPTIONAL] pin the provided <em>PDaaS</em> certificate</li>
</ul></li>
</ol>
</section>
<section id="data-access" class="level6">
<h6><span class="header-section-number">7.5.1.0.0.2</span> Data Access</h6>
<ol start="0" type="1">
<li><p>after successfully authenticated, <em>consumer</em> sends <em>access request</em></p></li>
<li>request contains at least the <em>data query</em>; based on that query and the <em>permission profiles</em>, access is tried to get verified
<ol type="a">
<li>on success, response gets computed</li>
<li>on failure, error code/message is responded; process aborts
<ul>
<li>if the error was raised because no appropriate <em>permission profile</em> was found, then the <em>consumer</em> first needs to request permission for the <em>data points</em> that were part of the query</li>
</ul></li>
</ol></li>
<li><p>[OPTIONAL] depending on whether the <code>keepalive</code> flag was set <code>true</code>, the connection of this requests lasts until response computation has finished or timeout has reached, otherwise the response contains a URI unique to this current request including an estimation when response will be available under that URI; connection can still timeout, which is defined by the system</p></li>
<li>depending on the type of that <em>access request</em>,
<ol type="A">
<li>the data get queried and the result is added to the response</li>
<li>based in further information provided by the request, the environment for the <em>supervised code execution</em> is getting provisioned, the program from the <em>consumer</em> will be ran against various tests
<ol type="a">
<li>in fail, error code/message get added to the response</li>
<li>on pass, computed result gets added to the response</li>
</ol></li>
</ol></li>
<li><p>response is finalized and gets returned back to the <em>consumer</em>, either as a response to this request or provided under the unique URI as of 2)</p></li>
</ol>
</section>
<section id="permission-validation" class="level6">
<h6><span class="header-section-number">7.5.1.0.0.3</span> Permission Validation</h6>
<p>TODO: detailed description of the algorithm that checks <em>permission profiles</em> according to an <em>access request</em>; including all different possible cases (multiple profiles for one consumer etc)</p>
</section>
<section id="add-or-change-personal-data" class="level6">
<h6><span class="header-section-number">7.5.1.0.0.4</span> Add or Change Personal Data</h6>
</section>
<section id="data-management" class="level3">
<h3><span class="header-section-number">7.5.2</span> Data Management</h3>
<ul>
<li>one third party access (consumer) relates to one access <em>endpoint</em>, that also authenticates that third party by TLS based <em>two-way auth</em></li>
<li>zero or more <em>permission profiles</em> are associated to one <em>endpoint</em></li>
</ul>
</section>
</section>
<section id="apis" class="level2">
<h2><span class="header-section-number">7.6</span> APIs</h2>
<p><strong>Registration Request</strong></p>
<ul>
<li>contains certificate signing request</li>
<li>[OPTIONAL] contains <em>permission request</em></li>
</ul>
<div class="sourceCode"><pre class="sourceCode json"><code class="sourceCode json"><span class="fu">{</span>
    <span class="dt">&quot;callbackUri&quot;</span><span class="fu">:</span> <span class="st">&quot;TODO&quot;</span><span class="fu">,</span>
    <span class="dt">&quot;csr&quot;</span><span class="fu">:</span> <span class="st">&quot;TODO&quot;</span><span class="fu">,</span>
    <span class="dt">&quot;dataPoints&quot;</span><span class="fu">:</span> <span class="ot">[</span>
        <span class="st">&quot;profile.lastname&quot;</span>
    <span class="ot">]</span>
<span class="fu">}</span></code></pre></div>
<p><strong>Permission Request</strong></p>
<ul>
<li>creates new <em>permission profile</em></li>
<li><code>https://example-consumer.pdaas.tld/pr</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode json"><code class="sourceCode json"><span class="fu">{</span>
    <span class="dt">&quot;callbackUri&quot;</span><span class="fu">:</span> <span class="st">&quot;&quot;</span><span class="fu">,</span>
    <span class="dt">&quot;dataPoints&quot;</span><span class="fu">:</span> <span class="ot">[</span>
        <span class="st">&quot;profile.lastname&quot;</span>
    <span class="ot">]</span>
<span class="fu">}</span></code></pre></div>
<p><strong>Access Request</strong></p>
<ul>
<li>obtains actual data</li>
<li>if <code>keepalive</code> is set <code>true</code>, the connections lasts until response computation has finished, otherwise the response contains a URI unique to this current request including an estimation when response will be available under that URI; connection can still timeout, which is defined by the system</li>
<li><code>https://example-consumer.pdaas.tld/ar</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode json"><code class="sourceCode json"><span class="fu">{</span>
    <span class="dt">&quot;query&quot;</span><span class="fu">:</span> <span class="st">&quot;TODO&quot;</span>
<span class="fu">}</span></code></pre></div>
<p><em>Requirements:</em></p>
<ul>
<li>query has to match exactly one corresponding <em>permission profile</em></li>
</ul>
<p>TODO: basic structure of a <em>permission profile</em></p>
<p>How do the APIs involved with the protocols look like?</p>
</section>
<section id="security" class="level2">
<h2><span class="header-section-number">7.7</span> Security</h2>
<ul>
<li>the downside of having not just parts of the personal data in different places (which is currently the common way to store), is in case of security breach, it would increase the possible damage by an exponential rate Thereby all data is exposed at once, instead of not just the parts which a single service has stored</li>
<li><p>does it matter from what origin the data request was made? how to check that? is the requester’s server domain in the http header? eventually there is no way to check that, so me might need to go with request logging and trying to detect abnormal behaviour/occurrence with a learning artificial intelligence</p></li>
<li><p>is the consumer able to call the access request URI repeatedly and any time? (meaning will this be stateless or stateful?)</p></li>
<li><p>initial consumer registration would be done on a common and valid https:443 CA-certified connection. after transferring their cert to them as a response, all subsequent calls need to go to their own endpoint, defined as subdomains like <code>consumer-name.owners-notification-server.tld</code></p></li>
</ul>
<section id="environment" class="level3">
<h3><span class="header-section-number">7.7.2</span> Environment</h3>
</section>
<section id="transport" class="level3">
<h3><span class="header-section-number">7.7.3</span> Transport</h3>
<ul>
<li>communication between internal components <em>must</em> be done in https only, but which ciphers? eventually even http/2?</li>
</ul>
</section>
<section id="storage" class="level3">
<h3><span class="header-section-number">7.7.4</span> Storage</h3>
<ul>
<li>documents based DB instead of Relational DBS, because of structure/model flexibility</li>
<li>graphql because of it’s nature to abstract a storage engine, which comes in handy when the actual storage gets relocated (e.g. from a server to a mobile device)</li>
</ul>
</section>
<section id="authentication-1" class="level3">
<h3><span class="header-section-number">7.7.5</span> Authentication</h3>
<ul>
<li>how should consumer authenticate?</li>
</ul>
</section>
</section>
<section id="recommendations" class="level2">
<h2><span class="header-section-number">7.8</span> Recommendations</h2>
<section id="software-dependencies" class="level3">
<h3><span class="header-section-number">7.8.2</span> Software Dependencies</h3>
</section>
<section id="host-environments" class="level3">
<h3><span class="header-section-number">7.8.3</span> Host Environment(s)</h3>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1><span class="header-section-number">8</span> Conclusion</h1>
<section id="ethical-social-impact-todo-or-relevance" class="level2">
<h2><span class="header-section-number">8.2</span> Ethical &amp; Social Impact (TODO: or “Relevance”)</h2>
<ul>
<li>Regarding involving an official party to verify data reliability: The actual question would be, is the <em>data subject</em> certain, that she really wants to hand over those capabilities to official authorities? Depending on which <em>data consumers</em>, what task their are entrusted with and what motivation the <em>data subject</em> has has in mind to do so, the <em>PDaaS</em> might become a powerful <em>“digital reflection”</em> and starts to get seen as a real and reliable representation of herself. Then the decisions made by <em>data consumers</em> might have a big impact for the <em>data subject’s</em> life. For example a housing loan won’t be granted or a medical treatment has been refused.</li>
</ul>
</section>
<section id="business-models-monetisation" class="level2">
<h2><span class="header-section-number">8.3</span> Business Models &amp; Monetisation</h2>
<ul>
<li>possible resulting direct or indirect business models</li>
<li>data subject might want to sell her data, only under her conditions. therefor some kind of infrastructure and process is required (such as payment transfer, data anonymization, market place to offer data)</li>
</ul>
</section>
<section id="target-group-perspectives" class="level2">
<h2><span class="header-section-number">8.4</span> Target group perspectives</h2>
<ul>
<li>User: would I use this stuff? The underpinning technical details and how it works is not my concern and non of my interests. I want this stuff work and being reliable. it its simple to use. and maybe even easy to setup (server n stuff), then the hell, I would!</li>
<li>Dev:
<ul>
<li>spec implementer</li>
<li>integrater in consumer:</li>
</ul></li>
<li>Consumer:</li>
</ul>
<p>TODO: make a reference or involve the research mentioned at the beginning</p>
</section>
<section id="challenges" class="level2">
<h2><span class="header-section-number">8.5</span> Challenges</h2>
<ul>
<li><p>adoption rate of such technology</p></li>
<li><p>data reliability from the perspective of a <em>data consumer</em> Since it is almost impossible to ensure complete reliability of all the data a <em>PDaaS</em> has stored or might me offering, and because it is operated by exactly that individual, and that individual only, all data in question is relates to and is thereby owned by her, it, of cause, makes it not easy for <em>data consumers</em> to trust <em>PDaaS</em>s as resources for their business processes, but I am certain, that the demand for all different kinds of data exceeds the partial uncertainty of their reliability.</p></li>
<li><p>personal data leaking Preventing personal data from being leaked to the outside, is, especially because of the system’s purpose, extremely hard to prevent, if not possible at all. Just by querying data from the storage or by physically transferring them from one location to another, it’s already copied. It’s the very nature of digital information technology/systems. So this cannot be defeated. It only can be impeded. Interestingly though, is the same approach the media industry for centuries is trying to make copyright infringements more difficult.</p></li>
<li><p>scenario where the mobile device, or in general the data storage get lost. first of all, not much of a problem, because either device backup or since the liberal relation, the system would continue to function, but limited, until a data storage gets part of the system again (TODO: touched on in the data section at the end)</p></li>
</ul>
</section>
<section id="solutions" class="level2">
<h2><span class="header-section-number">8.6</span> Solutions</h2>
<ul>
<li><p>even though <em>OAuth</em> don’t find it’s way into this project, working through the standard inspired here and there a solution, for example using a URI as a feedback channel or TODO.</p></li>
<li><p>refer to the scenarios at the beginning by saying that with the <em>PDaaS</em> one is able to implement all of them</p></li>
</ul>
</section>
<section id="attack-scenarios" class="level2">
<h2><span class="header-section-number">8.7</span> Attack Scenarios</h2>
<ul>
<li>single point of failure (data-wise),
<ul>
<li>but considering what data users already put into their social networks (or: thE social network: fb), they/it has already become a de facto data silo and is thus a single point of failure. If that service breaks or get down, the data from all users might be lost or worse (stolen). The aspect of data decentralisation achieved by individual data stores can be valued as positive.</li>
</ul></li>
<li><p>what about token stealing when using jwt?</p></li>
<li><p>future work: add/activate an intrusion detection system</p></li>
</ul>
</section>
<section id="future-work" class="level2">
<h2><span class="header-section-number">8.8</span> Future Work</h2>
<ul>
<li>maybe enable the tool to play the role of an own OpenID provider?</li>
<li><p>going one step further and train machine (predictor) by our self with our own data (https://www.technologyreview.com/s/514356/stephen-wolfram-on-personal-analytics/)</p></li>
<li>finalize first draft of the spec with all core aspect included and outlined</li>
<li>developing based on that a first prototype to find flaws in the spec. iterate/repeat</li>
<li>release 1.0 (spec and example implementation)</li>
<li>touch on parts that were left blank</li>
<li><p>first supporting platforms</p></li>
<li><p>full encryption of the <em>data storage</em></p></li>
</ul>
</section>
<section id="summary" class="level2">
<h2><span class="header-section-number">8.9</span> Summary</h2>
<ul>
<li>main focus</li>
<li>unique features</li>
<li>technology stack &amp; standards</li>
<li>resources</li>
<li>the tool might be not a bulletproof vest, but</li>
</ul>
<p>The work will be continued.</p>
</section>
</section>
<section id="bibliography" class="level1 unnumbered">
<h1>Bibliography</h1>
<div id="refs" class="references">
<div id="ref-web_2016_privacy-international-about-big-data">
<p>[1] <em>Big data privacy international</em>. URL <a href="https://www.privacyinternational.org/node/8" class="uri">https://www.privacyinternational.org/node/8</a>. - retrieved 2016-11-15</p>
</div>
<div id="ref-paper_2008_discrimination-aware-data-mining">
<p>[2] <span style="font-variant: small-caps;">Pedreshi, Dino</span> ; <span style="font-variant: small-caps;">Ruggieri, Salvatore</span> ; <span style="font-variant: small-caps;">Turini, Franco</span>: Discrimination-aware data mining. In: <em>Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</em> : ACM, 2008, pp. 560–568</p>
</div>
<div id="ref-book_2015_ethical-it-innovation_ethical-uses-of-information-and-knowledge">
<p>[3] <span style="font-variant: small-caps;">Spiekermann, Sarah</span>: <em>Ethical IT Innovation: A Value-Based System Design Approach</em> : CRC Press; Taylor &amp; Francis Group, LLC, 2015 – scale — ISBN 978-1-4822-2635-5</p>
</div>
<div id="ref-paper_1996_bias-in-computer-systems">
<p>[4] <span style="font-variant: small-caps;">Friedman, Batya</span> ; <span style="font-variant: small-caps;">Nissenbaum, Helen</span>: Bias in computer systems. In: <em>ACM Transactions on Information Systems (TOIS)</em> vol. 14 (1996), Nr. 3, pp. 330–347</p>
</div>
<div id="ref-wikipedia_2016_cognitive-bias">
<p>[5] <em>Cognitive bias</em>. URL <a href="https://en.wikipedia.org/w/index.php?title=Cognitive_bias&amp;oldid=742803386" class="uri">https://en.wikipedia.org/w/index.php?title=Cognitive_bias&amp;oldid=742803386</a>. - retrieved 2016-11-08. — Wikipedia. — Page Version ID: 742803386</p>
</div>
<div id="ref-web_2016_big-data-is-people">
<p>[6] <span style="font-variant: small-caps;">Lemov, Rebecca</span>: <em>Why big data is actually small, personal and very human. Aeon essays</em>. URL <a href="https://aeon.co/essays/why-big-data-is-actually-small-personal-and-very-human" class="uri">https://aeon.co/essays/why-big-data-is-actually-small-personal-and-very-human</a>. - retrieved 2016-11-17</p>
</div>
<div id="ref-video_2015_big-data-and-deep-learning_discrimination">
<p>[7] <span style="font-variant: small-caps;">Dewes, Andreas</span>: <em>C3TV - Say hi to your new boss: How algorithms might soon control our lives.</em> URL <a href="https://media.ccc.de/v/32c3-7482-say_hi_to_your_new_boss_how_algorithms_might_soon_control_our_lives#video&amp;t=1538" class="uri">https://media.ccc.de/v/32c3-7482-say_hi_to_your_new_boss_how_algorithms_might_soon_control_our_lives#video&amp;t=1538</a>. - retrieved 2016-11-03</p>
</div>
<div id="ref-web_2010_projectvrm_about">
<p>[8] <em>ProjectVRM - about. ProjectVRM</em>. URL <a href="https://blogs.harvard.edu/vrm/about/" class="uri">https://blogs.harvard.edu/vrm/about/</a>. - retrieved 2016-11-09</p>
</div>
<div id="ref-paper_2013_the-personal-data-store-approach-to-personal-data-security_2013">
<p>[9] <span style="font-variant: small-caps;">Tom Kirkham</span> ; <span style="font-variant: small-caps;">Sandra Winfield</span> ; <span style="font-variant: small-caps;">Serge Ravet</span> ; <span style="font-variant: small-caps;">Kellomaki, Sampo</span>: The personal data store approach to personal data security. In: <em>IEEE Security &amp; Privacy</em> vol. 11. Los Alamitos, CA, USA, IEEE Computer Society (2013), Nr. 5, pp. 12–19</p>
</div>
<div id="ref-whitepaper_2014_mydata-a-nordic-model-for-human-centered-personal-data-management-and-processing">
<p>[10] <span style="font-variant: small-caps;">Poikola, Antti</span> ; <span style="font-variant: small-caps;">Kuikkaniemi, Kai</span> ; <span style="font-variant: small-caps;">Honko, Harri</span>: MyData – a nordic model for human-centered personal data management and processing, Ministry of Transport; Communications (2015), pp. 1–12 — ISBN 978-952-243-455-5</p>
</div>
<div id="ref-web_2016_meeco-how-it-works">
<p>[11] <em>Meeco how it works</em>. URL <a href="https://meeco.me/how-it-works.html" class="uri">https://meeco.me/how-it-works.html</a>. - retrieved 2016-11-09</p>
</div>
<div id="ref-repo_2016_pdaas-spec">
<p>[12] <em>Open specification of the concept called personal data as a service (pdaas). GitHub</em>. URL <a href="https://github.com/lucendio/pdaas_spec" class="uri">https://github.com/lucendio/pdaas_spec</a>. - retrieved 2016-11-11</p>
</div>
<div id="ref-web_2010_projectvrm-wiki_about-vrm">
<p>[13] <em>ProjectVRM wiki - about VRM</em>. URL <a href="https://cyber.harvard.edu/projectvrm/Main_Page#About_VRM" class="uri">https://cyber.harvard.edu/projectvrm/Main_Page#About_VRM</a>. - retrieved 2016-11-11</p>
</div>
<div id="ref-web_2010_projectvrm-wiki_pims-example-list">
<p>[14] <em>ProjectVRM wiki - list of personal information management systems</em>. URL <a href="https://cyber.harvard.edu/projectvrm/VRM_Development_Work#Personal_Information_Management_Systems_.28PIMS.29" class="uri">https://cyber.harvard.edu/projectvrm/VRM_Development_Work#Personal_Information_Management_Systems_.28PIMS.29</a>. - retrieved 2016-11-11</p>
</div>
<div id="ref-report_2014_data-brokers">
<p>[15] <span style="font-variant: small-caps;">USA, Federal Trade Commission</span>: <em>Data brokers</em>, 2014 – scale</p>
</div>
<div id="ref-whitepaper_2012_the-value-of-our-digital-identity_definition">
<p>[16] <span style="font-variant: small-caps;">Rose, John</span> ; <span style="font-variant: small-caps;">Rehse, Olaf</span> ; <span style="font-variant: small-caps;">Röber, Björn</span>: The value of our digital identity. In: <em>Boston Cons. Gr</em> (2012)</p>
</div>
<div id="ref-web_2016_wikipedia_intellectual-property">
<p>[17] <em>Outline of intellectual property</em>. URL <a href="https://en.wikipedia.org/w/index.php?title=Outline_of_intellectual_property&amp;oldid=743830160" class="uri">https://en.wikipedia.org/w/index.php?title=Outline_of_intellectual_property&amp;oldid=743830160</a>. - retrieved 2016-12-25. — Page Version ID: 743830160</p>
</div>
<div id="ref-regulation_2016_eu_general-data-protection-regulation_definition">
<p>[18] Regulation (EU) 2016/679 — General data protection regulation, 2016 – scale</p>
</div>
<div id="ref-web_2016_wikipedia_information-privacy-law_us">
<p>[19] <span style="font-variant: small-caps;">Wikipedia</span>: <em>Information privacy law</em>. URL <a href="https://en.wikipedia.org/wiki/Information_privacy_law#United_States" class="uri">https://en.wikipedia.org/wiki/Information_privacy_law#United_States</a>. - retrieved 2016-11-20. — Page Version ID: 749338152</p>
</div>
<div id="ref-web_2016_data-protection-laws-in-the-us">
<p>[20] <span style="font-variant: small-caps;">Loeb), Ieuan Jolly (Loeb &amp;</span>: <em>PLC - data protection in the united states: Overview</em>. URL <a href="http://us.practicallaw.com/6-502-0467" class="uri">http://us.practicallaw.com/6-502-0467</a>. - retrieved 2016-11-20</p>
</div>
<div id="ref-web_2015_white-house-releases-consumer-privacy-bill-draft">
<p>[21] <span style="font-variant: small-caps;">Wilhelm, Alex</span>: <em>White house drops “consumer privacy bill of rights act” draft. TechCrunch</em>. URL <a href="http://social.techcrunch.com/2015/02/27/white-house-drops-consumer-privacy-bill-of-rights-act-draft/" class="uri">http://social.techcrunch.com/2015/02/27/white-house-drops-consumer-privacy-bill-of-rights-act-draft/</a>. - retrieved 2016-11-20</p>
</div>
<div id="ref-bill-draft_2015_us_consumer-privacy-bill-of-rights-act_definition">
<p>[22] Consumer privacy bill of rights act (cpbora) — Administration discussion draft: Consumer privacy bill of rights act of 2015, 2015 – scale</p>
</div>
<div id="ref-rules_2016_fcc_to-protect-broadband-consumer-privacy_sensitive-types-of-data">
<p>[23] FCC 16-148 — Report and order, 2016 – scale. — In the Matter of Protecting the Privacy of Customers of Broadband and Other Telecommunications Services</p>
</div>
<div id="ref-rules_2016_fcc_to-protect-broadband-consumer-privacy_personally-identifiable-information">
<p>[24] FCC 16-39 — Notice of proposed rulemaking, 2016 – scale. — In the Matter of Protecting the Privacy of Customers of Broadband and Other Telecommunications Services</p>
</div>
<div id="ref-web_2016_privacy-policies-are-mandatory-by-law">
<p>[25] <em>Privacy policies are mandatory by law</em>. URL <a href="https://termsfeed.com/blog/privacy-policy-mandatory-law/" class="uri">https://termsfeed.com/blog/privacy-policy-mandatory-law/</a>. - retrieved 2016-11-20. — Disclaimer: Legal information is not legal advice</p>
</div>
<div id="ref-web_2016_international-privacy-standards">
<p>[26] <em>International privacy standards</em>. URL <a href="https://www.eff.org/issues/international-privacy-standards" class="uri">https://www.eff.org/issues/international-privacy-standards</a>. - retrieved 2016-11-20</p>
</div>
<div id="ref-paper_2014_who-owns-yours-data">
<p>[27] <span style="font-variant: small-caps;">Rosner, Gilad</span>: Who owns your data? In:  : ACM Press, 2014 — ISBN 978-1-4503-3047-3, pp. 623–628</p>
</div>
<div id="ref-book_1987_private-ownership_definition">
<p>[28] <span style="font-variant: small-caps;">Grunebaum, J.O.</span>: <em>Private ownership</em>, <em>Problems of philosophy</em> : Routledge &amp; Kegan Paul, 1987 – scale — ISBN 9780710207067</p>
</div>
<div id="ref-regulation_2016_eu_general-data-protection-regulation_ownership">
<p>[29] Regulation (EU) 2016/679 — General data protection regulation, 2016 – scale</p>
</div>
<div id="ref-rules_2016_fcc_to-protect-broadband-consumer-privacy_ownership">
<p>[30] FCC 16-148 — Report and order, 2016 – scale. — In the Matter of Protecting the Privacy of Customers of Broadband and Other Telecommunications Services</p>
</div>
<div id="ref-web_2016_facebook_terms-of-service">
<p>[31] <span style="font-variant: small-caps;">Facebook</span>: <em>Facebooks’s terms of service. Statement of rights and responsibilities</em>. URL <a href="https://www.facebook.com/legal/terms" class="uri">https://www.facebook.com/legal/terms</a>. - retrieved 2016-12-01</p>
</div>
<div id="ref-web_2016_twitter_terms-of-service">
<p>[32] <span style="font-variant: small-caps;">Twitter</span>: <em>Twitters’s terms of service. Twitter terms of service</em>. URL <a href="https://twitter.com/tos#intlTerms" class="uri">https://twitter.com/tos#intlTerms</a>. - retrieved 2016-12-01</p>
</div>
<div id="ref-web_2016_google_terms-of-service">
<p>[33] <span style="font-variant: small-caps;">Google</span>: <em>Google’s terms of service. Google terms of service</em>. URL <a href="https://www.google.com/intl/en/policies/terms/regional.html" class="uri">https://www.google.com/intl/en/policies/terms/regional.html</a>. - retrieved 2016-12-01</p>
</div>
<div id="ref-web_2016_apple-icloud_terms-of-service">
<p>[34] <span style="font-variant: small-caps;">Apple</span>: <em>Apple’s iClound terms and conditions. V. content and your conduct</em>. URL <a href="https://www.apple.com/legal/internet-services/icloud/en/terms.html" class="uri">https://www.apple.com/legal/internet-services/icloud/en/terms.html</a>. - retrieved 2016-12-01</p>
</div>
<div id="ref-web_2013_why-metadata-matters">
<p>[35] <em>Why metadata matters</em>. URL <a href="https://www.eff.org/deeplinks/2013/06/why-metadata-matters" class="uri">https://www.eff.org/deeplinks/2013/06/why-metadata-matters</a>. - retrieved 2016-11-24</p>
</div>
<div id="ref-web_2016_why-you-need-metadata-for-big-data-to-success">
<p>[36] <span style="font-variant: small-caps;">Stevens, John P.</span>: <em>Why you need metadata for big data success</em>. URL <a href="http://www.datasciencecentral.com/profiles/blogs/why-you-need-metadata-for-big-data-success" class="uri">http://www.datasciencecentral.com/profiles/blogs/why-you-need-metadata-for-big-data-success</a>. - retrieved 2016-11-24</p>
</div>
<div id="ref-web_2016_oxford_definition_big-data">
<p>[37] <em>Big data n.</em> URL <a href="http://www.oed.com/view/Entry/18833#eid301162177" class="uri">http://www.oed.com/view/Entry/18833#eid301162177</a>. - retrieved 2016-11-11</p>
</div>
<div id="ref-web_2016_wikipedia_definition_big-data">
<p>[38] <span style="font-variant: small-caps;">Wikipedia</span>: <em>Big data</em>. URL <a href="https://en.wikipedia.org/w/index.php?title=Big_data&amp;oldid=748964100" class="uri">https://en.wikipedia.org/w/index.php?title=Big_data&amp;oldid=748964100</a>. - retrieved 2016-11-11. — Page Version ID: 748964100</p>
</div>
<div id="ref-paper_2015_big-data-analytics_a-survey">
<p>[39] <span style="font-variant: small-caps;">Tsai, Chun-Wei</span> ; <span style="font-variant: small-caps;">Lai, Chin-Feng</span> ; <span style="font-variant: small-caps;">Chao, Han-Chieh</span> ; <span style="font-variant: small-caps;">Vasilakos, Athanasios V.</span>: Big data analytics: A survey. In: <em>Journal of Big Data</em> vol. 2 (2015), Nr. 1, p. 21</p>
</div>
<div id="ref-book-chapter_1999_Principles-of-knowledge-discovery-in-databases_introduction-to-data-mining">
<p>[40] <span style="font-variant: small-caps;">Zaïane, Osmar R</span>: <em>Principles of knowledge discovery in databases</em>, 1999 – scale</p>
</div>
<div id="ref-web_2013_big-data-collection-collides-with-privacy-concerns">
<p>[41] <em>Big data collection collides with privacy concerns, analysts say. PCWorld</em>. URL <a href="http://www.pcworld.com/article/2027789/big-data-collection-collides-with-privacy-concerns-analysts-say.html" class="uri">http://www.pcworld.com/article/2027789/big-data-collection-collides-with-privacy-concerns-analysts-say.html</a>. - retrieved 2016-11-15</p>
</div>
<div id="ref-web_2016_answers-io">
<p>[42] <em>Answers.io. Answers</em>. URL <a href="https://answers.io/answers" class="uri">https://answers.io/answers</a>. - retrieved 2016-11-14</p>
</div>
<div id="ref-web_2016_big-data-enthusiasts-should-not-ignore">
<p>[43] <span style="font-variant: small-caps;">Burgelman, Author: Luc</span> ; <span style="font-variant: small-caps;">Burgelman, NGDATA Luc</span> ; <span style="font-variant: small-caps;">NGDATA</span>: <em>Attention, big data enthusiasts: Here’s what you shouldn’t ignore. WIRED</em>. URL <a href="https://www.wired.com/insights/2013/02/attention-big-data-enthusiasts-heres-what-you-shouldnt-ignore/" class="uri">https://www.wired.com/insights/2013/02/attention-big-data-enthusiasts-heres-what-you-shouldnt-ignore/</a>. - retrieved 2016-11-15. — Partner Content</p>
</div>
<div id="ref-report_2001_3d-data-management-controlling-data-volume-velocity-and-variety">
<p>[44] <span style="font-variant: small-caps;">Laney, Douglas</span>: <em>3D data management: Controlling data volume, velocity, and variety</em> : META Group, 2001 – scale</p>
</div>
<div id="ref-paper_2015_big-data-for-development-a-review-of-promises-and-challenges:more-data">
<p>[45] <span style="font-variant: small-caps;">Hilbert, Martin</span>: Big data for development: A review of promises and challenges. In: <em>Development Policy Review</em> vol. 34 (2015), Nr. 1, pp. 135–174</p>
</div>
<div id="ref-web_2016_the-state-of-big-data">
<p>[46] <span style="font-variant: small-caps;">Davis Kho, Nancy</span>: <em>The state of big data</em>. URL <a href="http://www.econtentmag.com/Articles/Editorial/Feature/The-State-of-Big-Data-108666.htm" class="uri">http://www.econtentmag.com/Articles/Editorial/Feature/The-State-of-Big-Data-108666.htm</a>. - retrieved 2016-11-18</p>
</div>
<div id="ref-web_2016_apple_customer-letter">
<p>[47] <span style="font-variant: small-caps;">CEO), Tim Cook (Apple’s</span>: <em>A message to our customers. Customer letter</em>. URL <a href="http://www.apple.com/customer-letter/" class="uri">http://www.apple.com/customer-letter/</a>. - retrieved 2016-11-18</p>
</div>
<div id="ref-web_2016_what-is-differential-privacy">
<p>[48] <span style="font-variant: small-caps;">Green, Matthew</span>: <em>What is differential privacy? A few thoughts on cryptographic engineering</em>. URL <a href="https://blog.cryptographyengineering.com/2016/06/15/what-is-differential-privacy/" class="uri">https://blog.cryptographyengineering.com/2016/06/15/what-is-differential-privacy/</a>. - retrieved 2016-11-18</p>
</div>
<div id="ref-web_2016_eff_whatsapp-rolls-out-emd-to-end-encryption">
<p>[49] <span style="font-variant: small-caps;">Budington, Bill</span>: <em>WhatsApp rolls out end-to-end encryption to its over one billion users</em>. URL <a href="https://www.eff.org/deeplinks/2016/04/whatsapp-rolls-out-end-end-encryption-its-1bn-users" class="uri">https://www.eff.org/deeplinks/2016/04/whatsapp-rolls-out-end-end-encryption-its-1bn-users</a>. - retrieved 2016-11-18</p>
</div>
<div id="ref-web_2007_introducing-google-traffic">
<p>[50] <em>Stuck in traffic? Insights from googlers into our products, technology, and the google culture</em>. URL <a href="https://googleblog.blogspot.com/2007/02/stuck-in-traffic.html" class="uri">https://googleblog.blogspot.com/2007/02/stuck-in-traffic.html</a>. - retrieved 2016-11-18</p>
</div>
<div id="ref-web_2016_wikipedia_google-traffic">
<p>[51] <span style="font-variant: small-caps;">Wikipedia</span>: <em>Google traffic</em>. URL <a href="https://en.wikipedia.org/w/index.php?title=Google_Traffic&amp;oldid=746200591" class="uri">https://en.wikipedia.org/w/index.php?title=Google_Traffic&amp;oldid=746200591</a>. - retrieved 2016-11-18. — Page Version ID: 746200591</p>
</div>
<div id="ref-graphic_2016_global-mobile-os-market-share">
<p>[52] <em>Global mobile OS market share</em>. URL <a href="https://www.statista.com/statistics/266136/global-market-share-held-by-smartphone-operating-systems/" class="uri">https://www.statista.com/statistics/266136/global-market-share-held-by-smartphone-operating-systems/</a>. - retrieved 2016-11-18</p>
</div>
<div id="ref-estimating-the-locations-of-emergency-events-from-twitter-streams_2014">
<p>[53] <span style="font-variant: small-caps;">Ao, Ji</span> ; <span style="font-variant: small-caps;">Zhang, Peng</span> ; <span style="font-variant: small-caps;">Cao, Yanan</span>: Estimating the Locations of Emergency Events from Twitter Streams. In: <em>Procedia Computer Science</em> vol. 31 (2014), pp. 731–739</p>
</div>
<div id="ref-the-practice-of-predictive-analytics-in-healthcare_2013">
<p>[54] <span style="font-variant: small-caps;">Palem, Gopalakrishna</span>: The Practice of Predictive Analytics in Healthcare. In: <em>ResearchGate</em> (2013)</p>
</div>
<div id="ref-data-collection-for-climate-changes_2014">
<p>[55] <span style="font-variant: small-caps;">Burger, Nicholas</span> ; <span style="font-variant: small-caps;">Ghosh-Dastidar, Bonnie</span> ; <span style="font-variant: small-caps;">Grant, Audra</span> ; <span style="font-variant: small-caps;">Joseph, George</span> ; <span style="font-variant: small-caps;">Ruder, Teague</span> ; <span style="font-variant: small-caps;">Tchakeva, Olesya</span> ; <span style="font-variant: small-caps;">Wodon, Quentin</span>: Data Collection for the Study on Climate Change and Migration in the MENA Region (2014)</p>
</div>
<div id="ref-graphic_2015_applications-of-big-data-in-10-industry-verticals">
<p>[56] <span style="font-variant: small-caps;">Gaitho, Maryanne</span>: <em>Applications of big data in 10 industry verticals</em>. URL <a href="https://www.simplilearn.com/big-data-applications-in-industries-article" class="uri">https://www.simplilearn.com/big-data-applications-in-industries-article</a>. - retrieved 2016-11-19</p>
</div>
<div id="ref-graphic_2012_personal-data-ecosystem">
<p>[57] <span style="font-variant: small-caps;">USA, Federal Trade Commission</span>: <em>Personal data ecosystem</em>. URL <a href="https://www.ftc.gov/sites/default/files/documents/public_events/exploring-privacy-roundtable-series/personaldataecosystem.pdf" class="uri">https://www.ftc.gov/sites/default/files/documents/public_events/exploring-privacy-roundtable-series/personaldataecosystem.pdf</a>. - retrieved 2016-11-17. — Protecting Consumer Privacy in an Era of Rapid Change - Recommendations for Business and Policymakers - FTC Report</p>
</div>
<div id="ref-paper_1965_moors-law">
<p>[58] <span style="font-variant: small-caps;">Moore, Gordon E.</span>: Cramming more components onto integrated circuits. In: <em>Electronics</em> vol. 38 (1965), p. 4</p>
</div>
<div id="ref-podcast_2015_cre-neuronale-netze">
<p>[59] <span style="font-variant: small-caps;">Pritlove, Tim</span> ; <span style="font-variant: small-caps;">Schöneberg, Ulf</span>: <em>Neuronale netze</em>, 2015 – scale</p>
</div>
<div id="ref-web_2016_industries-intention-to-invest-in-big-data">
<p>[60] <span style="font-variant: small-caps;">Columbus, Louis</span>: <em>51% of enterprises intend to invest more in big data</em>. URL <a href="http://www.forbes.com/sites/louiscolumbus/2016/05/22/51-of-enterprises-intend-to-invest-more-in-big-data/" class="uri">http://www.forbes.com/sites/louiscolumbus/2016/05/22/51-of-enterprises-intend-to-invest-more-in-big-data/</a>. - retrieved 2016-12-07</p>
</div>
<div id="ref-web_2016_projectvrm_development-work">
<p>[61] <em>ProjectVRM - cDevelopment work. ProjectVRM</em>. URL <a href="https://cyber.harvard.edu/projectvrm/VRM_Development_Work" class="uri">https://cyber.harvard.edu/projectvrm/VRM_Development_Work</a>. - retrieved 2016-12-09</p>
</div>
<div id="ref-web_2016_projectvrm_principles">
<p>[62] <em>ProjectVRM - principles. ProjectVRM</em>. URL <a href="https://cyber.harvard.edu/projectvrm/Main_Page#VRM_Principles" class="uri">https://cyber.harvard.edu/projectvrm/Main_Page#VRM_Principles</a>. - retrieved 2016-12-09</p>
</div>
<div id="ref-graphic_2011_architecture_components-of-organization-domain">
<p>[63] <span style="font-variant: small-caps;">The TAS3 Consortium</span>: <em>TAS3 architecture - figure 2.2: Major components of organization domain.</em>, 2011 – scale. — v 2.24</p>
</div>
<div id="ref-web_kantara-initiative">
<p>[64] <em>Kantara initiative – join. innovate. trust.</em> URL <a href="https://kantarainitiative.org/" class="uri">https://kantarainitiative.org/</a>. - retrieved 2016-12-14</p>
</div>
<div id="ref-paper_2014_personal-data-store-approach">
<p>[65] <span style="font-variant: small-caps;">Kirkham, Tom</span> ; <span style="font-variant: small-caps;">Winfield, Sandra</span> ; <span style="font-variant: small-caps;">Ravet, Serge</span> ; <span style="font-variant: small-caps;">Kellomaki, Sampo</span>: The personal data store approach to personal data security. In: <em>IEEE Security &amp; Privacy</em> vol. 11 (2013), Nr. 5, pp. 12–19</p>
</div>
<div id="ref-paper_2012_openpds_on-trusted-use-of-large-scale-personal-data">
<p>[66] <span style="font-variant: small-caps;">Montjoye, Yves-Alexandre de</span> ; <span style="font-variant: small-caps;">Wang, Samuel S.</span> ; <span style="font-variant: small-caps;">Pentland, Alex</span> ; <span style="font-variant: small-caps;">Anh, Dinh Tien Tuan</span> ; <span style="font-variant: small-caps;">Datta, Anwitaman</span> ; <span style="font-variant: small-caps;">others</span>: On the trusted use of large-scale personal data. In: <em>IEEE Data Eng. Bull.</em> vol. 35 (2012), Nr. 4, pp. 5–8</p>
</div>
<div id="ref-web_mit_openpds-safeanswers-project-page">
<p>[67] <em>openPDS/SafeAnswers - the privacy-preserving personal data store</em>. URL <a href="http://openpds.media.mit.edu/" class="uri">http://openpds.media.mit.edu/</a>. - retrieved 2016-12-14</p>
</div>
<div id="ref-paper_2014_openpds_protecting-privacy-of-meta-data-through-safeanswers">
<p>[68] <span style="font-variant: small-caps;">Montjoye, Yves-Alexandre de</span> ; <span style="font-variant: small-caps;">Shmueli, Erez</span> ; <span style="font-variant: small-caps;">Wang, Samuel S.</span> ; <span style="font-variant: small-caps;">Pentland, Alex Sandy</span>: openPDS: Protecting the privacy of metadata through SafeAnswers. In: <span style="font-variant: small-caps;">Preis, T.</span> (ed.) <em>PLoS ONE</em> vol. 9 (2014), Nr. 7, p. e98790</p>
</div>
<div id="ref-web_microsoft_healthvault">
<p>[69] <em>Microsoft HealthVault. Overview</em>. URL <a href="https://www.healthvault.com/de/en/overview" class="uri">https://www.healthvault.com/de/en/overview</a>. - retrieved 2016-12-14</p>
</div>
<div id="ref-web_meeco_how-it-works">
<p>[70] <em>How it works meeco</em>. URL <a href="https://meeco.me/how-it-works.html" class="uri">https://meeco.me/how-it-works.html</a>. - retrieved 2016-12-14</p>
</div>
<div id="ref-slides_2015_meeco-case-study">
<p>[71] <span style="font-variant: small-caps;">Page, Mike</span>: Online adver&gt;sing – booming or broken?, 2015 – scale</p>
</div>
<div id="ref-web_industrial-data-space">
<p>[72] <em>The principles. Industrial data space e.V.</em> URL <a href="http://www.industrialdataspace.org/en/the-principles/" class="uri">http://www.industrialdataspace.org/en/the-principles/</a>. - retrieved 2016-12-14</p>
</div>
<div id="ref-whitepaper_2016_industrial-data-space">
<p>[73] <span style="font-variant: small-caps;">Prof. Dr.-Ing. Otto, Boris</span> ; <span style="font-variant: small-caps;">Prof. Dr. Auer, Sören</span> ; <span style="font-variant: small-caps;">Cirullies, Jan</span> ; <span style="font-variant: small-caps;">Prof. Dr. Jürjens, Jan</span> ; <span style="font-variant: small-caps;">Menz, Nadja</span> ; <span style="font-variant: small-caps;">Schon, Jochen</span> ; <span style="font-variant: small-caps;">Dr. Wenzel, Sven</span>: Industrial data space - digital sovereignity over data.</p>
</div>
<div id="ref-web_spec_http1">
<p>[74] <span style="font-variant: small-caps;">Leach, Paul J.</span> ; <span style="font-variant: small-caps;">Berners-Lee, Tim</span> ; <span style="font-variant: small-caps;">Mogul, Jeffrey C.</span> ; <span style="font-variant: small-caps;">Masinter, Larry</span> ; <span style="font-variant: small-caps;">Fielding, Roy T.</span> ; <span style="font-variant: small-caps;">Gettys, James</span>: <em>Hypertext transfer protocol – HTTP/1.1</em>. URL <a href="https://tools.ietf.org/html/rfc2616" class="uri">https://tools.ietf.org/html/rfc2616</a>. - retrieved 2016-12-17</p>
</div>
<div id="ref-web_spec_http2">
<p>[75] <span style="font-variant: small-caps;">Belshe, Mike</span> ; <span style="font-variant: small-caps;">Thomson, Martin</span> ; <span style="font-variant: small-caps;">Peon, Roberto</span>: <em>Hypertext transfer protocol version 2 (HTTP/2)</em>. URL <a href="https://tools.ietf.org/html/rfc7540" class="uri">https://tools.ietf.org/html/rfc7540</a>. - retrieved 2016-12-17</p>
</div>
<div id="ref-web_spec_websockets">
<p>[76] <span style="font-variant: small-caps;">Fette, Ian</span> ; <span style="font-variant: small-caps;">Melnikov, A.</span>: <em>The WebSocket protocol</em>. URL <a href="https://tools.ietf.org/html/rfc6455" class="uri">https://tools.ietf.org/html/rfc6455</a>. - retrieved 2016-12-17</p>
</div>
<div id="ref-web_spec_json">
<p>[77] <span style="font-variant: small-caps;">Crockford, Douglas</span>: The JSON data interchange format.</p>
</div>
<div id="ref-web_rfc_json">
<p>[78] <span style="font-variant: small-caps;">Bray, T.</span>: <em>The JavaScript object notation (JSON) data interchange format</em>. URL <a href="https://tools.ietf.org/html/rfc7159" class="uri">https://tools.ietf.org/html/rfc7159</a>. - retrieved 2016-12-17</p>
</div>
<div id="ref-web_2012_problem-with-oauth-for-authentication">
<p>[79] <span style="font-variant: small-caps;">Bradley, John</span>: <em>The problem with OAuth for authentication.</em> URL <a href="http://www.thread-safe.com/2012/01/problem-with-oauth-for-authentication.html" class="uri">http://www.thread-safe.com/2012/01/problem-with-oauth-for-authentication.html</a>. - retrieved 2016-12-17</p>
</div>
<div id="ref-web_spec_oauth-1a">
<p>[80] <em>OAuth core 1.0a</em>. URL <a href="https://oauth.net/core/1.0a/" class="uri">https://oauth.net/core/1.0a/</a>. - retrieved 2016-12-18</p>
</div>
<div id="ref-web_spec_oauth-2">
<p>[81] <span style="font-variant: small-caps;">Hardt, Dick</span>: <em>The OAuth 2.0 authorization framework</em>. URL <a href="https://tools.ietf.org/html/rfc6749" class="uri">https://tools.ietf.org/html/rfc6749</a>. - retrieved 2016-12-18</p>
</div>
<div id="ref-web_2016_oauth-2">
<p>[82] <span style="font-variant: small-caps;">WG, IETF OAuth</span>: <em>OAuth 2.0</em>. URL <a href="https://oauth.net/2/" class="uri">https://oauth.net/2/</a>. - retrieved 2016-12-16</p>
</div>
<div id="ref-web_spec_openid-connect-1">
<p>[83] <em>OpenID connect core 1.0 incorporating errata set 1</em>. URL <a href="https://openid.net/specs/openid-connect-core-1_0.html" class="uri">https://openid.net/specs/openid-connect-core-1_0.html</a>. - retrieved 2016-12-17</p>
</div>
<div id="ref-web_spec_json-web-token">
<p>[84] <span style="font-variant: small-caps;">Bradley, John</span> ; <span style="font-variant: small-caps;">Sakimura, Nat</span> ; <span style="font-variant: small-caps;">Jones, Michael</span>: <em>JSON web token (JWT)</em>. URL <a href="https://tools.ietf.org/html/rfc7519" class="uri">https://tools.ietf.org/html/rfc7519</a>. - retrieved 2016-12-17</p>
</div>
<div id="ref-web_spec_json-web-encryption">
<p>[85] <span style="font-variant: small-caps;">Hildebrand, Joe</span> ; <span style="font-variant: small-caps;">Jones, Michael</span>: <em>JSON web encryption (JWE)</em>. URL <a href="https://tools.ietf.org/html/rfc7516" class="uri">https://tools.ietf.org/html/rfc7516</a>. - retrieved 2016-12-17</p>
</div>
<div id="ref-web_spec_json-web-signature">
<p>[86] <span style="font-variant: small-caps;">Bradley, John</span> ; <span style="font-variant: small-caps;">Sakimura, Nat</span> ; <span style="font-variant: small-caps;">Jones, Michael</span>: <em>JSON web signature (JWS)</em>. URL <a href="https://tools.ietf.org/html/rfc7515" class="uri">https://tools.ietf.org/html/rfc7515</a>. - retrieved 2016-12-17</p>
</div>
<div id="ref-paper_1976_d-h-key-exchange">
<p>[87] <span style="font-variant: small-caps;">Diffie, Whitfield</span> ; <span style="font-variant: small-caps;">Hellman, Martin</span>: New directions in cryptography. In: <em>IEEE transactions on Information Theory</em> vol. 22 (1976), Nr. 6, pp. 644–654</p>
</div>
<div id="ref-book_2014_chapter-9-1-public-key-crypto">
<p>[88] <span style="font-variant: small-caps;">Stallings, William</span>: 9.1 principles of public-key cryptosystems. In: <em>Cryptography and network security: Principles and practice</em>. Seventh edition. ed. Boston : Pearson, 2014 — ISBN 978-0-13-335469-0, pp. 256–264</p>
</div>
<div id="ref-web_spec_tls">
<p>[89] <span style="font-variant: small-caps;">Dierks, Tim</span> ; <span style="font-variant: small-caps;">Rescorla, E.</span>: <em>The transport layer security (TLS) protocol version 1.2</em>. URL <a href="https://tools.ietf.org/html/rfc5246" class="uri">https://tools.ietf.org/html/rfc5246</a>. - retrieved 2016-12-17</p>
</div>
<div id="ref-book_2014_chapter-14-5-pki">
<p>[90] <span style="font-variant: small-caps;">Stallings, William</span>: 10.5 pseudorandom number generation based on an asymmetric cipher. In: <em>Cryptography and network security: Principles and practice</em>. Seventh edition. ed. Boston : Pearson, 2014 — ISBN 978-0-13-335469-0, pp. 443–445</p>
</div>
<div id="ref-web_spec_x509">
<p>[91] <span style="font-variant: small-caps;">Cooper, Dave</span> ; <span style="font-variant: small-caps;">Santesson, S.</span> ; <span style="font-variant: small-caps;">Farrell, S.</span> ; <span style="font-variant: small-caps;">Boeyen, S.</span> ; <span style="font-variant: small-caps;">Housley, W., <span style="font-variant:normal;">R. andPolk</span></span>: <em>Internet x.509 public key infrastructure certificate and certificate revocation list (CRL) profile</em>. URL <a href="https://tools.ietf.org/html/rfc5280" class="uri">https://tools.ietf.org/html/rfc5280</a>. - retrieved 2017-01-11</p>
</div>
<div id="ref-web_spec_rest">
<p>[92] <span style="font-variant: small-caps;">Fielding, Thomas</span>: Representational state transfer (REST). In: <em>Architectural styles and the design of network-based software architectures</em> : University of California, Irvine, 2000, pp. 76–106</p>
</div>
<div id="ref-web_spec_http-methods">
<p>[93] <span style="font-variant: small-caps;">Leach, Paul J.</span> ; <span style="font-variant: small-caps;">Berners-Lee, Tim</span> ; <span style="font-variant: small-caps;">Mogul, Jeffrey C.</span> ; <span style="font-variant: small-caps;">Masinter, Larry</span> ; <span style="font-variant: small-caps;">Fielding, Roy T.</span> ; <span style="font-variant: small-caps;">Gettys, James</span>: <em>HTTP methods</em>. URL <a href="https://tools.ietf.org/html/rfc2616#section-9" class="uri">https://tools.ietf.org/html/rfc2616#section-9</a>. - retrieved 2016-12-18</p>
</div>
<div id="ref-web_spec_graphql">
<p>[94] <em>GraphQL</em>. URL <a href="https://facebook.github.io/graphql/" class="uri">https://facebook.github.io/graphql/</a>. - retrieved 2016-12-17</p>
</div>
<div id="ref-web_w3c-tr_rdf">
<p>[95] <span style="font-variant: small-caps;">Beckett, Dave</span> ; <span style="font-variant: small-caps;">McBride, Brian</span>: <em>RDF/XML syntax specification (revised)</em>. URL <a href="https://www.w3.org/TR/REC-rdf-syntax/" class="uri">https://www.w3.org/TR/REC-rdf-syntax/</a>. - retrieved 2016-12-19</p>
</div>
<div id="ref-web_w3c-tr_owl">
<p>[96] <span style="font-variant: small-caps;">W3C OWL Working Group</span>: <em>OWL 2 web ontology language document overview (second edition)</em>. URL <a href="https://www.w3.org/TR/owl2-overview/" class="uri">https://www.w3.org/TR/owl2-overview/</a>. - retrieved 2016-12-19</p>
</div>
<div id="ref-web_w3c-tr_sparql">
<p>[97] <span style="font-variant: small-caps;">Harris, Steve</span> ; <span style="font-variant: small-caps;">Seaborne, Andy</span> ; <span style="font-variant: small-caps;">Prud’hommeaux, Eric</span>: <em>SPARQL 1.1 query language</em>. URL <a href="https://www.w3.org/TR/sparql11-query/" class="uri">https://www.w3.org/TR/sparql11-query/</a>. - retrieved 2016-12-19</p>
</div>
<div id="ref-web_w3c-draft_webid">
<p>[98] <em>WebID specifications</em>. URL <a href="https://www.w3.org/2005/Incubator/webid/spec/" class="uri">https://www.w3.org/2005/Incubator/webid/spec/</a>. - retrieved 2016-12-19</p>
</div>
<div id="ref-web_spec_solid">
<p>[99] <em>Solid specification</em>. URL <a href="https://github.com/solid/solid-spec" class="uri">https://github.com/solid/solid-spec</a>. - retrieved 2016-12-17</p>
</div>
<div id="ref-web_2016_wiki_webaccesscontrol">
<p>[100] <em>WebAccessControl - w3c wiki</em>. URL <a href="https://www.w3.org/wiki/WebAccessControl" class="uri">https://www.w3.org/wiki/WebAccessControl</a>. - retrieved 2016-12-19</p>
</div>
<div id="ref-web_2016_demo_databox">
<p>[101] <em>Databox.me</em>. URL <a href="https://databox.me/" class="uri">https://databox.me/</a>. - retrieved 2016-12-19</p>
</div>
<div id="ref-web_2015_cgroup-doc">
<p>[102] <span style="font-variant: small-caps;">Heo, Tejun</span>: <em>Control group (v2) documentation</em>. URL <a href="https://www.kernel.org/doc/Documentation/cgroup-v2.txt" class="uri">https://www.kernel.org/doc/Documentation/cgroup-v2.txt</a>. - retrieved 2016-12-20</p>
</div>
<div id="ref-web_2016_kernel-namespace">
<p>[103] <em>Overview of linux namespaces</em>. URL <a href="http://man7.org/linux/man-pages/man7/namespaces.7.html" class="uri">http://man7.org/linux/man-pages/man7/namespaces.7.html</a>. - retrieved 2016-12-20</p>
</div>
<div id="ref-web_2016_open-container-initiative">
<p>[104] <em>Open container initiative</em>. URL <a href="https://www.opencontainers.org/" class="uri">https://www.opencontainers.org/</a>. - retrieved 2016-12-20</p>
</div>
<div id="ref-web_oci-spec_runtime">
<p>[105] <em>Container runtime specification (v1.0.0-rc3)</em>. URL <a href="https://github.com/opencontainers/runtime-spec/tree/v1.0.0-rc3" class="uri">https://github.com/opencontainers/runtime-spec/tree/v1.0.0-rc3</a>. - retrieved 2016-12-20</p>
</div>
<div id="ref-web_oci-spec_image">
<p>[106] <em>Container image specification (v1.0.0-rc3)</em>. URL <a href="https://github.com/opencontainers/image-spec/tree/v1.0.0-rc3" class="uri">https://github.com/opencontainers/image-spec/tree/v1.0.0-rc3</a>. - retrieved 2016-12-20</p>
</div>
<div id="ref-web_2013_npa-sicherheitsdefizit">
<p>[107] <em>Basisleser weiterhin kritische schwachstelle des elektronischen / neuen personalausweises. Netzpolitik.org</em>. URL <a href="https://netzpolitik.org/2013/basisleser-weiterhin-kritische-schwachstelle-des-elektronischen-neuen-personalausweises/" class="uri">https://netzpolitik.org/2013/basisleser-weiterhin-kritische-schwachstelle-des-elektronischen-neuen-personalausweises/</a>. - retrieved 2017-01-05</p>
</div>
<div id="ref-web_2014_test-qes-support-in-npa">
<p>[108] <span style="font-variant: small-caps;">Stiemerling, Oliver</span>: <em>Qualifizierte elektronische signatur mit dem neuen personalausweis – oder: QES mit nPA, ein selbstversuch. CR-online.de blog</em>. URL <a href="http://www.cr-online.de/blog/2014/08/26/qualifizierte-elektronische-signatur-mit-dem-neuen-personalausweis-oder-qes-mit-npa-ein-selbstversuch/" class="uri">http://www.cr-online.de/blog/2014/08/26/qualifizierte-elektronische-signatur-mit-dem-neuen-personalausweis-oder-qes-mit-npa-ein-selbstversuch/</a>. - retrieved 2017-01-05</p>
</div>
<div id="ref-web_2017_about-de-mail">
<p>[109] <span style="font-variant: small-caps;">Bundesregierung für Informationstechnik, Der Bundesbeauftragte der</span>: <em>IT-beauftragter der bundesregierung de-mail</em>. URL <a href="http://www.cio.bund.de/Web/DE/Innovative-Vorhaben/De-Mail/de_mail_node.html" class="uri">http://www.cio.bund.de/Web/DE/Innovative-Vorhaben/De-Mail/de_mail_node.html</a>. - retrieved 2017-01-06</p>
</div>
<div id="ref-statement_2013_de-mail">
<p>[110] <span style="font-variant: small-caps;">Neumann, Linus</span>: Stellungnahme zum elektronischen rechtsverkehr.</p>
</div>
<div id="ref-book_2015_ethical-it-innovation">
<p>[111] <span style="font-variant: small-caps;">Spiekermann, Sarah</span>: <em>Ethical IT Innovation: A Value-Based System Design Approach</em> : CRC Press; Taylor &amp; Francis Group, LLC, 2015 – scale — ISBN 978-1-4822-2635-5</p>
</div>
<div id="ref-paper_2004_distributed-mapreduce">
<p>[112] <span style="font-variant: small-caps;">Dean, Eeffrey</span> ; <span style="font-variant: small-caps;">Ghemawat, Sanjay</span>: MapRednce: Simplified data processing on large clusters (2004)</p>
</div>
<div id="ref-web_spec_tls-12_client-auth">
<p>[113] <span style="font-variant: small-caps;">Dierks, Tim</span>: <em>The transport layer security (TLS) protocol version 1.2</em>. URL <a href="https://tools.ietf.org/html/rfc5246#section-7.4.6" class="uri">https://tools.ietf.org/html/rfc5246#section-7.4.6</a>. - retrieved 2017-01-09</p>
</div>
<div id="ref-web_2017_wikipedia_mutual-auth">
<p>[114] <em>Mutual authentication</em>. URL <a href="https://en.wikipedia.org/w/index.php?title=Mutual_authentication&amp;oldid=737409981" class="uri">https://en.wikipedia.org/w/index.php?title=Mutual_authentication&amp;oldid=737409981</a>. - retrieved 2017-01-10. — Page Version ID: 737409981</p>
</div>
<div id="ref-book_2013_networking-101_tls-session-resumption">
<p>[115] <em>Networking 101: Transport layer security (TLS) - high performance browser networking (o’Reilly). High performance browser networking</em>. URL <a href="https://hpbn.co/transport-layer-security-tls/#tls-session-resumption" class="uri">https://hpbn.co/transport-layer-security-tls/#tls-session-resumption</a>. - retrieved 2017-01-12</p>
</div>
<div id="ref-web_spec_tls-session-ticket-resumption">
<p>[116] <span style="font-variant: small-caps;">Joseph Salowey, P. Eronen, <span style="font-variant:normal;">H. Zhou</span></span>: <em>Transport layer security (TLS) session resumption without server-side state</em>. URL <a href="https://tools.ietf.org/html/rfc5077" class="uri">https://tools.ietf.org/html/rfc5077</a>. - retrieved 2017-01-12</p>
</div>
<div id="ref-web_bsi-spec_eid">
<p>[117] <em>BSI - technische richtlinien des BSI - BSI TR-03130 eID-server</em>. URL <a href="https://www.bsi.bund.de/DE/Publikationen/TechnischeRichtlinien/tr03130/tr-03130.html" class="uri">https://www.bsi.bund.de/DE/Publikationen/TechnischeRichtlinien/tr03130/tr-03130.html</a>. - retrieved 2017-01-06</p>
</div>
<div id="ref-web_2017_npa-eid-server">
<p>[118] <em>Personalausweisportal - eID-server</em>. URL <a href="https://personalausweisportal.de/DE/Wirtschaft/Technik/eID-Server/eID-Server_node.html" class="uri">https://personalausweisportal.de/DE/Wirtschaft/Technik/eID-Server/eID-Server_node.html</a>. - retrieved 2017-01-06</p>
</div>
<div id="ref-book_2014_chapter-10-5-asym-random-number-gen">
<p>[119] <span style="font-variant: small-caps;">Stallings, William</span>: 9.1 public-key infrastructure. In: <em>Cryptography and network security: Principles and practice</em>. Seventh edition. ed. Boston : Pearson, 2014 — ISBN 978-0-13-335469-0, p. 307</p>
</div>
<div id="ref-web_spec_http-error-codes">
<p>[120] <span style="font-variant: small-caps;">Leach, Paul J.</span> ; <span style="font-variant: small-caps;">Berners-Lee, Tim</span> ; <span style="font-variant: small-caps;">Mogul, Jeffrey C.</span> ; <span style="font-variant: small-caps;">Masinter, Larry</span> ; <span style="font-variant: small-caps;">Fielding, Roy T.</span> ; <span style="font-variant: small-caps;">Gettys, James</span>: <em>Hypertext transfer protocol – HTTP/1.1</em>. URL <a href="https://tools.ietf.org/html/rfc2616#section-10" class="uri">https://tools.ietf.org/html/rfc2616#section-10</a>. - retrieved 2017-01-20</p>
</div>
<div id="ref-web_spec_oauth-1a_client-reg">
<p>[121] <em>OAuth core 1.0a</em>. URL <a href="https://oauth.net/core/1.0a/#rfc.section.4.2" class="uri">https://oauth.net/core/1.0a/#rfc.section.4.2</a>. - retrieved 2016-11-01</p>
</div>
<div id="ref-web_spec_oauth-2_client-reg">
<p>[122] <span style="font-variant: small-caps;">Hardt, Dick</span>: <em>The OAuth 2.0 authorization framework</em>. URL <a href="https://tools.ietf.org/html/rfc6749#section-2" class="uri">https://tools.ietf.org/html/rfc6749#section-2</a>. - retrieved 2016-11-01</p>
</div>
<div id="ref-web_spec_oauth-1a_access-verification">
<p>[123] <em>OAuth core 1.0a</em>. URL <a href="https://oauth.net/core/1.0a/#rfc.section.7" class="uri">https://oauth.net/core/1.0a/#rfc.section.7</a>. - retrieved 2016-11-01</p>
</div>
<div id="ref-web_spec_oauth-2_access-verification">
<p>[124] <span style="font-variant: small-caps;">Hardt, Dick</span>: <em>The OAuth 2.0 authorization framework</em>. URL <a href="https://tools.ietf.org/html/rfc6749#section-7" class="uri">https://tools.ietf.org/html/rfc6749#section-7</a>. - retrieved 2016-11-01</p>
</div>
<div id="ref-web_spec_data-schemas_ehr">
<p>[125] <span style="font-variant: small-caps;">Foundation</span>: <em>OpenEHR - EHR information model</em>. URL <a href="http://www.openehr.org/releases/RM/latest/docs/ehr/ehr.html" class="uri">http://www.openehr.org/releases/RM/latest/docs/ehr/ehr.html</a>. - retrieved 2017-01-28</p>
</div>
<div id="ref-web_spec_data-schemas_poi">
<p>[126] <span style="font-variant: small-caps;">W3C</span>: <em>Points of interest core</em>. URL <a href="https://www.w3.org/TR/poi-core/" class="uri">https://www.w3.org/TR/poi-core/</a>. - retrieved 2017-01-28</p>
</div>
<div id="ref-web_spec_data-schemas_bank-transfer">
<p>[127] <span style="font-variant: small-caps;">Authority, ISO 20022 Registration</span>: <em>ISO 20022 - universal financial industry message scheme</em>. URL <a href="https://www.iso20022.org/" class="uri">https://www.iso20022.org/</a>. - retrieved 2017-01-28</p>
</div>
<div id="ref-web_2017_repo_node-simple-schema">
<p>[128] <em>Aldeed/node-simple-schema. GitHub</em>. URL <a href="https://github.com/aldeed/node-simple-schema" class="uri">https://github.com/aldeed/node-simple-schema</a>. - retrieved 2017-01-29</p>
</div>
<div id="ref-web_spec_xml_types">
<p>[129] <span style="font-variant: small-caps;">W3C</span>: <em>XML schema part 2: Datatypes second edition</em>. URL <a href="https://www.w3.org/TR/xmlschema-2/#built-in-primitive-datatypes" class="uri">https://www.w3.org/TR/xmlschema-2/#built-in-primitive-datatypes</a>. - retrieved 2017-01-29</p>
</div>
<div id="ref-web_spec_graphql_types">
<p>[130] <span style="font-variant: small-caps;">Facebook, Inc.</span>: <em>GraphQL Specification</em>. URL <a href="https://facebook.github.io/graphql/#sec-Input-Values" class="uri">https://facebook.github.io/graphql/#sec-Input-Values</a>. - retrieved 2017-01-29</p>
</div>
<div id="ref-web_2016_wikipedia_separation-of-concerns">
<p>[131] <em>Separation of concerns</em>. URL <a href="https://en.wikipedia.org/w/index.php?title=Separation_of_concerns&amp;oldid=747272729" class="uri">https://en.wikipedia.org/w/index.php?title=Separation_of_concerns&amp;oldid=747272729</a>. - retrieved 2017-01-24. — Page Version ID: 747272729</p>
</div>
<div id="ref-web_spec_acme">
<p>[132] <span style="font-variant: small-caps;">Kasten, James</span> ; <span style="font-variant: small-caps;">Barnes, Richard</span> ; <span style="font-variant: small-caps;">Hoffman-Andrews, Jacob</span>: <em>Automatic certificate management environment (ACME)</em>. URL <a href="https://tools.ietf.org/html/draft-ietf-acme-acme-04" class="uri">https://tools.ietf.org/html/draft-ietf-acme-acme-04</a>. - retrieved 2017-01-11</p>
</div>
<div id="ref-web_2009-success-of-facebook-connect">
<p>[133] <span style="font-variant: small-caps;">Carlson, Nicholas</span>: <em>Facebook connect is a huge success – by the numbers</em>. URL <a href="http://www.businessinsider.com/six-months-in-facebook-connect-is-a-huge-success-2009-7" class="uri">http://www.businessinsider.com/six-months-in-facebook-connect-is-a-huge-success-2009-7</a>. - retrieved 2016-12-16</p>
</div>
</div>
</section>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>according to article 12-14 of the <em>EU General Data Protection Regulation 2016/679</em><a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>EU Data Protection Regulation<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>public massages published by an account on <a href="twitter.com" class="uri">twitter.com</a>, which will be displayed in the timeline of all her subscribers and also might contain additional types of content like images, links or video<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>it doesn’t matter whether an individual or just someone on behalf of an organisation spend money for something. at the end of the day, they are all humans on this planet and in a capitalistic oriented world money needs to flow and profits needs to be maximized. So to know where it will flow or why it will flow in a certain direction it is crucial to know everything about it’s decision maker - the humans on this planet.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>side note - one might come to the conclusion, that only the trend towards the <em>cloud</em> made it actually possible to collect to such an extent we are all observing these days, because standalone software should not necessarily require internet connection and therefore the vendors had no way to gather information whatsoever<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Banking and Securities; Communication, Media &amp; Entertainment; Healthcare Providers; Government; Insurance; Retail &amp; Wholesale Trade; Energy &amp; Utilities<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Banking and Securities; Communication, Media &amp; Entertainment; Insurance; Energy &amp; Utilities<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>more information on the project, the code and the author, Sampo Kellomäki, can be found under <em>zxid.org</em><a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>Security Assertion Markup Language 2.0<a href="#fnref9">↩</a></p></li>
<li id="fn10"><p>eXtensible Access Control Markup Language<a href="#fnref10">↩</a></p></li>
<li id="fn11"><p>The JavaScript Object Notation (JSON) Data Interchange Format; ECMA Standard<br />
<span class="citation" data-cites="web_spec_json">[<a href="#ref-web_spec_json">77</a>]</span> and Internet Engineering Task Force RFC 7159 <span class="citation" data-cites="web_rfc_json">[<a href="#ref-web_rfc_json">78</a>]</span><a href="#fnref11">↩</a></p></li>
<li id="fn12"><p>JSON Web Encryption, Internet Engineering Task Force RFC 7516 <span class="citation" data-cites="web_spec_json-web-encryption">[<a href="#ref-web_spec_json-web-encryption">85</a>]</span><a href="#fnref12">↩</a></p></li>
<li id="fn13"><p>JSON Web Signature, Internet Engineering Task Force RFC 7515 <span class="citation" data-cites="web_spec_json-web-signature">[<a href="#ref-web_spec_json-web-signature">86</a>]</span><a href="#fnref13">↩</a></p></li>
<li id="fn14"><p>Internet Engineering Task Force; non-profit organisation that develops and releases standards mainly related to the Internet protocol suite<a href="#fnref14">↩</a></p></li>
<li id="fn15"><p><em>Representational State Transfer</em>, introduces by Roy Fielding in his doctoral dissertation <span class="citation" data-cites="web_spec_rest">[<a href="#ref-web_spec_rest">92</a>]</span><a href="#fnref15">↩</a></p></li>
<li id="fn16"><p>knows as HTTP Methods or Verbs <span class="citation" data-cites="web_spec_http-methods">[<a href="#ref-web_spec_http-methods">93</a>]</span> (e.g. GET, OPTIONS, PUT, DELETE)<a href="#fnref16">↩</a></p></li>
<li id="fn17"><p>World Wide Web Consortium; international community that develops standards for the web<a href="#fnref17">↩</a></p></li>
<li id="fn18"><p>Resource Description Framework <span class="citation" data-cites="web_w3c-tr_rdf">[<a href="#ref-web_w3c-tr_rdf">95</a>]</span><a href="#fnref18">↩</a></p></li>
<li id="fn19"><p>Web Ontology Language <span class="citation" data-cites="web_w3c-tr_owl">[<a href="#ref-web_w3c-tr_owl">96</a>]</span><a href="#fnref19">↩</a></p></li>
<li id="fn20"><p>social linked data <span class="citation" data-cites="web_spec_solid">[<a href="#ref-web_spec_solid">99</a>]</span><a href="#fnref20">↩</a></p></li>
<li id="fn21"><p>control groups <span class="citation" data-cites="web_2015_cgroup-doc">[<a href="#ref-web_2015_cgroup-doc">102</a>]</span><a href="#fnref21">↩</a></p></li>
<li id="fn22"><p>Electronic government<a href="#fnref22">↩</a></p></li>
<li id="fn23"><p>in german so called <em>elektronische Personalausweis (nPA)</em><a href="#fnref23">↩</a></p></li>
<li id="fn24"><p>Transaction authentication number<a href="#fnref24">↩</a></p></li>
<li id="fn25"><p>Software as a Service<a href="#fnref25">↩</a></p></li>
<li id="fn26"><p>(german) Berechtigungszertifikate-Anbieter<a href="#fnref26">↩</a></p></li>
<li id="fn27"><p><em>Digital Rights Management</em> - set of technologies, that are used to control access to data or content that is restricted in certain ways (e.g. content provided by video streaming)<a href="#fnref27">↩</a></p></li>
<li id="fn28"><p>Network Address Translation; practice of routing traffic between and through distinct networks address spaces by remapping IPs from those different networks onto each other<a href="#fnref28">↩</a></p></li>
<li id="fn29"><p>Portable Operating System Interface; a collection of standards released by the IEEE Computer Society to preserve compatibility between operating systems.<a href="#fnref29">↩</a></p></li>
<li id="fn30"><p>Domain Name System; decentralized open directory that associates readable names with IP addresses<a href="#fnref30">↩</a></p></li>
<li id="fn31"><p>Certificate signing request<a href="#fnref31">↩</a></p></li>
</ol>
</section>
            </body>
</html>
